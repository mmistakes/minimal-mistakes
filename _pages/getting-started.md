---
title: "Getting Started"
permalink: /getting-started/
classes: wide2
header:
  overlay_color: "#0066CC"
excerpt: >
  Leverage explainable AI and find the right tool for the job by using our interactive concept map.<br />
---
Often the hardest part of leveraging explainable artificial intelligence can be finding the right tool for the job. Different tools are better suited for different types of data and different problems, especially when there are humans in the loop. The concept map below is designed to give users a bit of a rough guide on how to approach problems with regard to which types of tools to try on your data and models.

Click on any resource tag in the concept map below to see associated capabilities.

{% include capabilities_map.html %}

{: .text-right}
[![CmapTools](/assets/kitware/images/CmapToolsTrademark.gif)](http://cmap.ihmc.us/)

## Other Resources
There are a lot of other awesome tools being created by the explainable AI community that we would like to share. Please feel free to submit a pull request to contribute to this list.

[AIX360](http://aix360.mybluemix.net/)  
Interpretability and explainability of data and machine learning models

[Alibi Explain](https://docs.seldon.io/projects/alibi/en/latest/)  
Algorithms for explaining machine learning models

[Captum](https://captum.ai/)  
Model interpretability and understanding for PyTorch

[Interpretable Machine Learning Book](https://christophm.github.io/interpretable-ml-book/)  
A guide for making black box models explainable

[InterpretML](https://interpret.ml/)  
A toolkit to help understand models and enable responsible machine learning

[PAIR Saliency](https://pair-code.github.io/saliency)  
Framework-agnostic implementation for state-of-the-art saliency methods

[Responsible AI Toolkit](https://www.tensorflow.org/responsible_ai)  
Integrate Responsible AI practices into ML workflows using TensorFlow

[Skater](https://oracle.github.io/Skater/overview.html)  
Python library for model interpretation and explanations