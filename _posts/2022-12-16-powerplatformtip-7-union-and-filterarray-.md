---
title: "#PowerPlatformTip 7 â€“ 'UNION and FilterArray'"
date: 2022-12-16
categories:
  - Article
  - PowerPlatformTip
tags:
  - powerautomate
  - union
  - filterarray
  - data-manipulation
  - efficiency
excerpt: "Merge and filter arrays in Power Automate: Use UNION and FilterArray for efficient data manipulation, deduplication, and smarter workflows."
header:
  overlay_color: "#2dd4bf"
  overlay_filter: "0.5"
toc: true
toc_sticky: true
---

## ğŸ’¡ Challenge
Data manipulation in Power Automate often requires merging or filtering datasets, which can feel like sorting through a mountain of information by hand.

## âœ… Solution
Use the UNION function to merge arrays and eliminate duplicates, and use FilterArray to sift and retain only desired items.

## ğŸ”§ How It's Done
Here's how to do it:
1. Use UNION  
   ğŸ”¸ The function merges two arrays into one.  
   ğŸ”¸ When the same array is used twice, it removes duplicates (like DISTINCT).  
2. Use FilterArray  
   ğŸ”¸ Iterates through an array and applies a condition to keep only matching items.  
3. Combine the functions  
   ğŸ”¸ First merge with UNION, then apply FilterArray to the result for precise filtering.

## ğŸ‰ Result
You can easily merge datasets, remove duplicates, and filter arrays, streamlining your workflows and ensuring data integrity.

## ğŸŒŸ Key Advantages
ğŸ”¸ Efficiency: Complete complex data manipulation in minutes.  
ğŸ”¸ Flexibility: Adaptable to various merging and filtering scenarios.  
ğŸ”¸ Data Integrity: Built-in deduplication when using UNION with identical arrays.

## ğŸ› ï¸ FAQ
**1. Does UNION automatically remove duplicates?**  
Yes, UNION automatically removes duplicate entries when combining arrays, ensuring unique values in the result.

**2. Can I use FilterArray with complex nested objects?**  
Absolutely! FilterArray works with complex objects and supports advanced expressions to filter based on nested properties.

**3. What's the performance impact of combining UNION and FilterArray?**  
These functions are optimized for performance, but with very large datasets, consider processing in batches to maintain optimal flow execution times.

---

