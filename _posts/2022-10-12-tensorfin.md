---
title : '[DL/BASIC] 텐서(Tensor) 알아보기 📊 '
layout : single
---

# 1. 신경망을 위한 데이터 표현 

## 1.텐서(tensor)란? : 데이터를 위한 컨테이너 , 텐서는 임의의 차원(축) 개수를 가지는 행렬의 일반화된 모습.

### 1.1.1 스칼라(랭크 - 0 텐서)

하나의 숫자만 담고 있는 텐서를 스칼라라고 부른다.

넘파이에서 float32나 float64 타입의 숫자 => 스칼라 텐서

ndim 속성을 사용해서 넘파이 배열의 축 개수를 확인해보면 스칼라 텐서의 축개수는 0이다. (텐서의 축 개수를 **랭크(rank)**라고 부른다.)


```python
import numpy as np
x = np.array(12)
print('x의 축의 개수: ',x.ndim)
```

    x의 축의 개수:  0


### 1.1.2 벡터(랭크 - 1 텐서)

숫자의 배열을 백터 또는 랭크-1 텐서나 1D텐서라고 부른다.
벡터는 1개의 축을 가진다. 


```python
x = np.array([24,6,22,12,5])
print(x)
print('x의 축의 개수: ',x.ndim)
```

    [24  6 22 12  5]
    x의 축의 개수:  1


*위의 벡터는 5차원 벡터이다. 5D벡터 ≠ 5D텐서 ,*  **차원 수** *는 특정 축을 따라 놓은 원소 개수 or 텐서의 축의 개수.*

*5D벡터는 하나의 축을 따라 5개의 차원을 가진 벡터이고 , 5D는 5개의 축을 가진 것*

### 1.1.3 행렬(랭크 - 2 텐서)

백터의 배열은 행렬(matrix)또는 랭크-2 텐서나 2D 텐서이다.


```python
x = np.array([[5,2,72,12,6],
            [21,534,86,3,21],
            [45,12,69,3,4]])
print(x)
print('x의 축의 개수: ',x.ndim)
```

    [[  5   2  72  12   6]
     [ 21 534  86   3  21]
     [ 45  12  69   3   4]]
    x의 축의 개수:  2


위의 벡터에서 첫번째 축의 원소를 행, 두번째 축의 원소를 열이라고 부른다.

### 1.1.4 랭크-3 텐서와 더 높은 랭크의 텐서

위와 같은 행렬들을 하나의 새로운 배열로 합치면 숫차가 채워진 직육면체로 해석할 수 있는 랭크-3 텐서가 만들어진다.


```python
x = np.array([[[5,2,72,12,6],
            [21,534,86,3,21],
            [45,12,69,3,4]],
            [[5,2,72,12,6],
            [21,534,86,3,21],
            [45,12,69,3,4]],
            [[5,2,72,12,6],
            [21,534,86,3,21],
            [45,12,69,3,4]]])
print('x의 축의 개수: ',x.ndim)
```

    x의 축의 개수:  3


랭크-3 탠서들을 하나의 배열로 합치면 랭크-4 텐서를 만드는 식으로 이어진다.

**딥러닝에서는 보통 랭크 0에서 4까지의 텐서를 다룬다.**

### 1.1.5 핵심속성


*   축의 개수 (랭크) : 넘파이나 텐서플로 등의 파이썬 라이브러리에서는 ndim 속성에 저장되어 있다.
*   크기(shape) : 텐서의 각 축을 따라 얼마나 많은 차원이 있는지 나타낸 파이썬의 튜플이다. 
예를 들어 위의 행렬의 크기는 (3,5) , 랭크-3 텐서는 (3,3,5)이다.
*   테이터 타입(dtype) : 텐서에 포함된 데이터의 타입. ex) float16, float32, float64 , uint8 , string 등이 있다.






MNIST 데이터를 활용해서 위의 내용을 구체적으로 다뤄보자.

먼저 MNIST 데이터셋을 불러드린다.


```python
from tensorflow.keras.datasets import mnist
(train_images,train_labels),(test_images,test_label) = mnist.load_data()
```

    Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
    11493376/11490434 [==============================] - 0s 0us/step
    11501568/11490434 [==============================] - 0s 0us/step


train_images 배열의 ndim 속성으로 축의 개수를 확인한다.


```python
train_images.ndim
```




    3



다음으로 배열의 크기를 확인한다.


```python
train_images.shape
```




    (60000, 28, 28)



dtype 속성을 이용해서 데이터 타입을 확인한다.


```python
train_images.dtype
```




    dtype('uint8')



위의 내용들로 train_images 배열은 8비트 정수형 , 랭크-3 텐서이고 , 28x28 크기의 정수행렬 6만개가 있는 배열인 것을 알 수 있다.

각 행렬은 흑백 이미지고 , 행렬의 각 원소는 0에서 255사이의 값을 가진다.

## 1.2 넘파이로 텐서 조작하기
 
train_image[i] 같은 형식으로 배열에 있는 특정 원소들을 선택하는 것을 **슬라이싱(slicing)**이라고 한다.

다음 코드는 11번째에서 101번째까지 (101번째는 포함X) 숫자를 선택해서 (90,28,28)크기의 배열을 만든다.


```python
ex_slice = train_images[10:100]
ex_slice.shape
```




    (90, 28, 28)



조금 더 자세한 slicing 표기법은 각 배열의 축을 따라 슬라이싱의 시작 인덱스와 마지막 인덱스를 지정하는 것이다. :(콜론)은 전체 인덱스를 선택한다.


```python
ex_slice= train_images[10:100,:,:]
print(ex_slice.shape)

ex2_slice = train_images[10:100, 0:25 , 0:25]
print(ex2_slice.shape)
```

    (90, 28, 28)
    (90, 25, 25)


음수 인덱스도 사용할 수 있다. 파이썬 리스트의 음수 인덱스와 마찬가지로 현재 축의 끝에서 상대적인 위치를 나타낸다. 

정중앙의 14x14 픽셀 조각을 이미지에서 잘라내려면 다음 코드와 같이 하면 된다.


```python
mid_slice = train_images[:,7:-7,7:-7]
mid_slice.shape
```




    (60000, 14, 14)



## 1.3 배치 데이터

딥러닝 모델은 한번에 전체 데이터셋을 처리하지 않는다. 

그대신 작은 배치(batch)로 나눈다. 예를 들어 MNIST 숫자 데이터에서 크기가 128인 데이터 배치는 다음과 같다.


```python
batch = train_images[:128]
```

n번째 배치는 다음과 같다.


```python
n = 3 
batch = train_images[128 * n : 128 * (n+1)]
```

이런 배치 데이터를 다룰 때 첫번째 축 (0번 축)을 **배치 축** or **배치 차원**이라고 부른다.

## 1.4 텐서의 연산

### 1.4.1 원소별 연산

이 연산은 텐서에 있는 각 원소에 독립적으로 적용된다.

넘파이 배열을 다룰 때는 최적화된 넘파인 내장함수로 덧셈,곱셈,뺄셈,relu함수 등을 처리할 수 있다.


```python
import numpy as np
z = x + y #원소별 덧셈
z = np.maximum(z,0.) #원소별 relu 함수
```

### 1.4.2 브로드캐스팅

크기가 다른 두 텐서가 더해질 때 브로드캐스팅이 일어난다.

다음과 같은 순서로 이뤄진다.

1.   큰 텐서의 ndim에 맞춰 작은 텐서에 축이 추가된다.
2.   작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복된다.



### 1.4.3 텐서 곱셈

점곱이라고도 불리는 텐서 곱셈은 가장 널리 사용되는 텐서 연산이다. (*연산자를 사용하는 원소별 곱셈과 다르다*)

넘파이에서 np.dot 함수를 사용해서 텐서 곱셈을 수행한다.


```python
import numpy as np
x = np.random.random((5,5))
y = np.random.random((5,5))
z = np.dot(x,y)

```

점곱은 임의의 축 개수를 가진 텐서에 일반화 된다. 

가장 일반적인 용도인 두 행렬 간의 점곱은 x.shape[1] == y.shape[0] 일때 점곱 (dot(x,y))이 성립한다.

## 1.5 텐서 크기 변환

텐서 크기 변환은 특정 크기에 맞게 열과 행을 재배열하는 것이다. 물론 텐서의 원소 개수는 동일하다.


```python
x = np.array([[0,1],
              [2,3],
              [4,5]])
print(x.shape)
x = x.reshape((6,1))
print(x)
x = x.reshape((2,3))
print(x)
```

    (3, 2)
    [[0]
     [1]
     [2]
     [3]
     [4]
     [5]]
    [[0 1 2]
     [3 4 5]]


자주 쓰는 특별한 크기 변환은 **전치(transposition)**이다. 행과 열을 바꾸는 것이다. 예를 들어 , x[i,j]는 x[j,i]가 된다.

출처:

프랑소와 숄레 지음, ⌜케라스 창시자에게 배우는 딥러닝 개정2판⌟, 박해선 옮김, 길벗, 2022 , 57-82쪽
