---
layout: single        # 문서 형식
title: 'Generative Adversarial Nets 리뷰'         # 제목
categories: Generative Model    # 카테고리
toc: true             # 글 목차
author_profiel: false # 홈페이지 프로필이 다른 페이지에도 뜨는지 여부
sidebar:              # 페이지 왼쪽에 카테고리 지정
    nav: "docs"       # sidebar의 주소 지정
#search: false # 블로그 내 검색 비활성화
---
# Keywords
generative model, adversarial net, discriminator



# 1. Introduction
#### - 딥러닝의 목표
딥러닝의 기본적인 목표는 인공지능을 적용을 위한 데이터의 확률 분포에서 풍부한 계층적 모델을 발견하는 것이다. 딥러닝에서 가장 두드러진 성공은 보통 고차원적이고 풍부한 감각 입력을 클래스 레이블로 매핑하는 판별 모델과 관련되어왔다. 그리고 이 성공은 주로 잘 작동하는 gradient를 가지고 있는 구간별 선형 유닛을 사용하는 역전파나 dropout 알고리즘 등에 기반한다.
#### - 기존 생성모델의 어려움
반면에 생성모델은 MLE 등에 대한 많은 완고한 확률적 계산을 추정하는 어려움과 생성 context에 대한 구간별 선형 유닛의 이점을 활용하기 어려움이 있기에 상대적으로 영향력이 적었다.
#### - 본 논문의 신경망
본 논문의 적대적 신경망에서, 생성 모델은 데이터 분포로부터 생성하고 판별 모델은 모델 분포나 데이터 분포에서 데이터가 생성되었는지를 결정하는 것을 학습한다. 그리고 이 둘을 통해 역전파 및 최적화를 진행한다. 이 때, 기존에 사용하는 근사 추론이나 Markov chain 등은 필요하지 않다. 



# 2. Adversarial Nets
## 2.1. Notation
$\bold{x}$ : 원본 데이터
$\bold{z}$ : input noise variable
$p_g$ : 생성모델의 분포
$p_\bold{z}(\bold{z})$ : input noise variables 에 대한 사전 분포
$G$ : 생성 모델, 모수가 $\theta_g$인 다층 퍼셉트론으로 구성된 미분 가능한 함수 
$G(\bold{z} ;\theta_g)$ : noise variable로 구성된 공간 -> 생성한 이미지의 분포
$D(\bold{x})$ : 판별 모델, $p_g$가 아닌 $\bold{x}$에서 추출되었을 확률분포
$D(\bold{x} ;\theta_g)$ : 원본 데이터로 구성된 공간 -> 출력 결과가 단일 스칼라인 두번째 다층 퍼셉트론 


## 2.2. Objects
#### - Generative model $G$ 
원래 데이터 $x$의 분포를 근사할 수 있도록 학습한다. 만약 학습이 잘 되었다면 통계적으로 평균적인 특징을 가지는 데이터를 쉽게 생성 가능하다.

#### - Discriminator model $D$
데이터가 원래 데이터 $x$의 분포에서 나온 것인지, 아니면 $G$의 분포에서 나온 것인지 판별하도록 학습한다. 출력 결과가 1(진짜) 또는 0(가짜)으로 판별한다.

#### - 목표
<img src = "E:\공부\Github\blog\images\GAN\figure1.jpg">

<p align="right"><img src = "E:\공부\Github\blog\images\GAN\figure1 설명.jpg" width="150" height = "50">

(a) -> (d) 로 시간의 흐름에 따라 진행하면서 생성 모델의 분포가 원본 데이터의 분포를 학습하는 것을 목표로 한다.


## 2.3. Objective Function
$min \atop G$ $ max \atop D$ $V(D,G) = \mathbb{E}_{\bold{x} \sim p_{data}({\bold{x}})} [logD(\bold{x})] + \mathbb{E}_{\bold{z} \sim p_{\bold{z}}({\bold{z}})} [1-logD(G(\bold{z}))]$ 

$\mathbb{E}_{\bold{x} \sim p_{data}({\bold{x}})} [logD(\bold{x})] $ : 원본 데이터 분포에서 샘플 $x$를 뽑아 $logD(x)$의 기댓값을 계산 
    -> 원본 데이터가 진짜(1)인지 가짜(0)인지 구분
    -> $max \atop D$ : 기댓값이 0이 나오도록 구성

$\mathbb{E}_{\bold{z} \sim p_{\bold{z}}({\bold{z}})} [1-logD(G(\bold{z}))]$ : noise variable 분포에서 샘플 $z$를 뽑아 $1-logD(G(z))$의 기댓값을 계산 
    -> 생성모델을 이용해 만든 이미지가 진짜(1)인지 가짜(0)인지 구분 
    -> $D(G(z))$ = 1 -> 기댓값 감소, $D(G(z))$ = 0 -> 기댓값 증가
    -> $min \atop G$ : 기댓값이 0이 나오도록 구성



# 3. Theoritical Results
#### - algorithm 1
미니배치 최적화 진행 알고리즘
<img src = "E:\공부\Github\blog\images\GAN\algorithm1.jpg">


## 3.1. Global Optimality of $p_g = p_\bold{data}$
(생성한 이미지와 원본 이미지를 구별하지 않는 경우 또는 구별되지 않는 경우 고려)
#### - Proposition 1 : Optimal Discriminator
고정된 $G$에 대해, 최적의 판별자 D는 다음과 같다. 
$D^{*}_G(\bold{x}) = p_\bold{data}(\bold{x}) / (p_\bold{data}(\bold{x}) + p_g(\bold{x}))$

$Proof$. 주어진 어떤 $G$에 대해,
$V(G,D) = \int_{\bold{x}}p_{data}(\bold{x})log(D(\bold{x})) dx + \int_{\bold{z}}p_{\bold{z}}(\bold{z})log(1-D(g(\bold{x}))) dz$ = $\int_{\bold{x}}p_{data}(\bold{x})log(D(\bold{x})) + p_{g}(\bold{x})log(1-D(\bold{x}))dx$
($\because g(\bold{z}) = \bold{x} $  if  $ p_g = p_\bold{data}$ -> 이미지에 대한 labeling 구분 x)

For any (a,b) $\in \mathbb{R}^2 $ \ {0,0}, the function $F(y) = alog(y) + blog(1-y)$는 $a/(a+b)$ 에서 최대값 [0,1]을 가진다. 따라서 판별 모형은 $Supp(p_{data}) \bigcup Supp(p_{g})$ 에서만 정의되므로 증명이 된다.

#### - Definition : The virtual training criterion $C(G)$

$ C(G) $= $ max \atop D$ $V(G,D) $ 
$= \mathbb{E}_{\bold{x} \sim p_{data}} [logD^*_G(\bold{x})] + \mathbb{E}_{\bold{z} \sim p_{\bold{z}}} [1-logD^*_G(G(\bold{z}))]$ 
$= \mathbb{E}_{\bold{x} \sim p_{data}} [logD^*_G(\bold{x})] + \mathbb{E}_{\bold{z} \sim p_{g}} [1-logD^*_G(\bold{x})]$ 
$= \mathbb{E}_{\bold{x} \sim p_{data}({\bold{x}})} [log (p_{data}(\bold{x})/(p_{data}(\bold{x})+ p_{g}(\bold{x})))] + \mathbb{E}_{\bold{z} \sim p_{\bold{z}}({\bold{z}})} [log (p_{g}(\bold{x})/(p_{data}(\bold{x})+ p_{g}(\bold{x})))]$ 

#### - Theorem 1 : Lower bound of the global minimum
virtual training criterion $C(G)$의 global 최솟값의 필요충분 조건은 $p_g = p_\bold{data}$ 이고, 이 지점에서 $C(G)$의 값은 $-log4$이다.


$Proof$.
$p_g = p_{data}$ 에 대해 Proposition 1에 의해 $D^*_G(\bold{x}) = 1/2$이다. 따라서 $C(G) = log(1/2) + log(1/2) = -log4$ 임을 알 수 있다.  위 정리(가설)에서 $C(G) = V(D^*_G, G)$ 로 표현하면, Jenson-Shannon divergence(JSD)에 의해
$C(G) = -log4 + KL(p_{data}||(p_{data}+ p_{g})/2) + KL(p_{g}||(p_{data}+ p_{g})/2) = -log4 + 2*JSD(p_{data} || p_{g})$ 
임을 알 수 있다. 두 분포간 Jenson-Shannon divergence 는 항상 0이상이고 두 분포가 동일할 때 0이므로, $C(G)$의 global 최솟값은 $-log4$ 임을 알 수 있다.  


## 3.2. Convergence of Algorithm 1
#### - Proposition 2 : Covergence of $p_g$ to $p_x$ 
G와 D가 충분한 용량을 가지고 있고, Algorithm1의 각 단계에서 판별 모델이 주어진 G에 대해 최적 상태에 도달되도록 허용되며, $p_g$가 다음과 같은 기준을 개선하도록 업데이트 된다면,
$\mathbb{E}_{\bold{x} \sim p_{data}({\bold{x}})} [logD^*_G(\bold{x})] + \mathbb{E}_{\bold{z} \sim p_{\bold{z}}({\bold{z}})} [1-logD^*_G(\bold{x})]$ 
$p_g$는 $p_{data}$로 수렴한다.

$Proof.$
$p_g$ 에 대한 기준이 위와 같을 때, $V(G,D) = U(p_g,D)$을 고려해보자. 이 때, $U(p_g,D)$는 $p_g$에 대해 볼록함수이다. 그러면 볼록함수의 상한에 대한 하방미분은 최고점에서의 도함수를 포함한다. 즉, 이는 주어진 G에 대해 최적의 D에서 $p_g$에 대한 gradient descent를 계산하는 것과 동일하다. Theorem 1에서 증명한 바와 같이 $sup_{D}U(p_g,D)$는 $p_g$에 대해 볼록하며 유일한 global 최적점을 가진다. 따라서 충분히 작은 업데이트로도 $p_g$ 가 $p_x$로 수렴하는 것을 알 수 있다.



# 4. Experiments
## 1. Train
#### - Adversarial nets
datasets : MNIST, Toronto Face Database(TFD), CIFAR-10

#### - Generator nets
rectifier linear activation(ReLU), sigmoid activation 사용

#### - Discriminator nets
maxout activation 사용
dropout 적용


## 2. Test
$G$로 생성한 샘플에 Gaussian Parzen window를 맞추어 이 분포 하에서 로그 가능도를 전달함으로써 테스트 데이터의 확률을 $p_g$ 하에서 추정했다. 이 때 Gaussian의 파라미터 $\sigma$는 cross validation을 이용해 최적의 값을 계산해 적용했다.

<p align="center"><img src = "E:\공부\Github\blog\images\GAN\Table1.jpg" width="450" height = "150">


이 가능도 추정방법은 상당히 높은 분산을 가지고 고차원 데이터에 대한 성능이 좋지 않지만, 최선의 방법이다. 

<img src = "E:\공부\Github\blog\images\GAN\figure2.jpg" width = 700 height = 700>

위 이미지들은 훈련 후 generative nets의 샘플들이다. 기존 방법들보다 우수하다고는 할 수는 없지만 적대적 프레임워크의 잠재력을 제시하며 우수한 생성 모델들과 경쟁이 가능하다고 본다.




# 5. Advantages and Disadvantages
#### - 장점
1. Markov chain이 필요하지않다.
2. 오직 역전파만을 이용해 기울기를 계산한다.
3. train 중 추론이 필요없으며 다양한 함수를 모델에 통합가능하다.
4. 주로 계산적인 측면에서 강점을 보인다.

#### - 단점
1. $p_g$에 대한 명시적 표현이 없다.
2. 훈련 중 $D$와 $G$가 잘 동기화되어야한다. $G$가 $D$를 잘 업데이트하지 않은 채로 훈련하게 되면, $p_{data}$를 모델링하기에는 다양성이 부족해지는 현상이 발생한다.



# 6. Conclusions and Future works 
1. 조건부 생성 모델 $p(\bold{x}|\bold{c})$는 $\bold{c}$를 $G$와 $D$ 모두에 입력으로 추가해 얻을 수 있다.
2. 학습된 근사 추론은 $\bold{x}$가 주어졌을 때 $\bold{z}$를 예측하기 위해 보조 네트워크를 훈련함으로써 수행 가능하다.
3. $S$ 가 $\bold{x}$의 인덱스들의 하위 집합일때, 모든 조건부 $p(\bold{x}_S | \bold{x}_{\not{S}})$에 대해 매개변수를 공유하는 모든 조건부 모델 종류를 훈련해 대략적으로 모델링할 수 있다.
4. seim-supervised 학습 : 판별 모델 또는 추론 신경망에서 얻은 특징은 제한된 labeling 데이터가 있을 때 분류기의 성능을 향상할 수 있다.
5. 효율성 개선 : $G$와 $D$를 조정하는 더 나은 방법을 고안하거나 훈련 중 샘플링할 $\bold{z}$의 더 나은 분포를 결정함으로써 훈련 속도를 크게 증가할 수 있다.



# 참고
[GAN: Generative Adversarial Networks (꼼꼼한 딥러닝 논문 리뷰와 코드 실습)]
https://www.youtube.com/watch?v=AVvlDmhHgC4&t=2020s

[Jensen-Shannon Divergence]
https://ddongwon.tistory.com/118