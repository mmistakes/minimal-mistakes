---
layout: single
title:  "10.ë‹¨ì–´ ë¹ˆë„ë¶„ì„ê³¼ Word Clouding"
categories: TextMining
tag: [python,Jupyter Notebook,TextMining]
toc: true
toc_sticky: true
author_profile: false #ì˜†ì— ì •ë³´ ë„ê¸°
sidebar: 
    nav: "docs"
typora-root-url: ../
---

<div class="notice--info">
<h4>ğŸ’¡ëª©í‘œ</h4>
<ul>
    <li> ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ë§ì´ ì‚¬ìš©ë˜ëŠ” íŒ¨í‚¤ì§€ì¸ sklearn ì¤‘ì— CountVectorizerë¥¼ ì´ìš©í•´ DTMê³¼ TDMìë£Œ ë§Œë“¤ê¸°</li>
    <li>DTMìë£Œì™€ TDM ìë£Œë¥¼ í†µí•´ì„œ TF(Term Frequency)ë¡œ ìë£Œë¥¼ ë³€í™˜í•˜ê³  wordcloudë¥¼ í†µí•´ ì‹œê°í™” í•´ë³´ê¸°</li>
</ul>
</div>

---

#### 1) dtmê³¼ tdm ì´ë€?

-   dtm = Document Term Matrix(ë¬¸ì„œ ìš©ì–´ í–‰ë ¬)  
    Â  Â  Â  Â  Â  ë¬¸ì„œê°€ í–‰ì— ì˜¤ê³  ìš©ì–´ê°€ ë³€ìˆ˜(ì—´)ì— ì˜¤ëŠ” í˜•íƒœ.

-   tdm = Term Document Matrix(ìš©ì–´ ë¬¸ì„œ í–‰ë ¬)  
    Â  Â  Â  Â  Â  ë¬¸ì„œê°€ ì—´ì—ì˜¤ê³  ìš©ì–´ê°€ í–‰ì— ì˜¤ëŠ” í˜•íƒœ.

---

##### _ì‹¤ìŠµ) 01. íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°_

```
#pip install wordcloud                      #wordcloudì—ì„œ ì˜¤ë¥˜ì‹œì— #ì‚­ì œí•˜ê³  ì‹¤í–‰í•˜ê¸°

import pandas as pd                         #ë°ì´í„°êµ¬ì¡°ì˜ ì „ë°˜ì ì¸ ì²˜ë¦¬í•˜ëŠ” íŒ¨í‚¤ì§€
import sklearn                              
from sklearn.feature_extraction.text import CountVectorizer   #íŠ¹ì§•(ë‹¨ì–´)ê°€ ëª‡ë²ˆ ë“¤ì–´ìˆëŠ”ì§€
from wordcloud import WordCloud, STOPWORDS  #STOPWORDS ë¶ˆìš©ì–´ì²˜ë¦¬
import matplotlib.pyplot as plt             #matplotlib.pyplot ê·¸ë¦¼ì„ ê·¸ë ¤ì£¼ëŠ” ê¸°ë³¸ íŒ¨í‚¤ì§€
import numpy as np                          #numpy ì—°ì‚°ì²˜ë¦¬ë¥¼ arrayë¡œ í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€
```



##### _ì‹¤ìŠµ)02. ë°ì´í„°ë¶ˆëŸ¬ì˜¤ê¸° ë° DTMìë£Œ ë§Œë“¤ê¸°_

```
data=pd.read_csv('wos_ai_.csv',encoding='utf-8').ABSTRACT   #ABSTRACTì—´ë§Œ ë¶ˆëŸ¬ì˜¤ê¸°
cv = CountVectorizer(max_features=100,stop_words='english')
```

\- max\_features ëŠ” íŠ¹ì„±(ë‹¨ì–´)ì˜ ê°¯ìˆ˜ë¥¼ ì§€ì •í•´ì£¼ëŠ” ê²ƒ

\- stop\_words ëŠ” ë¶ˆìš©ì–´ ì²˜ë¦¬ë¥¼ ì˜ì–´ë¡œ í•œë‹¤ëŠ” ê²ƒ(í•œê¸€ì€ ì•„ì‰½ê²Œ ì—†ìŒ)

```
dtm= cv.fit_transform(data) #100ê°œì˜ ìë£Œë¥¼ ì…‹ë˜ cv ìë£Œë¥¼ dtm ìë£Œë¡œ ë³€í™˜
dtm   #ê²°ê³¼ : <119x100 sparse matrix of type '<class 'numpy.int64'>'
```

\- ìœ„ì— max\_featuresì˜ ê°’ì„ 300ê°œë¡œ ì¤€ë‹¤ë©´ dtm ê²°ê³¼ëŠ” 119x300 ìœ¼ë¡œ ì¶œë ¥ ë¨.

\- ì¶”ì¶œí•˜ê³  ì‹¶ì€ ì›í•˜ëŠ” ë‹¨ì–´ì˜ ìˆ˜ë¥¼ max\_featuresì˜ ê°’ì— ì…ë ¥í•´ì£¼ë©´ ë¨.



---

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  

Â [ DTM ìë£Œ í˜•íƒœ \]

| Â  | 1 | ë‹¨ì–´2 | ë‹¨ì–´3 |
| --- | --- | --- | --- |
| ë¬¸ì„œ1 | 2 | 3 | 4 |
| ë¬¸ì„œ2 | 4 | 1 | 0 |
| **ì´** | **6** | **4** | **4** |

Â  \[ TF ìë£Œ í˜•íƒœ \]

| ë‹¨ì–´1 | 6 |
| --- | --- |
| ë‹¨ì–´2 | 4 |
| ë‹¨ì–´3 | 4 |

\- í˜„ì¬ dtm ë³€ìˆ˜ì˜ í˜•íƒœëŠ” DTM ìë£Œ í˜•íƒœì™€ ê°™ì€ë° ì‹¤ì œë¡œ í…ìŠ¤íŠ¸ë¶„ì„ì„ ìœ„í•´ì„  **TF ìë£Œ í˜•íƒœë¡œ ë³€í™˜**í•  í•„ìš”ê°€ ìˆìŒ.



---



##### _ì‹¤ìŠµ)03. TF ë§Œë“¤ê¸°_

```
words = cv.get_feature_names()   #íŠ¹ì„±(ë‹¨ì–´)ì˜ ì´ë¦„ì„ wordsì— ì €ì¥
```

![ìŠ¤í¬ë¦°ìƒ· 2023-04-03 150812](/images/ìŠ¤í¬ë¦°ìƒ· 2023-04-03 150812.png)

\- wordsì˜ ê°’ì„ ì‹¤ì œë¡œ ì‚´í´ë³´ë©´ algorithm ê³¼ algorithms ì€ ì–´ê°„ì´ ê°™ìœ¼ë¯€ë¡œ ì „ì²˜ë¦¬ ê³¼ì •ì´ ë” í•„ìš”í•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŒ.

\- ì´ë²ˆ ì‹¤ìŠµ ë•ŒëŠ” wordcloud ì‹œê°í™”ê°€ ëª©í‘œì´ë¯€ë¡œ ì „ì²˜ë¦¬ë¥¼ í•˜ì§€ ì•Šì•˜ì§€ë§Œ, í…ìŠ¤íŠ¸ë¶„ì„ ì‹œì— ì „ì²˜ë¦¬ê°€ ì¤‘ìš”í•¨.

```
count_mat = dtm.sum(axis=0)    #sumì„ ì‚¬ìš©í•˜ë ¤ë©´ numpy í•„ìš”.
```

\- dtm ìë£Œë¥¼ ì—´(ì„¸ë¡œ)ë¡œ sum(ë”í•˜ê¸°)í•˜ë¼.

\- í–‰ìœ¼ë¡œ ë”í•˜ë ¤ë©´ axis=1

\- count\_matì€ ì¼ë•Œ matrix í˜•íƒœë¡œ ì¶œë ¥ëœë‹¤.

```
count = np.squeeze(np.asarray(count_mat))   #arrayí˜•íƒœë¡œ ë°”ê¿”ì¤Œ
```

\- countë³€ìˆ˜ë¥¼ ìœ„ì˜ words í•¨ìˆ˜ì™€ í•©ì³ì£¼ê¸° ìœ„í•´ array í˜•íƒœë¡œ ë³€í™˜í•œë‹¤.

![ìŠ¤í¬ë¦°ìƒ· 2023-04-03 151950](/images/ìŠ¤í¬ë¦°ìƒ· 2023-04-03 151950.png)

```
word_list=list(sip(words,count)) #countì™€ words ë³€ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì³ì¤Œ
word_list
```

![ìŠ¤í¬ë¦°ìƒ· 2023-04-03 152303](/images/ìŠ¤í¬ë¦°ìƒ· 2023-04-03 152303-1681039771016-5.png)

```
word_list=sorted(word_list,key=lambda x:x[1],reverse=True) # x[1] = count ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
```



##### _ì‹¤ìŠµ)04. WordCloud ê·¸ë¦¬ê¸°_

```
stopwords= set(STOPWORDS)   # ë¶ˆìš©ì–´ ì €ì¥
wc = WordCloud(background_color='black',stopwords=stopwords,width=800,height=600) #wordcloud ì„¤ì •
cloud = wc.generate_from_frequencies(dict(word_list))  #wc(ì›Œë“œí´ë¼ìš°ë“œ) ë¹ˆë„ëŠ” word_listë¡œ ì§€ì •
plt.figure(figsize=(12,9))  # ê·¸ë˜í”„ í¬ê¸° ì¡°ì •
```

\- background\_color = ì›Œë“œí´ë¼ìš°ë“œì˜ ë°°ê²½ìƒ‰ ì§€ì •

\- stopwords = ë¶ˆìš©ì–´ ì§€ì •(ì—¬ê¸°ì„  ìš°ë¦¬ê°€ ì €ì¥í•œ stopwords ë³€ìˆ˜ ì‚¬ìš©)

\- figsize = ê·¸ë˜í”„ í¬ê¸° ì¡°ì •

```
plt.imshow(cloud)  #ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ì¤€ë‹¤.
plt.axis('off')    #ê·¸ë˜í”„ì˜ ì¶• ì—†ì•¤ë‹¤.
```

\- ì‹¤í–‰ ì‹œì— ì•ˆë‚˜ì˜¤ë©´ plt.show() ì¶”ê°€í•˜ê¸°.

![ìŠ¤í¬ë¦°ìƒ· 2023-04-03 153917](/images/ìŠ¤í¬ë¦°ìƒ· 2023-04-03 153917.png)
<br>

---


<br>
[\[ ì‹¤ìŠµíŒŒì¼ ë°”ë¡œê°€ê¸°(.git) \]](https://github.com/SongEunHwa/TextMining/blob/main/0403%2010%EC%9E%A5.ipynb){: .btn .btn--primary .btn--large}{: .align-center}

[\[ ë‹¤ìŒì±•í„° ë°”ë¡œê°€ê¸°(11.ë‹¨ì–´ ë° ë¶ˆìš©ì–´ 2ì°¨ ì •ì œ) \]](https://songeunhwa.github.io/textmining/2023-04-09-11Textmining){: .btn .btn--primary .btn--large}{: .align-center}
