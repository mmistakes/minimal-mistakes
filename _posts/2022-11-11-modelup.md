---
layout: single
title:  "[DL/κ³ κΈ‰] ν•μ΄νΌνλΌλ―Έν„°μ™€ μ•™μƒλΈ” - λ¨λΈμ μ„±λ¥ λμ–΄μ¬λ¦¬κΈ° π€"
toc: true
toc_sticky: true
categories:
  - advanced
---
## 1. λ¨λΈμ μµλ€ μ„±λ¥ λμ–΄λ‚΄κΈ° (KerasTuner, λ¨λΈ μ•™μƒλΈ”)

### 1.0 λ“¤μ–΄κ°€λ©° 
λ‹¨μ§€ μ‘λ™λ§ ν•λ” λ¨λΈμ„ κµ¬μ¶•ν•λ ¤λ©΄ κ·Έλƒ¥ λ§μ€ μ‹λ„λ¥Ό ν•΄λ³΄λ©° λ¨λΈμ„ λ§λ“¤μ–΄λ΄λ„ μ¶©λ¶„ν•μ§€λ§, λ” λ›°μ–΄λ‚ μ„±λ¥μ λ¨λΈμ„ λ§λ“¤λ ¤λ©΄ λ§μ€ κΈ°λ²•μ΄ ν•„μ”ν•λ‹¤. μ΄λ² κΈ€μ—μ„λ” λ¨λΈμ΄ κ·Έλƒ¥ μ‘λ™ν•λ” μμ¤€μ„ λ„μ–΄μ„ λ¨Έμ‹ λ¬λ‹ κ²½μ—° λ€νμ—μ„ μ°μΉν•  μ μλ” μ •λ„μ μ„±λ¥μ λ¨λΈμ„ κµ¬μ¶•ν•λ” κΈ°λ²•λ“¤μ— λ€ν•΄μ„ λ‹¤λ£° κ²ƒμ΄λ‹¤. 

### 1.1 ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”

#### 1.1.1 ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”λ€?
λ”¥λ¬λ‹ λ¨λΈμ„ λ§λ“¤ λ•λ” μƒλ‹Ήν λ§μ€ κ²°μ •μ„ ν•΄μ•Όν•λ‹¤. μλ¥Ό λ“¤μ–΄ 'μ–Όλ§λ‚ λ§μ€ μΈµμ„ μ“μ„κΉ?' , 'μΈµλ§λ‹¤ μ–Όλ§λ‚ λ§μ€ μ λ‹›μ΄λ‚ ν•„ν„°λ¥Ό λ‘μ–΄μ•Ό ν• κΉ?' , 'relu ν•¨μλ¥Ό μ‚¬μ©ν•΄μ•Ό ν•λ‚? μ•„λ‹λ©΄ λ‹¤λ¥Ό ν•¨μλ¥Ό μ‚¬μ©ν•΄μ•Ό ν•λ‚?' λ“±μ μ§λ¬Έλ“¤μ— λ€ν• κ²°μ •μ„ ν•΄μ•Όν•λ‹¤. μ΄λ° κµ¬μ΅°μ— κ΄€λ ¨λ νλΌλ―Έν„°λ¥Ό μ—­μ „νλ΅ ν›λ ¨λλ” λ¨λΈ νλΌλ―Έν„°μ™€ κµ¬λ¶„ν•μ—¬ **ν•μ΄νΌνλΌλ―Έν„°**λΌκ³  λ¶€λ¥Έλ‹¤. ν•μ΄νΌνλΌλ―Έν„° νλ‹μ— λ€ν• κ³µμ‹μ μΈ κ·μΉ™μ€ μ—†λ‹¤. κ²½ν—μ΄ λ§μ€ λ”¥λ¬λ‹ μ—”μ§€λ‹μ–΄μ™€ μ—°κµ¬μλ“¤μ€ ν•μ΄νΌνλΌλ―Έν„°μ— λ€ν• μ§κ΄€μ„ κ°€μ§€κ³  μμ§€λ§ μ΄λ“¤μ΅°μ°¨λ„ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ— λ€λ¶€λ¶„μ μ‹κ°„μ„ ν¬μν•λ‹¤. ν•μ§€λ§ ν•λ£¨ μΆ…μΌ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μμ •ν•λ” κ²ƒμ€ μ‚¬λμ΄ ν•  μΌμ΄ μ•„λ‹λ‹¤. μ΄λ” κΈ°κ³„μ— μ„μ„ν•λ” κ²ƒμ΄ λ” λ‚«λ‹¤.

κ°€λ¥ν• κ²°μ • κ³µκ°„μ„ μλ™μ , μ΅°μ§μ , κ·μΉ™μ μΈ λ°©λ²•μΌλ΅ νƒμƒ‰ν•΄μ•Ό ν•λ‹¤. κ°€λ¥μ„± μλ” κµ¬μ΅°λ¥Ό νƒμƒ‰ν•΄μ„ μ‹¤μ  κ°€μ¥ λ†’μ€ μ„±λ¥μ„ λ‚΄λ” κµ¬μ΅°λ¥Ό μ°Ύμ•„μ•Ό ν•λ‹¤. ν•μ΄νΌνλΌλ―Έν„° μλ™ μµμ ν™”κ°€ μ΄μ— κ΄€λ ¨λ λ¶„μ•Όμ΄λ‹¤. μ΄λ” ν•λ‚μ μ¤‘μ”ν• μ—°κµ¬ λ¶„μ•Όμ΄λ‹¤.

μ „ν•μ μΈ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™” κ³Όμ •μ€ λ‹¤μκ³Ό κ°™λ‹¤.

1. μΌλ ¨μ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό (μλ™μΌλ΅) μ„ νƒν•λ‹¤.
2. μ„ νƒλ ν•μ΄νΌνλΌλ―Έν„°λ΅ λ¨λΈμ„ κµ¬μ¶•ν•λ‹¤.
3. ν›λ ¨ λ°μ΄ν„°μ— ν•™μµν•κ³  κ²€μ¦ λ°μ΄ν„°λ΅ μ„±λ¥μ„ μΈ΅μ •ν•λ‹¤.
4. λ‹¤μμΌλ΅ μ‹λ„ν•  ν•μ΄νΌνλΌλ―Έν„°λ¥Ό (μλ™μΌλ΅) μ„ νƒν•λ‹¤.
5. μ„μ κ³Όμ •μ„ λ°λ³µν•λ‹¤.
6. λ§μ§€λ§‰μΌλ΅ ν…μ¤νΈ λ°μ΄ν„°λ΅ μ„±λ¥μ„ μΈ΅μ •ν•λ‹¤.

κ²€μ¦ μ„±λ¥κ³Ό λ‹¤μ–‘ν• ν•μ΄νΌνλΌλ―Έν„° μ‚¬μ΄μ κ΄€κ³„λ¥Ό λ¶„μ„ν•΄μ„ λ‹¤μ λ²μ— μ‹λ„ν•  ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ„ νƒν•λ” μ•κ³ λ¦¬μ¦μ΄ μ΄ κ³Όμ •μ ν•µμ‹¬μ΄λ‹¤. μ΄ κ³Όμ •μ—μ„ **λ² μ΄μ¦ μµμ ν™”**, **μ μ „ μ•κ³ λ¦¬μ¦**, **κ°„λ‹¨ν• λλ¤ νƒμƒ‰** λ“±μ μ—¬λ¬κ°€μ§€ κΈ°λ²•μ„ μ‚¬μ©ν•  μ μλ‹¤. λ¨λΈμ κ°€μ¤‘μΉ(νλΌλ―Έν„°)λ¥Ό ν›λ ¨ν•λ” κ²ƒκ³Ό λ‹¬λ¦¬ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ—…λ°μ΄νΈ ν•λ” κ²ƒμ€ λ‹¤μμ μ΄μ λ“¤ λ•λ¬Έμ— μ‰½μ§€ μ•μ€ κ³Όμ •μ΄λ‹¤.

* ν•μ΄νΌνλΌλ―Έν„° κ³µκ°„μ€ μ—°μ†μ μ΄μ§€ μ•κ³ , λ―Έλ¶„κ°€λ¥ν•μ§€ μ•κΈ° λ•λ¬Έμ— κ²½μ‚¬ ν•κ°•λ²•μ„ μ‚¬μ©ν•  μ μ—†κ³ , λ€μ‹  ν›¨μ”¬ λΉ„ν¨μ¨μ μΈ κ·Έλ λ””μ–ΈνΈ-ν”„λ¦¬ μµμ ν™” κΈ°λ²•μ„ μ‚¬μ©ν•΄μ•Ό ν•λ‹¤.
* μµμ ν™” κ³Όμ •μ ν”Όλ“λ°± μ‹ νΈλ¥Ό κ³„μ‚°ν•λ” κ²ƒμ€ μƒλ΅μ΄ λ¨λΈμ„ λ§λ“¤κ³  μ²μλ¶€ν„° λ‹¤μ‹ ν›λ ¨ν•΄μ•Όν•κΈ° λ•λ¬Έμ— λ§¤μ° λΉ„μ©μ΄ λ§μ΄ λ“ λ‹¤.
* ν”Όλ“λ°± μ‹ νΈλ” μ΅μμ΄ λ§μ„ μ μλ‹¤. μ–΄λ–¤ ν›λ ¨μ΄ 0.2%μ μ„±λ¥μ„ λ†’μ€λ‹¤λ©΄ λ” μΆ‹μ€ λ¨λΈ μ„¤μ • λ•λ¬ΈμΌκΉ? μ•„λ‹λ©΄ μ΄κΈ° κ°€μ¤‘μΉ κ°’μ΄ μ°μ—°ν μΆ‹μ•λ κ²ƒμΌκΉ?

λ‹¤ν–‰ν ν•μ΄νΌνλΌλ―Έν„° νλ‹μ„ μ‰½κ² μν–‰ν•  μ μλ” λ„κµ¬μΈ KerasTunerκ°€ μλ‹¤.

#### 1.1.2 KerasTuner μ‚¬μ©ν•κΈ°
λ¨Όμ € KerasTunerλ¥Ό μ„¤μΉν•λ‹¤.


```python
!pip install keras-tuner -q
```

    [K     |β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–| 135 kB 14.0 MB/s 
    [K     |β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–| 1.6 MB 55.9 MB/s 
    [?25h

KerasTunerλ¥Ό μ‚¬μ©ν•λ©΄ units=32μ™€ κ°™μ€ ν•λ“μ½”λ”©λ ν•μ΄νΌνλΌλ―Έν„° κ°’μ„ Int(name='units=32', min_value=16, max_value=64, step=16)κ³Ό κ°™μ΄ κ°€λ¥ν• μ„ νƒ λ²”μ„λ΅ λ°”κΏ€ μ μλ‹¤. μ–΄λ–¤ λ¨λΈμ— λ€ν• μ΄λ° μ„ νƒμ μ§‘ν•©μ„ ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ³Όμ •μ **νƒμƒ‰ κ³µκ°„(search space)**μ΄λΌκ³  λ¶€λ¥Έλ‹¤.

νƒμƒ‰ κ³µκ°„μ„ μ§€μ •ν•κΈ° μ„ν•΄ λ¨λΈ κµ¬μ¶• ν•¨μλ¥Ό μ •μν•λ‹¤. μ΄ ν•¨μλ” ν•μ΄νΌνλΌλ―Έν„° λ²”μ„λ¥Ό μƒν”λ§ν•  μ μλ” hp λ§¤κ°λ³€μλ¥Ό λ°›κ³  μ»΄νμΌλ μΌ€λΌμ¤ λ¨λΈμ„ λ°ν™ν•λ‹¤.


```python
from tensorflow import keras
from tensorflow.keras import layers

def build_model(hp):
  # hp κ°μ²΄μ—μ„ ν•μ΄νΌνλΌλ―Έν„° κ°’μ„ μƒν”λ§, μƒν”λ§ν• μ΄ κ°’(units)μ€ μΌλ°μ μΈ νμ΄μ¬ μƒμ
  units = hp.Int(name='units', min_value=16, max_value=64, step=16)

  model = keras.Sequential([
      layers.Dense(units, activation='relu'),
      layers.Dense(10, activation='softmax')
  ])
  # Int,Float,Boolean,Choice λ“± μ—¬λ¬ μΆ…λ¥μ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ κ³µ
  optimizer = hp.Choice(name='optimizer', values=['rmsprop','adam'])

  model.compile(
      optimizer = optimizer,
      loss = 'sparse_categorical_crossentropy',
      metrics = ['accuracy'])
  return model # μ»΄νμΌλ λ¨λΈ λ°ν™
```

HyerModel ν΄λμ¤λ¥Ό μƒμ†ν•κ³  build λ§¤μ„λ“λ¥Ό μ •μν•λ©΄ λ¨λΈ κµ¬μ¶•μ„ μ΅°κΈ λ” λ¨λ“ν™”ν•κ³  μ„¤μ •ν•κΈ° μ‰½κ² λ§λ“¤ μ μλ‹¤.


```python
from keras_tuner.engine import hypermodel
import keras_tuner as kt

class SimpleMLP(kt.HyperModel):
  def __init__(self, num_classes):
    self.num_classes = num_classes

  def build(self,hp): # μ„μ build_model() ν•¨μμ™€ λ™μΌ
    units = hp.Int(name='units',min_value=16,max_value=64,step=16)
    model = keras.Sequential([
        layers.Dense(units,activation='relu'),
        layers.Dense(self.num_classes,activation='softmax')
    ])

    optimizer = hp.Choice(name='optimizer',values =['rmsprop','adam'])
    model.compile(
        optimizer = optimizer,
        loss = 'sparse_categorical_crossentropy',
        metrics = ['accuracy'])
    return model

hypermodel = SimpleMLP(num_classes=10)
```

λ‹¤μ λ‹¨κ³„λ” **'νλ„(tuner)'**λ¥Ό μ •μν•λ” κ²ƒμ΄λ‹¤. νλ„λ¥Ό λ‹¤μ κ³Όμ •μ„ λ°λ³µν•λ” for λ£¨ν”„λ΅ μƒκ°ν•λ©΄ λλ‹¤.

* μΌλ ¨μ ν•μ΄νΌνλΌλ―Έν„° κ°’μ„ μ„ νƒν•λ‹¤.
* μ΄λ° κ°’μΌλ΅ λ¨λΈ κµ¬μ¶• ν•¨μλ¥Ό νΈμ¶ν•μ—¬ λ¨λΈμ„ λ§λ“ λ‹¤.
* λ¨λΈμ„ ν›λ ¨ν•κ³  ν‰κ°€ κ²°κ³Όλ¥Ό κΈ°λ΅ν•λ‹¤.

KerasTunerλ” RandomSearch, BayesianOptimization, Hyperbandμ λ‚΄μ¥ νλ„λ¥Ό μ κ³µν•λ‹¤. μ΄μ „ μ„ νƒμ κ²°κ³Όλ¥Ό λ°”νƒ•μΌλ΅ μµμƒμ ν•μ΄νΌνλΌλ―Έν„° κ°’μ„ μμΈ΅ν•λ” BayesianOptimization νλ„λ¥Ό μ‚¬μ©ν•΄λ³΄κ² λ‹¤.


```python
tuner = kt.BayesianOptimization(
    build_model, # λ¨λΈ κµ¬μ¶• ν•¨μ (or HyperModel ν΄λμ¤ κ°μ²΄) μ§€μ •
    objective = 'val_accuracy', # νλ„κ°€ μµμ ν™”ν•  μ§€ν‘ μ§€μ •, ν•­μƒ κ²€μ¦ μ§€ν‘ μ§€μ •
    max_trials = 100, # νƒμƒ‰μ„ λλ‚΄κΈ° μ „κΉμ§€ μ‹λ„ν•  μµλ€ νμ
    executions_per_trial = 2, # κ° λ¨λΈ μ„¤μ •μ„ λ‡λ²μ”© ν›λ ¨ν•΄μ„ ν‰κ· ν• μ§€ μ„¤μ •
    directory = 'mnist_kt_test', # νƒμƒ‰ λ΅κ·Έ μ €μ¥ μ„μΉ
    overwrite = True # μƒλ΅μ΄ νƒμƒ‰μ„ μ‹μ‘ν•κΈ° μ„ν•΄ λ””λ ‰ν„°λ¦¬μ λ°μ΄ν„° λ®μ–΄μ“Έμ§€ μ—¬λ¶€
    # λ¨λΈ κµ¬μ¶•ν•¨μλ¥Ό μμ •ν–λ‹¤λ©΄ True, λ™μΌν• λ¨λΈ κµ¬μ¶•ν•¨μλ΅ νƒμƒ‰ μ§„ν–‰ν•λ©΄ False

 )
```


```python
#search_space_summary() λ§¤μ„λ“λ΅ νƒμƒ‰ κ³µκ°„μ μ”μ•½ μ •λ³΄ μ¶λ ¥
tuner.search_space_summary()
```

    Search space summary
    Default search space size: 2
    units (Int)
    {'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': None}
    optimizer (Choice)
    {'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}


μ΄μ  νƒμƒ‰μ„ μ‹μ‘ν•΄λ³΄μ. κ²€μ¦ λ°μ΄ν„°λ¥Ό μ „λ‹¬ν•λ” κ²ƒμ„ μμ§€ λ§μ•„μ•Ό ν•κ³ , ν…μ¤νΈ μ„ΈνΈλ¥Ό κ²€μ¦μ— μ‚¬μ©ν•΄μ„λ” μ•λλ‹¤. κ·Έλ ‡μ§€ μ•μΌλ©΄ ν…μ¤νΈ λ°μ΄ν„°μ— κ³Όλ€μ ν•©λκΈ° μ‹μ‘ν•΄μ„ λ” μ΄μƒ ν…μ¤νΈ κ²°κ³Όλ¥Ό μ‹ λΆ°ν•  μ μ—†κ² λλ‹¤.


```python
(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()
x_train = x_train.reshape((-1,28*28)).astype('float32') / 255
x_test = x_test.reshape((-1,28*28)).astype('float32') / 255
x_train_full = x_train[:]
y_train_full = y_train[:]

# κ²€μ¦ μ„ΈνΈ λ”°λ΅ λ–Όμ–΄ λ†“κΈ°
num_val_samples = 10000
x_train, x_val = x_train[:-num_val_samples],x_train[-num_val_samples:]
y_train, y_val = y_train[:-num_val_samples],y_train[-num_val_samples:]

# λ¨λΈλ§λ‹¤ μ—ν¬ν¬κ°€ μ–Όλ§λ‚ ν•„μ”ν•μ§€ λ¨λ¥΄κΈ° λ•λ¬Έμ— μ—ν¬ν¬λ¥Ό ν¬κ² μ§€μ •ν•κ³  EarlyStopping μ½λ°± μ‚¬μ©
callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)]

tuner.search(
    x_train, y_train,
    batch_size=128,
    epochs=100,
    validation_data=(x_val, y_val),
    callbacks=callbacks,
    verbose=2,
)
```


```python
''' *κ²°κ³Ό λ„μ¶μ— 1μ‹κ°„ 30λ¶„κ°€λ‰ κ±Έλ¦¬κΈ° λ•λ¬Έμ— μ΄ν›„ μ½”λ“λ“¤μ—μ„λ” λ―Έλ¦¬ λ„μ¶λ κ²°κ³Όκ°’ μ‚¬μ©*
κ²°κ³Ό μ¶μ² https://github.com/rickiepark/deep-learning-with-python-2nd/blob/main/chapter13_best-practices-for-the-real-world.ipynb'''
Trial 100 Complete [00h 00m 42s]
val_accuracy: 0.9745000004768372

Best val_accuracy So Far: 0.9764499962329865
Total elapsed time: 01h 21m 04s
INFO:tensorflow:Oracle triggered exit
```

μ„μ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ€ μ„ νƒ κ°€λ¥ν• μµμ…λ„ μ κ³  κ°€λ²Όμ΄ MNIST λ°μ΄ν„°λ΅ ν›λ ¨ν•κΈ° λ•λ¬Έμ— μ κ² κ±Έλ¦¬λ” νΈμ΄λ‹¤. μΌλ°μ μΈ νƒμƒ‰ κ³µκ°„κ³Ό λ°μ΄ν„°μ…‹μ—μ„λ” λ°¤μƒ λλ” λ©°μΉ μ— κ±Έμ³ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ΄ μν–‰λλ‹¤. νƒμƒ‰ κ³Όμ •μ— λ¬Έμ κ°€ μƒκΈ°λ©΄ μ–Έμ λ‚ λ‹¤μ‹ μ‹μ‘ν•  μ μλ‹¤. νλ„μ— overwrite=Falseλ¥Ό μ§€μ •ν•λ©΄ λ””μ¤ν¬μ— μ €μ¥λ νƒμƒ‰ λ΅κ·Έμ—μ„ μ΄μ–΄μ„ νƒμƒ‰μ„ μν–‰ν•λ‹¤.

νƒμƒ‰μ΄ λλ‚λ©΄ μµμƒμ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ„ ν™•μΈν•κ³  μ΄λ¥Ό μ‚¬μ©ν•΄μ„ μµμƒμ ν•μ΄νΌνλΌλ―Έν„°λ΅ κµ¬μ„±λ λ¨λΈμ„ λ‹¤μ‹ ν›λ ¨ν•λ‹¤.


```python
top_n = 4
# λ¨λΈ κµ¬μ¶• ν•¨μμ— μ „λ‹¬ν•  μ μλ” HyerParameters κ°μ²΄ λ¦¬μ¤νΈ λ°ν™
best_hps = tuner.get_best_hyperparameters(top_n) 
```

μµμƒμ λ¨λΈμ„ λ‹¤μ‹ ν›λ ¨ν•  λ•λ” κ²€μ¦ λ°μ΄ν„°λ΅ μ„±λ¥ ν‰κ°€ν•  ν•„μ”κ°€ μ—†κΈ° λ•λ¬Έμ— ν›λ ¨ λ°μ΄ν„°μ— κ²€μ¦ λ°μ΄ν„°λ¥Ό ν¬ν•¨ν•΄μ„ ν›λ ¨ν•λ” κ²ƒμ΄ μΆ‹μ„ μ μλ‹¤. κ²€μ¦ μ„ΈνΈλ¥Ό λ”°λ΅ λ³΄κ΄€ν•μ§€ μ•κ³  μ›λ³Έ MNIST ν›λ ¨ λ°μ΄ν„°λ¥Ό λ¨λ‘ μ‚¬μ©ν•΄μ„ μµμΆ… λ¨λΈμ„ ν›λ ¨ν•΄λ³Έλ‹¤.

ν•μ§€λ§ μ „μ²΄ ν›λ ¨ λ°μ΄ν„°μ—μ„ ν›λ ¨ν•κΈ° μ „μ— λ§μ§€λ§‰μΌλ΅ μ •ν•  νλΌλ―Έν„°κ°€ ν•λ‚ μλ‹¤. λ°”λ΅ ν›λ ¨ μ—ν¬ν¬ νμμ΄λ‹¤. νƒμƒ‰ν•  λ• EarlyStopping μ½λ°±μ patience κ°’μ„ λ‚®μ¶”λ©΄ λΉ„μ©μ„ μ μ•½ν•  μ μμ§€λ§ μµμ μ λ¨λΈμ΄ μ•„λ‹μλ„ μλ‹¤. μµμƒμ μ—ν¬ν¬ νμλ¥Ό μ°ΎκΈ° μ„ν•΄ κ²€μ¦ μ„ΈνΈλ¥Ό μ‚¬μ©ν•΄λ³΄μ.


```python
def get_best_epoch(hp):
  model = build_model(hp)
  callbacks = [
      keras.callbacks.EarlyStopping(
          monitor='val_loss',mode='min',patience=10) #patience κ°’ λ†’κ²
  ]
  history = model.fit(
      x_train , y_train,
      validation_data = (x_val,y_val),
      epochs = 100
      batch_size = 128,
      callbacks = callbacks)
  val_loss_per_epoch = history.histoty['val_loss']
  best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1
  print(f'μµμƒμ μ—ν¬ν¬: {best_epoch}')
  return best_epoch
```

λ§μ§€λ§‰μΌλ΅ λ” λ§μ€ λ°μ΄ν„°μ—μ„ ν›λ ¨ν•λ―€λ΅ μ „μ²΄ λ°μ΄ν„°μ…‹μ—μ„ μ΄ μ—ν¬ν¬ νμλ³΄λ‹¤ μ΅°κΈ λ” μ¤λ ν›λ ¨ν•λ‹¤.


```python
def get_best_trained_model(hp):
  best_epoch = get_best_epoch(hp)
  model.fit(
      x_train_full,y_train_full,
      batch_size=128, epochs = int(best_epoch*1.2)) # 20% λ” λ§μ€ λ°μ΄ν„°λ΅ ν›λ ¨
  return model

best_models = []
for hp in best_hps:
  model = get_best_trained_model(hp)
  model.evaluate(x_test,y_test)
  best_models.append(model)
```

#### 1.1.3 μ¬λ°”λ¥Έ κ²€μƒ‰ κ³µκ°„μ„ λ§λ“λ” κΈ°μ 
μ „μ²΄μ μΌλ΅ λ΄¤μ„ λ• ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”λ” μ–΄λ μ‘μ—…μ—μ„ μµκ³ μ λ¨λΈμ„ μ–»κ±°λ‚ λ¨Έμ‹ λ¬λ‹ κ²½μ—° λ€νμ—μ„ μ°μΉν•κΈ° μ„ν• κ°•λ ¥ν•  λ„κµ¬λ‹¤. ν•μ§€λ§ ν•μ΄νΌνλΌλ―Έν„° νλ‹μΌλ΅ λ¨λΈ μ•„ν‚¤ν…μ²μ [λ¨λ²” μ‚¬λ΅€](https://hamin-chang.github.io/convarch/)λ¥Ό λ€μ²΄ν•  μ μ—†λ‹¤. λ¨λ“  κ²ƒμ„ ν•μ΄νΌνλΌλ―Έν„°λ΅ μ„¤μ •ν•΄μ„ νλ„κ°€ μ°Ύλ„λ΅ ν•λ©΄ λ„λ¬΄ λ§μ€ λΉ„μ©μ΄ λ“ λ‹¤. κ·Έλ ‡κΈ° λ•λ¬Έμ— μ¬λ°”λ¥Έ νƒμƒ‰ κ³µκ°„μ„ μ„¤κ³„ν•  ν•„μ”κ°€ μλ‹¤. **ν•μ΄νΌνλΌλ―Έν„° νλ‹μ€ μλ™ν™”μ΄μ§€ λ§λ²•μ΄ μ•„λ‹λ‹¤.** 

ν•μ΄νΌνλΌλ―Έν„° νλ‹μ€ λ¨λΈ μ„¤μ •μ— λ€ν• κ²°μ •μ„ **λ―Έμ‹μ  κ²°μ •**(μΈµμ μ λ‹› κ°μλ¥Ό μ–Όλ§λ΅ ν•΄μ•Όν• κΉ?)μ—μ„ λ†’μ€ μμ¤€μ **μ•„ν‚¤ν…μ² κ²°μ •**(μ΄ λ¨λΈμ— μ”μ°¨ μ—°κ²°μ„ μ‚¬μ©ν•΄μ•Όν• κΉ?)μΌλ΅ λ°”κΏ€ μ μλ‹¤. λ―Έμ‹μ  κ²°μ •μ€ νΉμ • λ¨λΈμ΄λ‚ νΉμ • λ°μ΄ν„°μ…‹μ— λ”°λΌ λ‹¤λ¥΄μ§€λ§ κ³ μμ¤€ κ²°μ •μ€ μ—¬λ¬ μ‘μ—…κ³Ό λ°μ΄ν„°μ…‹μ— κ±Έμ³ μΌλ°ν™”κ°€ λ” μλλ‹¤. μλ¥Ό λ“¤μ–΄ κ±°μ λ¨λ“  μ΄λ―Έμ§€ λ¶„λ¥ λ¬Έμ λ” κ°™μ€ μΆ…λ¥μ νƒμƒ‰ κ³µκ°„ ν…ν”λ¦ΏμΌλ΅ ν’€ μ μλ‹¤.

μ΄λ° λ…Όλ¦¬λ¥Ό λ”°λΌ KerasTunerλ” μ΄λ―Έμ§€ λ¶„λ¥μ™€ κ°™μ΄ λ„“μ€ λ²”μ„λ¥Ό κ°€μ§„ λ¬Έμ μ— κ΄€ν•΄ **μ‚¬μ „μ— μ •μλ νƒμƒ‰ κ³µκ°„**μ„ μ κ³µν•λ‹¤. λ°μ΄ν„°λ¥Ό μ¶”κ°€ν•κ³  νƒμƒ‰μ„ μ‹¤ν–‰ν•λ©΄ κ½¤ λ†’μ€ μ„±λ¥μ λ¨λΈμ„ μ–»μ„ μ μλ‹¤. μλ¥Ό λ“¤μ–΄ kt.applications.HyerXceptionκ³Ό kt.applications.HyperResNetλ“±μ ν•μ΄νΌ λ¨λΈμ΄ μλ‹¤.

### 1.2 λ¨λΈ μ•™μƒλΈ”
**λ¨λΈ μ•™μƒλΈ”**μ€ κ°€μ¥ μΆ‹μ€ κ²°κ³Όλ¥Ό μ–»μ„ μ μλ” λ λ‹¤λ¥Έ κ°•λ ¥ν• κΈ°λ²•μ΄λ‹¤. μ•™μƒλΈ”μ€ μ—¬λ¬ κ°μ λ‹¤λ¥Έ λ¨λΈμ μμΈ΅μ„ ν•©μ³μ„ λ” μΆ‹μ€ μμΈ΅μ„ λ§λ“λ” κΈ°λ²•μΈλ°, μΊκΈ€ κ°™μ€ λ¨Έμ‹ λ¬λ‹ λ€νμ—μ„ μ°μΉμλ“¤μ΄ λ§μ΄ μ‚¬μ©ν•λ” κΈ°λ²•μ΄λ‹¤.

μ•™μƒλΈ”μ€ λ…λ¦½μ μΌλ΅ ν›λ ¨λ λ‹¤λ¥Έ μΆ…λ¥μ μ λ™μ‘ν•λ” λ¨λΈμ΄ κ°κΈ° λ‹¤λ¥Έ μ¥μ μ„ κ°€μ§€κ³  μλ‹¤λ” κ°€μ •μ„ λ°”νƒ•μΌλ΅ ν•λ‹¤. κ° λ¨λΈμ€ κ°μμ κ°€μ •(κ³ μ ν• λ¨λΈ κµ¬μ΅°μ™€ λλ¤ κ°€μ¤‘μΉ μ΄κΈ°ν™”)λ¥Ό μ΄μ©ν•κ³  κ°μμ κ΄€μ μΌλ΅ ν›λ ¨ λ°μ΄ν„°μ λ§¤λ‹ν΄λ“λ¥Ό μ΄ν•΄ν•λ‹¤. μ΄λ“¤μ κ΄€μ μ„ λ¨μΌλ©΄ λ°μ΄ν„°λ¥Ό ν›¨μ”¬ μ •ν™•ν•κ² λ¬μ‚¬ν•  μ μλ‹¤. λ¶„λ¥λ΅ μλ¥Ό λ“¤μ–΄λ³Έλ‹¤. λ¶„λ¥κΈ° μμΈ΅μ„ μ•™μƒλΈ”ν•κΈ° μ„ν•΄ ν•©μΉλ” κ°€μ¥ μ‰¬μ΄ λ°©λ²•μ€ μ¶”λ΅ ν•  λ• λ‚μ¤λ” μμΈ΅μ ν‰κ· μ„ λ‚΄λ” κ²ƒμ΄λ‹¤.


```python
preds_a = model_a.predict(x_val)
preds_b = model_b.predict(x_val)
preds_c = model_c.predict(x_val)
preds_d = model_d.predict(x_val)
final_preds = 0.25 * (preds_a + preds_b + preds_c + preds_d) 
```

ν•μ§€λ§ μ΄ λ°©μ‹μ€ λ¶„λ¥κΈ°λ“¤μ΄ μ–΄λμ •λ„ λΉ„μ·ν• μ„±λ¥μΌ λ• μ μ‘λ™ν•λ‹¤. λ¶„λ¥κΈ° μ¤‘ ν•λ‚κ°€ λ‹¤λ¥Έ λ¨λΈλ³΄λ‹¤ μ›”λ“±ν λ‚μλ©΄ μµμΆ… μμΈ΅μ€ μ•™μƒλΈ”μ— μλ” κ°€μ¥ μΆ‹μ€ λ¶„λ¥κΈ°λ§νΌ μΆ‹μ§€ μ•μ„ μ μλ‹¤.

λ¶„λ¥κΈ°λ¥Ό μ•™μƒλΈ”ν•λ” λ” μΆ‹μ€ λ°©λ²•μ€ κ²€μ¦ λ°μ΄ν„°μ—μ„ ν•™μµλ κ°€μ¤‘μΉλ¥Ό μ‚¬μ©ν•΄μ„ κ°€μ¤‘ ν‰κ· ν•λ” κ²ƒμ΄λ‹¤. μ „ν•μ μΌλ΅ λ¶„λ¥κΈ°κ°€ μΆ‹μ„μλ΅ λ†’μ€ κ°€μ¤‘μΉλ¥Ό κ°€μ§€κ³  λ‚μ μλ΅ λ‚®μ€ κ°€μ¤‘μΉλ¥Ό κ°€μ§„λ‹¤. μΆ‹μ€ μ•™μƒλΈ” κ°€μ¤‘μΉλ¥Ό μ°ΎκΈ° μ„ν•΄ **λλ¤ μ„μΉ**λ‚ **λ„¬λ”-λ―Έλ“** μ•κ³ λ¦¬μ¦ κ°™μ€ μµμ ν™” μ•κ³ λ¦¬μ¦μ„ μ‚¬μ©ν•  μ μλ‹¤. μ΄λ” λ‹¤λ¥Έ κΈ€μ—μ„ λ‹¤λ¤„λ³΄λ„λ΅ ν•κ² λ‹¤.

λ‹¤μκ³Ό κ°™μ΄ κ°€μ¤‘ ν‰κ· μ„ λ‚΄λ©΄ λλ‹¤.


```python
preds_a = model_a.predict(x_val)
preds_b = model_b.predict(x_val)
preds_c = model_c.predict(x_val)
preds_d = model_d.predict(x_val)
final_preds = 0.5 * preds_a + 0.25 * preds_b + 0.1 * preds_c + 0.15 * preds_d
# κ°€μ¤‘μΉ (0.5,0.25,0.1,0.15)λ” μ•κ³ λ¦¬μ¦μΌλ΅ ν•™μµλ κ°€μ¤‘μΉ.
```

μ•™μƒλΈ”μ ν•µμ‹¬μ€ λ¶„λ¥κΈ°μ λ‹¤μ–‘μ„±μ΄λ‹¤. λ¨λ“  λ¨λΈμ΄ κ°™μ€ λ°©ν–¥μ„ νΈν–¥λμ–΄ μλ‹¤λ©΄ μ•™μƒλΈ”μ κ²°κ³Όλ„ λ™μΌν• νΈν–¥μ„ μ μ§€ν•  κ²ƒμ΄λ‹¤. λ¨λΈλ“¤μ΄ μ„λ΅ λ‹¤λ¥Έ λ°©ν–¥μΌλ΅ νΈν–¥λμ–΄ μλ‹¤λ©΄ νΈν–¥μ€ μ„λ΅ μƒμ‡„λΌκ³  μ•™μƒλΈ”μ΄ λ” κ²¬κ³ ν•κ³  μ •ν™•ν•΄μ§„λ‹¤. 

κΈ°νκ°€ λλ‹¤λ©΄ μ•™μƒλΈ” λ¨λΈμ— λ€ν•΄μ„λ” λ‹¤λ¥Έ κΈ€μ—μ„ λ‹¤λ¤„λ³΄κ² λ‹¤.

[<μΌ€λΌμ¤ μ°½μ‹μμ—κ² λ°°μ°λ” λ”¥λ¬λ‹ κ°μ • 2ν>(κΈΈλ²—, 2022)μ„ ν•™μµν•κ³  κ°μΈ ν•™μµμ©μΌλ΅ μ •λ¦¬ν• λ‚΄μ©μ…λ‹λ‹¤.] μ¶μ²: ν”„λ‘μ†μ™€ μ„λ  μ§€μ, βμΌ€λΌμ¤ μ°½μ‹μμ—κ² λ°°μ°λ” λ”¥λ¬λ‹ κ°μ •2νβ, λ°•ν•΄μ„  μ®κΉ€, κΈΈλ²—, 2022 λ„μ„λ³΄κΈ°: https://www.gilbut.co.kr/book/view?bookcode=BN003496
