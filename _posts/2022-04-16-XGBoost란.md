---
layout: single
title:  "XGBoost란"
categories: ML
tag: [XGBoost]
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: false
---
["출처: https://dacon.io/competitions/open/235698/talkboard/404176"](https://dacon.io/competitions/open/235698/talkboard/404176)
{: .notice--danger}


# XGBoost란

XGBoost는 Extreme Gradient Boosting의 약자입니다. 

Boosting 기법을 이용하여 구현한 알고리즘은 Gradient Boost가 대표적.

이 알고리즘을 병렬 학습이 지원되도록 구현한 라이브러리가 XGBoost이다.

Regression, Classification 문제를 모두 지원하며, 성능과 자원 효율이 좋아서, 인기 있게 사용되는 알고리즘 입니다.



여기서 Boosting이란, 여러개의 성능이 높지 않은 모델을 조합해서 사용하는 앙상블 기법중 하나입니다.

성능이 낮은 예측 모형들의 학습 에러에 가중치를 두고, 순차적으로 다음 학습 모델에 반영하여 강한 예측모형을 만듭니다. 아래 그림은 boosting 모델의 학습 예시 입니다.

![png](/assets/images/220416/Boosting.jpg)


## XGBoost의 장점

- 기존 boosting 모델 대비 빠른 수행시간(병렬 처리)
- 과적합 규제 지원(Regularization)
- 분류와 회귀 task 에서 높은 예측 성능
- Early Stopping(조기 종료) 기능 제공.
- 다양한 옵션을 제공해 Customizing이 용이.
- 결측치를 내부적으로 처리 함.
