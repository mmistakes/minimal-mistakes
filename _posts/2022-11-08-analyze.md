---
toc : true
title : '[DL/CV] ì»¨ë¸Œë„· í•´ì„ : ëª¨ë¸ì´ ë¬´ì—‡ì„ í•™ìŠµí–ˆëŠ”ê°€? ğŸ”'
layout : single
---

# 6. ì»¨ë¸Œë„·ì´ í•™ìŠµí•œ ê²ƒ í•´ì„í•˜ê¸°

---








### 6.0 ë“¤ì–´ê°€ë©°

ì‚¬ëŒë“¤ì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ 'ë¸”ë™ë°•ìŠ¤' ê°™ë‹¤ê³  ìì£¼ ì´ì•¼ê¸°í•œë‹¤. ëª¨ë¸ì´ í•™ìŠµí•œ í‘œí˜„ì„ ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë½‘ì•„ë‚´ëŠ” ê²ƒì´ ì–´ë µê¸° ë•Œë¬¸ì´ë‹¤. í•˜ì§€ë§Œ ì´ëŠ” ì»¨ë¸Œë„· ëª¨ë¸ì—ì„œëŠ” í‹€ë¦°ë§ì´ë‹¤. ì»¨ë¸Œë„·ì˜ í‘œí˜„ì€ ì‹œê°ì ì¸ ê°œë…ì„ í•™ìŠµí•œ ê²ƒì´ê¸° ë•Œë¬¸ì— ì‹œê°í™”ì— ìš©ì´í•˜ë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” ì»¨ë¸Œë„·ì˜ í‘œí˜„ë“¤ì„ ì‹œê°í™”í•˜ê³  í•´ì„í•˜ëŠ” ë‹¤ìŒì˜ ì„¸ê°€ì§€ ê¸°ë²•ì„ ì•Œì•„ë³´ê² ë‹¤. 





*   **ì»¨ë¸Œë„· ì¤‘ê°„ì¸µì˜ ì¶œë ¥ ì‹œê°í™”í•˜ê¸°** : ì—°ì†ëœ ì»¨ë¸Œë„· ì¸µì´ ì…ë ¥ì„ ì–´ë–»ê²Œ ë³€í˜•ì‹œí‚¤ëŠ”ì§€ ì´í•´í•˜ê³  ê°œë³„ì ì¸ í•„í„°ì˜ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ëŠ”ë° ë„ì›€ì´ ëœë‹¤.

*   **ì»¨ë¸Œë„· í•„í„° ì‹œê°í™”í•˜ê¸°** : ì»¨ë¸Œë„· í•„í„°ê°€ ì°¾ìœ¼ë ¤ëŠ” ì‹œê°ì ì¸ íŒ¨í„´ê³¼ ê°œë…ì´ ë¬´ì—‡ì¸ì§€ ìƒì„¸í•˜ê²Œ ì´í•´í•˜ëŠ”ë° ë„ì›€ì´ ëœë‹¤.

*   **í´ë˜ìŠ¤ í™œì„±í™”ì— ëŒ€í•œ íˆíŠ¸ë§µ(heatmap)ì„ ì´ë¯¸ì§€ì— ì‹œê°í™”í•˜ê¸°** : ì–´ë–¤ í´ë˜ìŠ¤ì— ì†í•˜ëŠ” ë° ì´ë¯¸ì§€ì˜ ì–´ëŠë¶€ë¶„ì´ ê¸°ì—¬í–ˆëŠ”ì§€ ì´í•´í•˜ê³  ì´ë¯¸ì§€ì—ì„œ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì¶”ì •í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤.



ì²«ë²ˆì§¸ í•­ëª©ë§Œ [ì´ì „ ê¸€](https://hamin-chang.github.io/small/)ì˜ ê°•ì•„ì§€ vs ê³ ì–‘ì´ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ë°‘ë°”ë‹¥ë¶€í„° í›ˆë ¨ì‹œí‚¨ ì‘ì€ ì»¨ë¸Œë„·ì„ ì‚¬ìš©í•˜ê³  , ë‹¤ë¥¸ ë‘ ê°€ì§€ í•­ëª©ì€ ì‚¬ì „ í›ˆë ¨ëœ Xception ëª¨ë¸ì„ ì‚¬ìš©í•˜ê² ë‹¤.



### 6.1 ì¤‘ê°„ í™œì„±í™” ì‹œê°í™”



ì¤‘ê°„ì¸µì˜ í™œì„±í™” ì‹œê°í™”ëŠ” ì–´ë–¤ ì…ë ¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ ëª¨ë¸ì— ìˆëŠ” ì—¬ëŸ¬ í•©ì„±ê³±ê³¼ í’€ë§ ì¸µì´ ë°˜í™˜í•˜ëŠ” ê°’ì„ ê·¸ë¦¬ëŠ” ê²ƒì´ë‹¤. (ì¸µì˜ ì¶œë ¥ì„ ì¢…ì¢… í™œì„±í™”ë¼ê³  ë¶€ë¥¸ë‹¤.) ì´ ë°©ë²•ì€ ë„¤íŠ¸ì›Œí¬ì— ì˜í•´ í•™ìŠµëœ í•„í„°ë“¤ì´ ì–´ë–»ê²Œ ì…ë ¥ì„ ë¶„í•´í•˜ëŠ”ì§€ ë³´ì—¬ì¤€ë‹¤. ë„ˆë¹„, ë†’ì´, ê¹Šì´(ì±„ë„) 3ê°œì˜ ì°¨ì›Œì— ëŒ€í•´ íŠ¹ì„± ë§µì„ ì‹œê°í™”í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤. ê° ì±„ë„ì€ ë¹„êµì  ë…ë¦½ì ì¸ íŠ¹ì„±ì„ ì¸ì½”ë”©í•˜ê¸° ë•Œë¬¸ì— íŠ¹ì„±ë§µì˜ ê° ì±„ë„ ë‚´ìš©ì„ ë…ë¦½ì ì¸ 2D ì´ë¯¸ì§€ë¡œ ê·¸ë¦¬ëŠ” ê²ƒì´ ì¢‹ì€ ë°©ë²•ì´ë‹¤. [ì´ì „ ê¸€](https://hamin-chang.github.io/small/)ì—ì„œ ì €ì¥í–ˆë˜ ëª¨ë¸ì„ ë¡œë“œí•´ì„œ ì‹œì‘í•œë‹¤.



```python

# ì´ì „ ê¸€ì—ì„œ ëª¨ë¸ ì €ì¥ ì•ˆí–ˆë‹¤ë©´ ì´ ì½”ë“œ ì‚¬ìš©í•´ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
!wget https://github.com/rickiepark/deep-learning-with-python-2nd/raw/main/convnet_from_scratch_with_augmentation.keras

from tensorflow import keras
model = keras.models.load_model("convnet_from_scratch_with_augmentation.keras")
```

```
--2022-11-07 03:06:02--  https://github.com/rickiepark/deep-learning-with-python-2nd/raw/main/convnet_from_scratch_with_augmentation.keras
Resolving github.com (github.com)... 20.205.243.166
Connecting to github.com (github.com)|20.205.243.166|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/deep-learning-with-python-2nd/main/convnet_from_scratch_with_augmentation.keras [following]
--2022-11-07 03:06:03--  https://raw.githubusercontent.com/rickiepark/deep-learning-with-python-2nd/main/convnet_from_scratch_with_augmentation.keras
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 7994528 (7.6M) [application/octet-stream]
Saving to: â€˜convnet_from_scratch_with_augmentation.kerasâ€™

convnet_from_scratc 100%[===================>]   7.62M  --.-KB/s    in 0.04s   

2022-11-07 03:06:04 (181 MB/s) - â€˜convnet_from_scratch_with_augmentation.kerasâ€™ saved [7994528/7994528]

```

```python
model.summary()
```

```
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 180, 180, 3)]     0         
                                                                 
 sequential (Sequential)     (None, 180, 180, 3)       0         
                                                                 
 rescaling_1 (Rescaling)     (None, 180, 180, 3)       0         
                                                                 
 conv2d_11 (Conv2D)          (None, 178, 178, 32)      896       
                                                                 
 max_pooling2d_6 (MaxPooling  (None, 89, 89, 32)       0         
 2D)                                                             
                                                                 
 conv2d_12 (Conv2D)          (None, 87, 87, 64)        18496     
                                                                 
 max_pooling2d_7 (MaxPooling  (None, 43, 43, 64)       0         
 2D)                                                             
                                                                 
 conv2d_13 (Conv2D)          (None, 41, 41, 128)       73856     
                                                                 
 max_pooling2d_8 (MaxPooling  (None, 20, 20, 128)      0         
 2D)                                                             
                                                                 
 conv2d_14 (Conv2D)          (None, 18, 18, 256)       295168    
                                                                 
 max_pooling2d_9 (MaxPooling  (None, 9, 9, 256)        0         
 2D)                                                             
                                                                 
 conv2d_15 (Conv2D)          (None, 7, 7, 256)         590080    
                                                                 
 flatten_3 (Flatten)         (None, 12544)             0         
                                                                 
 dropout (Dropout)           (None, 12544)             0         
                                                                 
 dense_3 (Dense)             (None, 1)                 12545     
                                                                 
=================================================================
Total params: 991,041
Trainable params: 991,041
Non-trainable params: 0
_________________________________________________________________
```
ì´ ë„¤íŠ¸ì›Œí¬ë¥¼ í›ˆë ¨í•  ë•Œ ì‚¬ìš©í–ˆë˜ ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ê³ ì–‘ì´ ì‚¬ì§„ í•˜ë‚˜ë¥¼ ì…ë ¥ ì´ë¯¸ì§€ë¡œ ì„ íƒí•œë‹¤.



```python
from tensorflow import keras
import numpy as np

img_path = keras.utils.get_file(  # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    fname="cat.jpg",
    origin="https://img-datasets.s3.amazonaws.com/cat.jpg")

def get_img_array(img_path, target_size):
  img = keras.utils.load_img(   # ì´ë¯¸ì§€ íŒŒì¼ì„ ë¡œë“œí•˜ê³  í¬ê¸°ë¥¼ ë³€ê²½
      img_path, target_size=target_size)
  array = keras.utils.img_to_array(img) # ì´ë¯¸ì§€ë¥¼ (180,180,3) í¬ê¸°ì˜ float32 ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
  array = np.expand_dims(array,axis=0) # ë°°ì—´ì„ ë‹¨ì¼ ì´ë¯¸ì§€ ë°°ì¹˜ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ ì°¨ì›ì¶”ê°€í•´ì„œ (1,180,180,3)ìœ¼ë¡œ ë³€í™˜
  return array

img_tensor = get_img_array(img_path,target_size=(180,180))
```

```
Downloading data from https://img-datasets.s3.amazonaws.com/cat.jpg
80329/80329 [==============================] - 0s 6us/step
```

```python
# ì´ë¯¸ì§€ ì¶œë ¥ ì½”ë“œ
import matplotlib.pyplot as plt

plt.axis('off')
plt.imshow(img_tensor[0].astype('uint8'))
plt.show()
```


![int0](https://user-images.githubusercontent.com/77332628/200586529-92333d4a-e70b-4374-a0d3-eea2c57552a9.png)



ì‹œê°í™”í•˜ê³  ì‹¶ì€ íŠ¹ì„± ë§µì„ ì¶”ì¶œí•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ ëª¨ë“  í•©ì„±ê³±ê³¼ í’€ë§ ì¸µì˜ í™œì„±í™”ë¥¼ ì¶œë ¥í•˜ëŠ” ì¼€ë¼ìŠ¤ ëª¨ë¸ì„ êµ¬ì¶•í•œë‹¤.



```python
from tensorflow.keras import layers

layer_outputs = []
layer_names = []
for layer in model.layers:
  if isinstance(layer,(layers.Conv2D,layers.MaxPooling2D)):
    layer_outputs.append(layer.output) # ëª¨ë“  Conv2Dì™€ MaxPooling2D ì¸µì˜ ì¶œë ¥ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    layer_names.append(layer.name) # ë‚˜ì¤‘ì„ ìœ„í•´ ì¸µ ì´ë¦„ ì €ì¥

#ëª¨ë¸ ì…ë ¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ ì¸µì˜ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ëª¨ë¸ êµ¬ì¶•
activation_model = keras.Model(inputs=model.input,outputs=layer_outputs)
```

ì…ë ¥ ì´ë¯¸ì§€ê°€ ì£¼ì…ë˜ë©´ ì´ ëª¨ë¸ì€ ì›ë³¸ ëª¨ë¸ì˜ í™œì„±í™” ê°’ì„ ë°˜í™˜í•œë‹¤. ì´ ëª¨ë¸ì€ ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ë¡œ í•˜ë‚˜ì˜ ì…ë ¥ì¸µê³¼ ì¸µì˜ í™œì„±í™”(ì¶œë ¥)ë§ˆë‹¤ í•˜ë‚˜ì”© ì´ 9ê°œì˜ ì¶œë ¥ì„ ê°€ì§„ë‹¤.



```python
activations = activation_model.predict(img_tensor)
# ì¸µ í™œì„±í™”ë§ˆë‹¤ ë°°ì—´ í•˜ë‚˜ì”© ì´ 9ê°œì˜ ë„˜íŒŒì´ ë°°ì—´ë¡œ êµ¬ì„±ëœ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
```

```
1/1 [==============================] - 8s 8s/step
```
ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒ ì½”ë“œëŠ” ê³ ì–‘ì´ ì´ë¯¸ì§€ì— ëŒ€í•œ ì²« ë²ˆì§¸ í•©ì„±ê³± ì¸µì˜ í™œì„±í™” ê°’ì´ë‹¤.



```python
first_layer_activation = activations[0]
print(first_layer_activation.shape)
```

```
(1, 178, 178, 32)
```
ì´ í™œì„±í™”ëŠ” 32ê°œì˜ ì±„ë„ì„ ê°€ì§„ 178x178 í¬ê¸°ì˜ íŠ¹ì„± ë§µì´ë‹¤. ë‹¤ìŒ ì½”ë“œëŠ” ì›ë³¸ ëª¨ë¸ì˜ ì²«ë²ˆì§¸ ì¸µ í™œì„±í™” ì¤‘ì—ì„œ ë‹¤ì„¯ë²ˆì§¸ ì±„ë„ì„ ê·¸ë¦¬ëŠ” ì½”ë“œë‹¤.



```python
import matplotlib.pyplot as plt

plt.matshow(first_layer_activation[0,:,:,5], cmap ='viridis')
plt.show()
```

![int1](https://user-images.githubusercontent.com/77332628/200586629-0120135d-ce5b-4cad-9a94-a0e8b195a329.png)



ì´ì œ ë„¤íŠ¸ì›Œí¬ì˜ ëª¨ë“  í™œì„±í™”ë¥¼ ì‹œê°í™” í•´ë³´ê² ë‹¤. ê° ì¸µì˜ í™œì„±í™”ì— ìˆëŠ” ëª¨ë“  ì±„ë„ì„ ê·¸ë¦¬ê¸° ìœ„í•´ í•˜ë‚˜ì˜ í° ì´ë¯¸ì§€ ê·¸ë¦¬ë“œì— ì¶”ì¶œí•œ ê²°ê³¼ë¥¼ ë‚˜ë€íˆ ìŒ“ê² ë‹¤.



```python
images_per_row = 16 # ê·¸ë¦¬ë“œ í–‰ ê°œìˆ˜

# í™œì„±í™”ì™€ í•´ë‹¹ ì¸µ ì´ë¦„ì— ëŒ€í•´ ë£¨í”„ë¥¼ ìˆœíšŒí•œë‹¤. 
for layer_name, layer_activation in zip(layer_names, activations):
    n_features = layer_activation.shape[-1] # ì¸µ í™œì„±í™” í¬ê¸°ëŠ” (1,size,size,n_features)
    size = layer_activation.shape[1]
    n_cols = n_features // images_per_row # ê·¸ë¦¬ë“œ ì—´ ê°œìˆ˜
    display_grid = np.zeros(((size + 1) * n_cols - 1,  # ë¹ˆ ê·¸ë¦¬ë“œ ì¤€ë¹„
                             images_per_row * (size + 1) - 1))
    for col in range(n_cols):
        for row in range(images_per_row):
            channel_index = col * images_per_row + row
            channel_image = layer_activation[0, :, :, channel_index].copy() # í•˜ë‚˜ì˜ ì±„ë„(ë˜ëŠ” íŠ¹ì„±) ì´ë¯¸ì§€

            # ëª¨ë‘ 0ì¸ ì±„ë„ì€ ê·¸ëŒ€ë¡œ ë‘ê³ ,
            if channel_image.sum() != 0:
                channel_image -= channel_image.mean()
                channel_image /= channel_image.std()
                channel_image *= 64
                channel_image += 128
            
            # ì±„ë„ ê°’ì„ [0,255] ë²”ìœ„ë¡œ ì •ê·œí™”
            channel_image = np.clip(channel_image, 0, 255).astype("uint8")

            # ë¹ˆ ê·¸ë¦¬ë“œì— ì±„ë„ í–‰ë ¬ ì €ì¥
            display_grid[
                col * (size + 1): (col + 1) * size + col,
                row * (size + 1) : (row + 1) * size + row] = channel_image
    # ê·¸ë¦¬ë“œ ì¶œë ¥
    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.axis("off")
    plt.imshow(display_grid, aspect="auto", cmap="viridis")
```
![int2](https://user-images.githubusercontent.com/77332628/200586901-2ae738c9-d1a9-4a36-af95-2a19f3fa23c8.png)
![int3](https://user-images.githubusercontent.com/77332628/200586909-526dd1e3-9d87-4582-9d8e-5575f79ccb5c.png)
![int4](https://user-images.githubusercontent.com/77332628/200586914-c4a943f7-050a-4e8d-af2c-764b6270594c.png)
![int5](https://user-images.githubusercontent.com/77332628/200586920-ec35f8b4-ba0c-4e59-9194-31b694c7f0ce.png)
![int6](https://user-images.githubusercontent.com/77332628/200586923-f22eb51b-940f-4b15-9094-3b8b4e9654f6.png)
![int7](https://user-images.githubusercontent.com/77332628/200586926-1975f854-78eb-4cbe-a2c6-7b606b705305.png)
![int8](https://user-images.githubusercontent.com/77332628/200586973-50138a77-a945-4409-913a-9839ca50eca2.png)
![int9](https://user-images.githubusercontent.com/77332628/200586981-4cbbf0b3-5aec-4985-9fda-bd7181e4db71.png)
![int10](https://user-images.githubusercontent.com/77332628/200586984-8030763c-3598-462d-bd7f-330a46be4079.png)

ì¶œë ¥ëœ ì´ë¯¸ì§€ê°€ êµ‰ì¥íˆ ë§ì§€ë§Œ ë‹¤ìŒì˜ ëª‡ê°€ì§€ ì£¼ëª©í•  ë‚´ìš©ì´ ìˆë‹¤.





*   ì²«ë²ˆì§¸ ì¸µì€ ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ì—ì§€ ê°ì§€ê¸°ë¥¼ ëª¨ì•„ ë†“ì€ ê²ƒ ê°™ë‹¤. ì´ ë‹¨ê³„ì˜ í™”ë í™”ì—ì„œëŠ” ì´ˆê¸° ì´ë¯¸ì§€ì— ìˆëŠ” ê±°ì˜ ëª¨ë“  ì •ë³´ê°€ ìœ ì§€ëœë‹¤.

*   ì¸µì´ ê¹Šì–´ì§ˆìˆ˜ë¡ í™œì„±í™”ëŠ” ì ì  ë” ì¶”ìƒì ìœ¼ë¡œ ë˜ê³  ì‹œê°ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ì–´ë ¤ì›Œì§„ë‹¤. 'ê³ ì–‘ì´ ê·€'ì™€ 'ê³ ì–‘ì´ ëˆˆ'ê³¼ ê°™ì€ ê³ ìˆ˜ì¤€ ê°œë…ì„ ì¸ì½”ë”©í•˜ê¸° ì‹œì‘í•˜ê³ , ê¹Šì€ ì¸µì˜ í‘œí˜„ì€ ì´ë¯¸ì§€ì˜ ì‹œê°ì  ì½˜í…ì¸ ì— ê´€í•œ ì •ë³´ê°€ ì ì  ì¤„ì–´ë“¤ê³  ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ì— ê´€í•œ ì •ë³´ê°€ ì ì  ì¦ê°€í•œë‹¤.

*   ì¸µì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ë¹„ì–´ ìˆëŠ” í™œì„±í™”ê°€ ëŠ˜ì–´ë‚œë‹¤. ì²« ë²ˆì§¸ ì¸µì—ì„œëŠ” ê±°ì˜ ëª¨ë“  í•„í„°ê°€ ì…ë ¥ ì´ë¯¸ì§€ì— í™œì„±í™” ë˜ì—ˆì§€ë§Œ ì¸µì„ ì˜¬ë¼ê°€ë©´ì„œ í™œì„±í™”ë˜ì§€ ì•ŠëŠ” í•„í„°ë“¤ì´ ìƒê¸´ë‹¤. ì´ëŠ” í•„í„°ì— ì¸ì½”ë”©ëœ íŒ¨í„´ì´ ì…ë ¥ ì´ë¯¸ì§€ì— ë‚˜íƒ€ë‚˜ì§€ ì•Šì•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.



ê¹Šì€ ì¸µì˜ í™œì„±í™”ëŠ” íŠ¹ì • ì…ë ¥ì— ëŒ€í•œ ì‹œê°ì  ì •ë³´ëŠ” ì ì  ì¤„ê³ , íƒ€ê¹ƒì— ê´€í•œ ì •ë³´ëŠ” ì ì  ë” ì¦ê°€í•œë‹¤. ì‹¬ì¸µ ì‹ ê²½ë§ì€ ë°˜ë³µì ì¸ ë³€í™˜ì„ í†µí•´ ê´€ê³„ì—†ëŠ” ì •ë³´ë¥¼ ê±¸ëŸ¬ë‚´ê³  ìœ ìš©í•œ ì •ë³´ëŠ” ê°•ì¡°ë˜ê³  ê°œì„ ëœë‹¤(ì—¬ê¸°ì—ì„œëŠ” ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤). ì‚¬ëŒê³¼ ë™ë¬¼ì´ ì„¸ìƒì„ ì¸ì§€í•˜ëŠ” ë°©ì‹ì´ ì´ì™€ ë¹„ìŠ·í•˜ë‹¤. ë¬¼ì²´ì˜ êµ¬ì²´ì ì¸ ëª¨ì–‘ì„ ê¸°ì–µí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ìš°ë¦¬ ë‡ŒëŠ” ì‹œê°ì  ì…ë ¥ì—ì„œ ê´€ë ¨ì„±ì´ ì ì€ ìš”ì†Œë¥¼ í•„í„°ë§í•´ì„œ ê³ ìˆ˜ì¤€ ê°œë…ìœ¼ë¡œ ë³€í™˜í•œë‹¤.





### 6.2 ì»¨ë¸Œë„· í•„í„° ì‹œê°í™”í•˜ê¸°



ì»¨ë¸Œë„·ì´ í•™ìŠµí•œ í•„í„°ë¥¼ ì¡°ì‚¬í•˜ëŠ” ë˜ ë‹¤ë¥¸ ë°©ë²•ì€ ê° í•„í„°ê°€ ë°˜ì‘í•˜ëŠ” ì‹œê°ì  íŒ¨í„´ì„ ê·¸ë ¤ë³´ëŠ” ê²ƒì´ë‹¤. ë¹ˆ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ì‹œì‘í•´ì„œ íŠ¹ì • í•„í„°ì˜ ì‘ë‹µì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ ì»¨ë¸Œë„· ì…ë ¥ ì´ë¯¸ì§€ì— ê²½ì‚¬ ìƒìŠ¹ë²•ì„ ì ìš©í•œë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì…ë ¥ ì´ë¯¸ì§€ëŠ” ì„ íƒëœ í•„í„°ê°€ ìµœëŒ€ë¡œ ì‘ë‹µí•˜ëŠ” ì´ë¯¸ì§€ê°€ ë  ê²ƒì´ë‹¤.



ì´ë²ˆì—ëŠ” ImageNetì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ Xception ëª¨ë¸ì˜ í•„í„°ë¥¼ ì‚¬ìš©í•œë‹¤. ì „ì²´ ê³¼ì •ì€ ê°„ë‹¨í•˜ë‹¤. íŠ¹ì„± í•©ì„±ê³± ì¸µì˜ í•œ í•„í„° ê°’ì„ ìµœëŒ€í™”í•˜ëŠ” ì†ì‹¤í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³  ì´ í™œì„±í™” ê°’ì„ ìµœëŒ€í™”í•˜ê¸° ìœ„í•´ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ë³€ê²½í•˜ë„ë¡ í™•ë¥ ì  ê²½ì‚¬ ìƒìŠ¹ë²•ì„ ì‚¬ìš©í•œë‹¤. ì´ëŠ” GradientTape ê°ì²´ë¥¼ ì‚¬ìš©í•´ì„œ ì €ìˆ˜ì¤€ì˜ í›ˆë ¨ ë£¨í”„ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì´ë‹¤. ë¨¼ì € ImageNetì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•´ì„œ Xception ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì. 



```python
model = keras.applications.xception.Xception(
    weights = 'imagenet',
    include_top = False) # ë¶„ë¥˜ ì¸µì´ í•„ìš”ì—†ê¸° ë•Œë¬¸ì— ëª¨ë¸ì˜ ìƒë‹¨ë¶€ ì œì™¸
```

```
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5
83683744/83683744 [==============================] - 4s 0us/step
```
ìš°ë¦¬ëŠ” ì´ ëª¨ë¸ì˜ í•©ì„±ê³± ì¸µì¸ Conv2Dì™€ SeperableConv2D ì¸µì— ê´€ì‹¬ì´ ìˆê¸° ë•Œë¬¸ì— ì´ëŸ° ì¸µì˜ ì¶œë ¥ì„ ì–»ìœ¼ë ¤ë©´ ì´ë¦„ì„ ì•Œì•„ì•¼ í•œë‹¤. ê¹Šì´ ìˆœì„œëŒ€ë¡œ ì´ë¦„ì„ ì¶œë ¥í•˜ì.



```python
for layer in model.layers:
  if isinstance(layer,(keras.layers.Conv2D, keras.layers.SeparableConv2D)):
    print(layer.name)
```

```
block1_conv1
block1_conv2
block2_sepconv1
block2_sepconv2
conv2d
block3_sepconv1
block3_sepconv2
conv2d_1
block4_sepconv1
block4_sepconv2
conv2d_2
block5_sepconv1
block5_sepconv2
block5_sepconv3
block6_sepconv1
block6_sepconv2
block6_sepconv3
block7_sepconv1
block7_sepconv2
block7_sepconv3
block8_sepconv1
block8_sepconv2
block8_sepconv3
block9_sepconv1
block9_sepconv2
block9_sepconv3
block10_sepconv1
block10_sepconv2
block10_sepconv3
block11_sepconv1
block11_sepconv2
block11_sepconv3
block12_sepconv1
block12_sepconv2
block12_sepconv3
block13_sepconv1
block13_sepconv2
conv2d_3
block14_sepconv1
block14_sepconv2
```
Xception ëª¨ë¸ì€ ì—¬ëŸ¬ê°œì˜ í•©ì„±ê³± ì¸µì„ ë‹´ì€ ë¸”ë¡ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ SeperableConv2D ì¸µì˜ ì´ë¦„ì€ ëª¨ë‘ block6_sepconv1, block7_sepconv2ì™€ ê°™ì€ ì‹ì´ë‹¤.



ì´ì œ íŠ¹ì • ì¸µì˜ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ë‘ ë²ˆì§¸ ë³´ë¸, ì¦‰ íŠ¹ì„± ì¶”ì¶œ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì. í•¨ìˆ˜í˜• APIë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— Xception ì „ì²´ ì½”ë“œë¥¼ ë³µì‚¬í•  í•„ìš” ì—†ì´ í•œ ì¸µì˜ outputì„ ì¶”ì¶œí•´ì„œ ìƒˆ ëª¨ë¸ì— ì¬ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.



```python
layer_name = 'block3_sepconv1' # Xception í•©ì„±ê³± ê¸°ë°˜ì— ìˆëŠ” ë‹¤ë¥¸ ì¸µì˜ ì´ë¦„ìœ¼ë¡œ êµì²´ ê°€ëŠ¥
layer = model.get_layer(name = layer_name) # ê´€ì‹¬ ëŒ€ìƒì¸ ì¸µì˜ ê°ì²´

# ì…ë ¥ ì´ë¯¸ì§€ê°€ ì£¼ì–´ì¡Œì„ ë•Œ í•´ë‹¹ ì¸µì˜ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ëª¨ë¸ êµ¬ì¶•
feature_extractor = keras.Model(inputs=model.input,outputs=layer.output)
```

ì´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì–´ë–¤ ì…ë ¥ ë°ì´í„°ì—ì„œ ëª¨ë¸ì„ í˜¸ì¶œí•˜ë©´ ëœë‹¤.



```python
activation = feature_extractor(
    keras.applications.xception.preprocess_input(img_tensor)) 
```

íŠ¹ì„± ì¶”ì¶œ ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ì…ë ¥ ì´ë¯¸ì§€ê°€ ì¸µì˜ í•„í„°ë¥¼ ì–¼ë§ˆë‚˜ í™œì„±í™”í•˜ëŠ”ì§€ ì •í–¥í™”ëœ ìŠ¤ì¹¼ë¼ ê°’ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•´ë³¸ë‹¤. ì´ í•¨ìˆ˜ê°€ ê²½ì‚¬ ìƒìŠ¹ë²• ê³¼ì •ë„ì•ˆ ìµœëŒ€í™”í•  'ì†ì‹¤ í•¨ìˆ˜'ê°€ ëœë‹¤.



```python
import tensorflow as tf
# ì´ ì†ì‹¤ í•¨ìˆ˜ëŠ” ì´ë¯¸ì§€ í…ì„œì™€ í•„í„° ì¸ë±ìŠ¤(ì •ìˆ˜)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ 
def comput_loss(image,filter_index): 
  activation = feature_extractor(image)

  # ì†ì‹¤ì— ê²½ê³„ í”½ì…€ ì œì™¸ì‹œì¼œì„œ ê²½ê³„ì— ë‚˜íƒ€ëŠ” ë¶€ìˆ˜íš¨ê³¼ ì œì™¸
  filter_activation = activation[:,2:-2,2:-2,filter_index]

  # ì´ í•„í„°ì— ëŒ€í•œ í™œì„±í™” ê°’ í‰ê·  ë°˜í™˜
  return tf.reduce_mean(filter_activation)
```

GradientTapeì„ ì‚¬ìš©í•´ì„œ ê²½ì‚¬ ìƒìŠ¹ë²• ë‹¨ê³„ë¥¼ êµ¬í˜„í•œë‹¤. 



ê²½ì‚¬ ìƒìŠ¹ë²• ê³¼ì •ì„ ë¶€ë“œëŸ½ê²Œ í•˜ê¸° ìœ„í•´ì„œ ê·¸ë ˆë””ì–¸íŠ¸ í…ì„œë¥¼ L2 norm(í…ì„œì— ìˆëŠ” ê°’ì„ ì œê³±í•œ í•©ì˜ ì œê³±ê·¼)ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì •ê·œí™”í•´ì„œ ì…ë ¥ ì´ë¯¸ì§€ì— ì ìš©í•  ìˆ˜ì •ëŸ‰ì˜ í¬ê¸°ë¥¼ í•­ìƒ ì¼ì • ë²”ìœ„ ì•ˆì— ë†“ëŠ”ë‹¤.



```python
@tf.function # ì†ë„ í–¥ìƒ ìœ„í•´ ë°ì½”ë ˆì´í„° ì‚¬ìš©
def gradient_ascent_step(image,filter_index,learning_rate):
  with tf.GradientTape() as tape:
    tape.watch(image) # ì´ë¯¸ì§€ëŠ” í…ì„œí”Œë¡œ ë³€ìˆ˜ê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ëª…ì‹œì ìœ¼ë¡œ ì§€ì •

    # í˜„ì¬ ì´ë¯¸ì§€ê°€ í•„í„°ë¥¼ ì–¼ë§ˆë‚˜ í™œì„±í™”í•˜ëŠ”ì§€ ë‚˜íƒ€ë‚´ëŠ” ìŠ¤ì¹¼ë¼í•¨ìˆ˜ ê³„ì‚°
    loss = comput_loss(image,filter_index) 
  grads = tape.gradient(loss,image) # ì´ë¯¸ì§€ì— ëŒ€í•œ ì†ì‹¤ì˜ ê·¸ë ˆë””ì–¸íŠ¸ ê³„ì‚°
  grads = tf.math.l2_normalize(grads) # ê·¸ë ˆë””ì–¸íŠ¸ ì •ê·œí™” íŠ¸ë¦­ ì ìš©
  image += learning_rate * grads # í•„í„°ë¥¼ ë” ê°•í•˜ê²Œ í™œì„±í™”ì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ì´ë¯¸ì§€ ì´ë™
  return image # ë°˜ë³µ ë£¨í”„ì—ì„œ ì´ ìŠ¤í…ì„ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ì—…ë°ì´íŠ¸ëœ ì´ë¯¸ì§€ ë°˜í™˜
  
```

ì´ì œ ì¸µ ì´ë¦„ê³¼ í•„í„° ì¸ë±ìŠ¤ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³ , ì§€ì •ëœ í•„í„°ì˜ í™œì„±í™”ë¥¼ ìµœëŒ€í™”í•˜ëŠ” íŒ¨í„´ì„ ë‚˜íƒ€ë‚´ëŠ” í…ì„œë¥¼ ë°˜í™˜í•˜ëŠ” íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ ë§Œë“ ë‹¤.



```python
img_width = 200
img_height = 200
def generate_filter_pattern(filter_index):
  iterations = 30 # ê²½ì‚¬ ìƒìŠ¹ë²• ì ìš© íšŸìˆ˜
  learning_rate = 10. # í•™ìŠµë¥ 

  # ëœë¤í•œ ê°’ìœ¼ë¡œ ì´ë¯¸ì§€ í…ì„œ ì´ˆê¸°í™”
  image = tf.random.uniform(
      minval = 0.4,
      maxval = 0.6,
      shape = (1,img_width,img_height,3))
  
  # ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœëŒ€í™”í•˜ë„ë¡ ì´ë¯¸ì§€ í…ì„œ ê°’ì„ ë°˜ë³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸
  for i in range(iterations):
    image = gradient_ascent_step(image,filter_index,learning_rate)
  
  return image[0].numpy()
```

ê²°ê³¼ ì´ë¯¸ì§€ í…ì„œëŠ” (200,200,3) í¬ê¸°ì˜ ë¶€ë™ ì†Œìˆ˜ì  í…ì„œì´ë‹¤. ì´ í…ì„œê°’ì€ [0,255] ì‚¬ì´ì˜ ì •ìˆ˜ê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì¶œë ¥ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ í›„ì²˜ë¦¬ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ í•´ì¤€ë‹¤.



```python
def deprocess_image(image):
    image -= image.mean()
    image /= image.std()
    image *= 64
    image += 128
    image = np.clip(image, 0, 255).astype("uint8")
    image = image[25:-25, 25:-25, :] # ë¶€ìˆ˜ íš¨ê³¼ í”¼í•˜ê¸° ìœ„í•´ ê²½ê³„ í”½ì…€ ì œì™¸
    return image
```

ì´ì œ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ë³´ì.



```python
plt.axis('off')
plt.imshow(deprocess_image(generate_filter_pattern(filter_index=2)))
plt.show()
```

![predown](https://user-images.githubusercontent.com/77332628/200587143-ac93437b-a02e-4262-b1d4-2d34df8c67a7.png)




block3_sepconv1 ì¸µì— ìˆëŠ” ì„¸ ë²ˆì§¸ í•„í„°ëŠ” ë¬¼ì´ë‚˜ í„¸ ê°™ì€ ìˆ˜í‰ íŒ¨í„´ì— ë°˜ì‘í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.



ë‹¤ìŒì€ êµ‰ì¥íˆ í¥ë¯¸ë¡œìš´ ë¶€ë¶„ì´ë‹¤. ì¸µì˜ ëª¨ë“  í•„í„°ë¥¼ ì‹œê°í™”í•˜ê±°ë‚˜ ëª¨ë¸ì— ìˆëŠ” ëª¨ë“  ì¸µì˜ í•„í„°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆë‹¤.



```python
# ì¸µì— ìˆëŠ” ì²˜ìŒ 64ê°œì˜ í•„í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ ì €ì¥
all_images = [] 
for filter_index in range(64):
  print(f'{filter_index}ë²ˆ í•„í„° ì²˜ë¦¬ì¤‘')
  image = deprocess_image(
      generate_filter_pattern(filter_index))
  all_images.append(image)

# í•„í„° ì‹œê°í™”ë¥¼ ì¶œë ¥í•œ ë¹ˆ ì´ë¯¸ì§€ ì¤€ë¹„
margin = 5 
n = 8
cropped_width = img_width - 25 * 2
cropped_height = img_height - 25 * 2
width = n * cropped_width + (n - 1) * margin
height = n * cropped_height + (n - 1) * margin
stitched_filters = np.zeros((width, height, 3))

# ì €ì¥ëœ í•„í„°ë¡œ ì´ë¯¸ì§€ ì±„ìš°ê¸°
for i in range(n):
    for j in range(n):
        image = all_images[i * n + j]
        stitched_filters[
            (cropped_width + margin) * i : (cropped_width + margin) * i + cropped_width,
            (cropped_height + margin) * j : (cropped_height + margin) * j
            + cropped_height,
            :,
        ] = image

keras.utils.save_img(
    f"filters_for_layer_{layer_name}.png", stitched_filters)
```

```
0ë²ˆ í•„í„° ì²˜ë¦¬ì¤‘
1ë²ˆ í•„í„° ì²˜ë¦¬ì¤‘
2ë²ˆ í•„í„° ì²˜ë¦¬ì¤‘
.
.
.
61ë²ˆ í•„í„° ì²˜ë¦¬ì¤‘
62ë²ˆ í•„í„° ì²˜ë¦¬ì¤‘
63ë²ˆ í•„í„° ì²˜ë¦¬ì¤‘
```
![block2](https://user-images.githubusercontent.com/77332628/200587247-bf1e9cf4-f710-444f-80a3-0607aed8dd9b.png)

block2 ì´ë¯¸ì§€



![block4](https://user-images.githubusercontent.com/77332628/200587256-53b61d88-f3fc-404c-ad05-c156c88e31fd.png)

block4 ì´ë¯¸ì§€


![block8](https://user-images.githubusercontent.com/77332628/200587276-df78523e-c2ab-4a45-9c29-7b5d5c86fea5.png)


block8 ì´ë¯¸ì§€



ì´ëŸ° í•„í„° ì‹œê°í™”ë¥¼ í†µí•´ ì»¨ë¸Œë„· ì¸µì´ ë°”ë¼ë³´ëŠ” ë°©ì‹ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤. ì»¨ë¸Œë„·ì˜ ê° ì¸µì€ í•„í„°ì˜ ì¡°í•©ìœ¼ë¡œ ì…ë ¥ì„ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ì¼ë ¨ì˜ íŒ¨í„´ì„ í•™ìŠµí•œë‹¤. ì´ ì»¨ë¸Œë„· í•„í„°ë“¤ì€ ëª¨ë¸ì˜ ì¸µì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ì ì  ë” ë³µì¡í•´ì§€ê³  ê°œì„ ëœë‹¤.



ìœ„ì˜ ì´ë¯¸ì§€ë“¤ì„ í†µí•´ì„œ ë‹¤ìŒì˜ ì‚¬ì‹¤ë“¤ì„ ì•Œ ìˆ˜ ìˆë‹¤.





*   ëª¨ë¸ì— ìˆëŠ” ì²« ë²ˆì§¸ ì¸µì˜ í•„í„°ëŠ” ê°„ë‹¨í•œ ëŒ€ê°ì„  ë°©í–¥ì˜ ì—ì§€ì™€ ìƒ‰ê¹”ì„ ì¸ì½”ë”©í•œë‹¤.

*   block4_sepconv1ê³¼ ê°™ì´ ì¡°ê¸ˆ ë” ë‚˜ì¤‘ì— ìˆëŠ” ì¸µì˜ í•„í„°ëŠ” ì—ì§€ë‚˜ ìƒ‰ê¹”ì˜ ì¡°í•©ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ê°„ë‹¨í•œ ì§ˆê°ì„ ì¸ì½”ë”©í•œë‹¤.

*   ë” ë’¤ì— ìˆëŠ” ì¸µì˜ í•„í„°ëŠ” ê¹ƒí„¸, ëˆˆ , ë‚˜ë­‡ì ë“± ìì—°ì ì¸ ì´ë¯¸ì§€ì—ì„œ ì°¾ì„ë²•í•œ ì§ˆê°ì„ ì ì  ë‹®ì•„ê°€ê¸° ì‹œì‘í•œë‹¤.



### 6.3 í´ë˜ìŠ¤ ì¶œë ¥ì˜ íˆíŠ¸ë§µ ì‹œê°í™”í•˜ê¸°



ë§ˆì§€ë§‰ìœ¼ë¡œ ì†Œê°œí•  ì‹œê°í™” ê¸°ë²•ì€ **í´ë˜ìŠ¤ í™œì„±í™” ë§µ(Class Activation Map, CAM) ì‹œê°í™”**ì´ë‹¤. ì´ ë°©ë²•ì€ ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•œ í´ë˜ìŠ¤ í™œì„±í™”ì˜ íˆíŠ¸ë§µì„ ë§Œë“œëŠ”ë°, í´ë˜ìŠ¤ í™œì„±í™” íˆíŠ¸ë§µì€ íŠ¹ì • ì¶œë ¥ í´ë˜ìŠ¤ì— ëŒ€í•´ ì…ë ¥ ì´ë¯¸ì§€ì˜ ëª¨ë“  ìœ„ì¹˜ë¥¼ ê³„ì‚°í•œ 2D ì ìˆ˜ ê·¸ë¦¬ë“œì´ë‹¤. í´ë˜ìŠ¤ì— ëŒ€í•´ ê° ìœ„ì¹˜ê°€ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ ì•Œë ¤ì¤€ë‹¤. ì´ ë°©ë²•ì€ ì´ë¯¸ì§€ì˜ ì–´ëŠ ë¶€ë¶„ì´ ì»¨ë¸Œë„·ì˜ ìµœì¢… ë¶„ë¥˜ ê²°ì •ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë¶„ë¥˜ì— ì‹¤ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ê²°ì • ê³¼ì •ì„ **'ë””ë²„ê¹…'**í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤. ë˜í•œ, ì´ë¯¸ì§€ì— íŠ¹ì • ë¬¼ì²´ê°€ ìˆëŠ” ìœ„ì¹˜ë¥¼ íŒŒì•…í•˜ëŠ” ë° ì‚¬ìš©í•˜ê¸°ë„ í•œë‹¤.



ì´ ê¸€ì—ì„œ ì‚¬ìš©í•  êµ¬ì²´ì ì¸ êµ¬í˜„ì€ "Grad-CAM : Visual Explanations from Deep Networks via Gradient-based Localization"ì— ê¸°ìˆ ë˜ì–´ ìˆëŠ” Grad-CAMì´ë‹¤. Grad-CAMì„ ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ë©´, **'ì…ë ¥ ì´ë¯¸ì§€ê°€ ê° ì±„ë„ì„ í™œì„±í™”í•˜ëŠ” ì •ë„'**ì— ëŒ€í•œ ê³µê°„ì ì¸ ë§µì„ **'í´ë˜ìŠ¤ì— ëŒ€í•œ ê° ì±„ë„ì˜ ì¤‘ìš”ë„'**ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ **'ì…ë ¥ ì´ë¯¸ì§€ê°€ í´ë˜ìŠ¤ë¥¼ í™œì„±í™”í•˜ëŠ” ì •ë„'**ì— ëŒ€í•œ ê³µê°„ì ì¸ ë§µì„ ë§Œë“œëŠ” ê²ƒì´ë¼ê³  ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.



ì‚¬ì „ í›ˆë ¨ëœ Xception ëª¨ë¸ì„ ë‹¤ì‹œ ì‚¬ìš©í•´ì„œ ì´ ê¸°ë²•ì„ ì‹œì—°í•´ë³´ê² ë‹¤.



```python
from tensorflow import keras
model = keras.applications.xception.Xception(weights='imagenet') # ìµœìƒìœ„ ë°€ì§‘ ì—°ê²° ì¸µ í¬í•¨
```

```
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5
91884032/91884032 [==============================] - 5s 0us/step
```
![elephant](https://user-images.githubusercontent.com/77332628/200587468-7a3bdbb6-1964-4ba3-9c94-3f9e1b52c916.jpg)



ìœ„ì˜ ì–´ë¯¸ì™€ ìƒˆë¼ ì½”ë¼ë¦¬ ì´ë¯¸ì§€ë¥¼ ì ìš©í•´ë³¸ë‹¤. Xception ëª¨ë¸ì€ 299x299 í¬ê¸°ì˜ ì´ë¯¸ì§€ì—ì„œ í›ˆë ¨ë˜ì—ˆê³ , keras.applications.xception.preprocess_input í•¨ìˆ˜ì— ë”°ë¼ ì „ì²˜ë¦¬ ë˜ì—ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì½”ë¼ë¦¬ ì´ë¯¸ì§€ë¥¼ 299x299 í¬ê¸°ë¡œ ë³€ê²½í•˜ê³  ë„˜íŒŒì´ float32 í…ì„œë¡œ ë°”ê¾¼ í›„ ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì ìš©í•´ì„œ Xception ëª¨ë¸ì´ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜í•œë‹¤.



```python
import numpy as np
# ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ, ê²½ë¡œ ì„¤ì •
img_path = keras.utils.get_file(
    fname="elephant.jpg",
    origin="https://img-datasets.s3.amazonaws.com/elephant.jpg")

def get_img_array(img_path,target_size):

  #299x299 í¬ê¸°ì˜ PIL ì´ë¯¸ì§€ ë°˜í™˜
  img = keras.utils.load_img(img_path,target_size=target_size)

  array = keras.utils.img_to_array(img) # (299,299,3) í¬ê¸°ì˜ float32 ë„˜íŒŒì´ ë°°ì—´ ë³€í™˜
  array = np.expand_dims(array,axis=0) # (1,299,299,3)ì˜ ë°°ì¹˜ ë³€í™˜ ìœ„í•´ ì°¨ì› ì¶”ê°€
  array = keras.applications.xception.preprocess_input(array) # ì „ì²˜ë¦¬ í•¨ìˆ˜ ì ìš©
  return array

img_array = get_img_array(img_path,target_size=(299,299))
```

ì´ì œ ë³€í™˜í•œ ì´ë¯¸ì§€ì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‹¤í–‰í•˜ê³  ì˜ˆì¸¡ ë²¡í„°ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ë””ì½”ë”©í•œë‹¤.



```python
preds = model.predict(img_array)
print(keras.applications.xception.decode_predictions(preds,top=3)[0])
```

```
1/1 [==============================] - 9s 9s/step
Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json
35363/35363 [==============================] - 0s 0us/step
[('n02504458', 'African_elephant', 0.8699264), ('n01871265', 'tusker', 0.076968774), ('n02504013', 'Indian_elephant', 0.023537323)]
```
ì´ ì´ë¯¸ì§€ì— ëŒ€í•œ ìƒìœ„ 3ê°œì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.





1.   ì•„í”„ë¦¬ì¹´ ì½”ë¼ë¦¬ : 87% í™•ë¥ 

2.   ì½”ë¼ë¦¬ : 8% í™•ë¥ 

3.   ì¸ë„ ì½”ë¼ë¦¬ : 2% í™•ë¥ 



ì´ ë„¤íŠ¸ì›Œí¬ëŠ” ì´ë¯¸ì§€ê°€ ì•„í”„ë¦¬ì¹´ ì½”ë¼ë¦¬ë¥¼ ë‹´ê³  ìˆë‹¤ê³  ì¸ì‹í–ˆë‹¤.






```python
np.argmax(preds[0]) 
```

```
386
```
ì˜ˆì¸¡ ë²¡í„°ì—ì„œ ìµœëŒ€ë¡œ í™œì„±í™”ëœ í•­ëª©ì€ 'ì•„í”„ë¦¬ì¹´ ì½”ë¼ë¦¬' í´ë˜ìŠ¤ì— ëŒ€í•œ ê²ƒìœ¼ë¡œ 386ë²ˆ ì¸ë±ìŠ¤ì´ë‹¤.



ì´ë¯¸ì§€ì—ì„œ ê°€ì¥ ì•„í”„ë¦¬ì¹´ ì½”ë¼ë¦¬ì™€ ê°™ì€ ë¶€ìœ„ë¥¼ ì‹œê°í™”í•˜ê¸° ìœ„í•´ Grad-CAM ì²˜ë¦¬ ê³¼ì •ì„ êµ¬í˜„í•œë‹¤.



ë¨¼ì €, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µì˜ í™œì„±í™”ì— ë§¤í•‘í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•œë‹¤.



```python
last_conv_layer_name = 'block14_sepconv2_act'
classifier_layer_names = ['avg_pool','predictions']
last_conv_layer = model.get_layer(last_conv_layer_name)
last_conv_layer_model = keras.Model(model.inputs,last_conv_layer.output)
```

ê·¸ë‹¤ìŒ ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µì˜ í™œì„±í™”ë¥¼ ìµœì¢… í´ë˜ìŠ¤ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•œë‹¤.



```python
classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])
x = classifier_input
for layer_name in classifier_layer_names:
  x = model.get_layer(layer_name)(x)
classifier_model = keras.Model(classifier_input,x)
```

ê·¸ë‹¤ìŒ ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µì˜ í™œì„±í™”ì— ëŒ€í•œ ìµœìƒìœ„ ì˜ˆì¸¡ í´ë˜ìŠ¤ì˜ ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•œë‹¤.



```python
import tensorflow as tf

with tf.GradientTape() as tape:
  # ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µì˜ í™œì„±í™”ë¥¼ ê³„ì‚°í•˜ê³  GradientTapeë¡œ ê°ì‹œ
  last_conv_layer_output = last_conv_layer_model(img_array)
  tape.watch(last_conv_layer_output)

  # ìµœìƒìœ„ ì˜ˆì¸¡ í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” í™œì„±í™” ì±„ë„ ì¶”ì¶œ
  preds = classifier_model(last_conv_layer_output)
  top_pred_index = tf.argmax(preds[0])
  top_class_channel = preds[:,top_pred_index]

# ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µì˜ ì¶œë ¥ íŠ¹ì„±ë§µì— ëŒ€í•œ ìµœìƒìœ„ ì˜ˆì¸¡ í´ë˜ìŠ¤ì˜ ê·¸ë ˆë””ì–¸íŠ¸ ê³„ì‚°
grads = tape.gradient(top_class_channel,last_conv_layer_output)
```

ì´ì œ ê·¸ë ˆë””ì–¸íŠ¸ í…ì„œë¥¼ í‰ê· í•˜ê³  ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•´ì„œ í´ë˜ìŠ¤ í™œì„±í™” íˆíŠ¸ë§µì„ ë§Œë“¤ì–´ë³´ì.



```python
'''ì´ ë²¡í„°ì˜ ê° ì›Œì†ŒëŠ” ì–´ë–¤ ì±„ë„ì— ëŒ€í•œ ê·¸ë ˆë””ì–¸íŠ¸ì˜ í‰ê·  ê°•ë„ì´ê³ , 
ìµœìƒìœ„ ì˜ˆì¸¡ í´ë˜ìŠ¤ì— ëŒ€í•œ ê° ì±„ë„ì˜ ì¤‘ìš”ë„ë¥¼ ì •ëŸ‰í™”'''
pooled_grads = tf.reduce_mean(grads,axis=(0,1,2)).numpy()
last_conv_layer_output = last_conv_layer_output.numpy()[0]

# ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µì˜ ì¶œë ¥ì— ìˆëŠ” ê° ì±„ë„ì— 'ì±„ë„ì˜ ì¤‘ìš”ë„'ë¥¼ ê³±í•¨
for i in range(pooled_grads.shape[-1]):
  last_conv_layer_output[:,:,i] *= pooled_grads[i]

# ë§Œë“¤ì–´ì§„ íŠ¹ì„± ë§µì„ ì±„ë„ë³„ë¡œ í‰ê· í•˜ë©´ í´ë˜ìŠ¤ í™œì„±í™” íˆíŠ¸ë§µì´ ëœë‹¤.
heatmap = np.mean(last_conv_layer_output,axis=-1)
```

ì‹œê°í™”ë¥¼ ìœ„í•´ íˆíŠ¸ë§µì„ 0,1 ì‚¬ì´ë¡œ ì •ê·œí™”í•œë‹¤. ìµœì¢… ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.



```python
from matplotlib import pyplot as plt
heatmap = np.maximum(heatmap,0)
heatmap /= np.max(heatmap)
plt.matshow(heatmap)
plt.show()
```

![heatmap](https://user-images.githubusercontent.com/77332628/200587559-a9d3b723-3e1a-4974-9040-1294b6e0ca3a.png)




ë§ˆì§€ë§‰ìœ¼ë¡œ ìœ„ì˜ íˆíŠ¸ë§µì— ì›ë³¸ ê·¸ë¦¼ì„ ê²¹ì¹œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë³¸ë‹¤.



```python
import matplotlib.cm as cm

img = keras.utils.load_img(img_path) # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
img = keras.utils.img_to_array(img)

heatmap = np.uint8(255*heatmap) # íˆíŠ¸ë§µ ë²”ìœ„ [0,255]ë¡œ ì¡°ì •

# 'jet' ì»¬ëŸ¬ë§µì„ ì‚¬ìš©í•´ì„œ íˆíŠ¸ë§µ ìƒ‰ ë³€ê²½
jet = cm.get_cmap('jet')
jet_colors = jet(np.arange(256))[:,:3]
jet_heatmap = jet_colors[heatmap]

# ìƒˆë¡œìš´ íˆíŠ¸ë§µì„ ë‹´ì„ ì´ë¯¸ì§€ ìƒì„±
jet_heatmap = keras.utils.array_to_img(jet_heatmap)
jet_heatmap = jet_heatmap.resize((img.shape[1],img.shape[0]))
jet_heatmap = keras.utils.img_to_array(jet_heatmap)

# íˆíŠ¸ë§µì— 40% íˆ¬ëª…ë„ ì ìš©í›„ ì›ë³¸ ì´ë¯¸ì§€ì™€ í•©ì¹¨
superimposed_img = jet_heatmap * 0.4 + img
superimposed_img = keras.utils.array_to_img(superimposed_img)

# í•©ì¹œ ì´ë¯¸ì§€ ì €ì¥
save_path = 'elephant_cam.jpg'
superimposed_img.save(save_path)
```

![elephant_cam](https://user-images.githubusercontent.com/77332628/200587628-cd6a54fd-b945-45e6-a30e-1e9187a02b40.jpg)



ì´ ì‹œê°í™” ê¸°ë²•ì€ 2ê°€ì§€ ì¤‘ìš”í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì¤€ë‹¤



* ì™œ ë„¤íŠ¸ì›Œí¬ê°€ ì´ ì´ë¯¸ì§€ì— ì•„í”„ë¦¬ì¹´ ì½”ë¼ë¦¬ê°€ ìˆë‹¤ê³  ìƒê°í•˜ëŠ”ê°€?

* ì•„í”„ë¦¬ì¹´ ì½”ë¼ë¦¬ê°€ ì‚¬ì§„ ì–´ë””ì— ìˆëŠ”ê°€?



ìœ„ì˜ ê²°ê³¼ë¬¼ ì‚¬ì§„ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, ìƒˆë¼ ì½”ë¼ë¦¬ì˜ ê·€ê°€ ê°•í•˜ê²Œ í™œì„±í™” ë˜ì—ˆëŠ”ë°, ì´ë¥¼ í†µí•´ì„œ ì•„ë§ˆ ë„¤íŠ¸ì›Œí¬ê°€ ì•„í”„ë¦¬ì¹´ ì½”ë¼ë¦¬ì™€ ì¸ë„ ì½”ë¼ë¦¬ë¥¼ êµ¬ë¶„í•œ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.


[<ì¼€ë¼ìŠ¤ ì°½ì‹œìì—ê²Œ ë°°ìš°ëŠ” ë”¥ëŸ¬ë‹ ê°œì • 2íŒ>(ê¸¸ë²—, 2022)ì„ í•™ìŠµí•˜ê³  ê°œì¸ í•™ìŠµìš©ìœ¼ë¡œ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.] ì¶œì²˜: í”„ë‘ì†Œì™€ ìˆ„ë ˆ ì§€ìŒ, âŒœì¼€ë¼ìŠ¤ ì°½ì‹œìì—ê²Œ ë°°ìš°ëŠ” ë”¥ëŸ¬ë‹ ê°œì •2íŒâŒŸ, ë°•í•´ì„  ì˜®ê¹€, ê¸¸ë²—, 2022 ë„ì„œë³´ê¸°: https://www.gilbut.co.kr/book/view?bookcode=BN003496

