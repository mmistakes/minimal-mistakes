---
title : "âš™ 5. ë¹„ìš© ìµœì†Œí™” êµ¬í˜„ - ì½”ë“œ"

categories:
    - Machinelearning
tags:
    - [AI, Regression, Cost]

toc : true
toc_sticky : true
use_math : true

date: 2022-01-17
last_modified_at: 2022-01-17
---  

* * *
ğŸ”¨ ì €ë²ˆ í¬ìŠ¤íŒ…ì—ì„œëŠ” ì„ í˜•íšŒê·€ë¥¼ ì§ì ‘ ì½”ë“œë¡œ ì‘ì„±í•´ë³´ì•˜ë‹¤. ì´ë²ˆì—ëŠ” ê·¸ ê²°ê³¼ ë‚˜ì˜¨ ë¹„ìš©ì„ ìµœì†Œí™”í•˜ëŠ” ì½”ë“œë¥¼ ì•Œì•„ë³´ì.
* * *

# 1. costí•¨ìˆ˜ / ë¹„ìš© êµ¬í•˜ê¸°
* * *

ğŸ”¨ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•˜ê³  X,Y ë°ì´í„°ë¥¼ ì •ì˜í•´ì£¼ì.

```py
import tensorflow as tf
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
%matplotlib inline

X = np.array([1,2,3])
Y = np.array([1,2,3])
```

## 1.1 íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•˜ê¸°

### 1.1.1. cost í•¨ìˆ˜ ë§Œë“¤ê¸°
* * *
ğŸ”¨ ë¹„ìš©í•¨ìˆ˜ : ì˜¤ì°¨ ì œê³±ì˜ í‰ê·   
<center>$$cost(W) = \frac{1}{m} \sum_{i=1}^m(Wx_i - y_i)^2$$</center>  

ğŸ”¨ ì›ì¹™ìƒ hypothesis í•¨ìˆ˜ëŠ” $H(x) = Wx + b$ ì˜ ëª¨ì–‘ì„ ê°€ì§€ì§€ë§Œ ì´ ê²½ìš°ì—ëŠ” ê°„ëµí™”ì‹œì¼œì„œ $H(x) = Wx$ ë¡œ ì•Œì•„ë³´ë„ë¡ í•˜ì.


```py
def cost_func(W,X,Y):
    c = 0
    for i in range(len(X)):
        c += np.square(W * X[i] - Y[i])
    return c / len(X)
```

### 1.1.2  ë¹„ìš© ê³„ì‚°í•˜ê¸°
* * *
```py
cost_values = []

# W ê°’ ì •ì˜ - np.linspace()ë¡œ 15ê°œì˜ W ê°’ì„ ì •ì˜
W_values = np.linspace(-3,5,num=15)
print("{:>6} | {:>10}".format("W","cost"))

# ë¯¸ë¦¬ ì •í•´ë‘” W ê°’ì— ë”°ë¼ costë¥¼ ì¶œë ¥
for feed_W in W_values:
    curr_cost = cost_func(feed_W, X, Y)
    cost_values.append(curr_cost)
    print("{:6.3f} | {:10.5f}".format(feed_W, curr_cost))
```
```
>>
     W |       cost
-3.000 |   74.66667
-2.429 |   54.85714
-1.857 |   38.09524
-1.286 |   24.38095
-0.714 |   13.71429
-0.143 |    6.09524
 0.429 |    1.52381
 1.000 |    0.00000
 1.571 |    1.52381
 2.143 |    6.09524
 2.714 |   13.71429
 3.286 |   24.38095
 3.857 |   38.09524
 4.429 |   54.85714
 5.000 |   74.66667
```

ğŸ”¨ Wê°€ 1ì¼ë•Œ costê°€ 0 ìœ¼ë¡œ ìµœì†Ÿê°’ì„ ê°€ì§€ëŠ” ê²ƒì„ í™•ì¸í•˜ì.  

```py
plt.figure(figsize = (10,10))
plt.plot(W_values, cost_values, "b")
plt.ylabel('Cost(W)')
plt.xlabel('W')
plt.show()
```

<p align="center"><img src="https://user-images.githubusercontent.com/65170165/149657232-a9761db4-9c81-4972-b691-879b6f89a70a.png" width="500" /></p>

ğŸ”¨ cost í•¨ìˆ˜ë¥¼ ì‹œê°í™”í•´ë³´ë©´ Wê°€ 1 ì¼ë•Œ ê¸°ìš¸ê¸°ê°€ 0 ì´ê³  cost í•¨ìˆ˜ê°€ ìµœì†Ÿê°’ 0ì„ ê°€ì§€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

## 1.2. Tensorflowë¡œ êµ¬í˜„í•˜ê¸°

```py
# X,Y ë°ì´í„° ì •ì˜
X = np.array([1,2,3])
Y = np.array([1,2,3])
print("{:>6} | {:>10}".format("W","cost"))

# ë¹„ìš©í•¨ìˆ˜ ìƒì„±
def cost_func_tf(W,X,Y):
    hypothesis = W*X
    return tf.reduce_mean(tf.square(hypothesis-Y))

# W ê°’ ì •ì˜ - np.linspace()ë¡œ 15ê°œì˜ W ê°’ì„ ì •ì˜
cost_values = []
W_values = np.linspace(-3,5,num=15)

# ë¯¸ë¦¬ ì •í•´ë‘” W ê°’ì— ë”°ë¼ costë¥¼ ì¶œë ¥
for feed_W in W_values:
    curr_cost = cost_func_tf(feed_W, X, Y)
    cost_values.append(curr_cost)
    print("{:6.3f} | {:10.5f}".format(feed_W, curr_cost))
```
```
>>
     W |       cost
-3.000 |   74.66667
-2.429 |   54.85714
-1.857 |   38.09524
-1.286 |   24.38095
-0.714 |   13.71429
-0.143 |    6.09524
 0.429 |    1.52381
 1.000 |    0.00000
 1.571 |    1.52381
 2.143 |    6.09524
 2.714 |   13.71429
 3.286 |   24.38095
 3.857 |   38.09524
 4.429 |   54.85714
 5.000 |   74.66667
```
```py
plt.figure(figsize = (10,10))
plt.plot(W_values, cost_values, "b")
plt.ylabel('Cost(W)')
plt.xlabel('W')
plt.show()
```
<p align="center"><img src="https://user-images.githubusercontent.com/65170165/149657232-a9761db4-9c81-4972-b691-879b6f89a70a.png" width="500" /></p>

ğŸ”¨ ê²°ê³¼ëŠ” íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•œ ê²°ê³¼ì™€ ë™ì¼í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

# 2. Gradient Descent
* * *

ğŸ”¨ <b>Hypothesis</b> <center>$$H(x) = Wx$$</center>  
ğŸ”¨ <b>Cost</b> <center>$$cost(W) = \frac{1}{m}\sum_{i=1}^m(Wx_i - y_i)^2$$</center>  
ğŸ”¨ <b>Gradient</b> <center>$$Gradient = \frac{1}{m} \sum_{i=1}^m (Wx_i - y_i) x_i$$ </center>  
ğŸ”¨ <b>Descent</b> <center>$$W := W - \alpha \frac{1}{m} \sum_{i=1}^m (Wx_i - y_i) x_i$$</center>
## 2.1. W ë¥¼ ì„ì˜ì˜ ë‚œìˆ˜ë¡œ ìƒì„±í•´ì„œ ì—…ë°ì´íŠ¸

```py
tf.random.set_seed(0)

X = np.array([1,2,3])
Y = np.array([1,2,3])
print("{:>5} | {:>10} | {:>10}".format("step", "cost", "W"))

# ë§¨ ì²˜ìŒ Wê°’ë§Œ ëœë¤í•¨ìˆ˜ë¡œ ì •ì˜
W = tf.Variable(tf.random.normal([1], -100., 100))

# W ê°’ 300 íšŒ ì—…ë°ì´íŠ¸ ì§„í–‰ 
for step in range(300):
    hypothesis = W * X
    cost = tf.reduce_mean(tf.square(hypothesis - Y))
    
    alpha = 0.01
    gradient = tf.reduce_mean(tf.multiply(hypothesis - Y, X))
    descent = W - tf.multiply(alpha, gradient)
    W.assign(descent)
    
    if step % 10 == 0:
        print("{:5} | {:10.4f} | {:10.6f}".format(step, cost.numpy(), W.numpy()[0]))
```
```
>>
 step |       cost |          W
    0 | 11716.3086 |  48.767971
   10 |  4504.9126 |  30.619968
   20 |  1732.1364 |  19.366755
   30 |   666.0052 |  12.388859
   40 |   256.0785 |   8.062004
   50 |    98.4620 |   5.379007
   60 |    37.8586 |   3.715335
   70 |    14.5566 |   2.683725
   80 |     5.5970 |   2.044044
   90 |     2.1520 |   1.647391
  100 |     0.8275 |   1.401434
  110 |     0.3182 |   1.248922
  120 |     0.1223 |   1.154351
  130 |     0.0470 |   1.095710
  140 |     0.0181 |   1.059348
  150 |     0.0070 |   1.036801
  160 |     0.0027 |   1.022819
  170 |     0.0010 |   1.014150
  180 |     0.0004 |   1.008774
  190 |     0.0002 |   1.005441
  200 |     0.0001 |   1.003374
  210 |     0.0000 |   1.002092
  220 |     0.0000 |   1.001297
  230 |     0.0000 |   1.000804
  240 |     0.0000 |   1.000499
  250 |     0.0000 |   1.000309
  260 |     0.0000 |   1.000192
  270 |     0.0000 |   1.000119
  280 |     0.0000 |   1.000074
  290 |     0.0000 |   1.000046
```

## 2.2. W ë¥¼ tf.Variable() ë¡œ ìƒì„±í•´ì„œ ì—…ë°ì´íŠ¸(1)

```py
X = np.array([1,2,3])
Y = np.array([1,2,3])
print("{:>5} | {:>10} | {:>10}".format("step", "cost", "W"))

# ë§¨ ì²˜ìŒ Wê°’ë§Œ ëœë¤í•¨ìˆ˜ë¡œ ì •ì˜
W = tf.Variable(5.0)

# W ê°’ 300 íšŒ ì—…ë°ì´íŠ¸ ì§„í–‰ 
for step in range(300):
    hypothesis = W * X
    cost = tf.reduce_mean(tf.square(hypothesis - Y))
    
    alpha = 0.01
    gradient = tf.reduce_mean(tf.multiply(hypothesis - Y, X))
    descent = W - tf.multiply(alpha, gradient)
    W.assign(descent)
    
    if step % 10 == 0:
        print("{:5} | {:10.4f} | {:10.6f}".format(step, cost.numpy(), W.numpy()))
```
```
>>
 step |       cost |          W
    0 |    74.6667 |   4.813334
   10 |    28.7093 |   3.364572
   20 |    11.0387 |   2.466224
   30 |     4.2444 |   1.909177
   40 |     1.6320 |   1.563762
   50 |     0.6275 |   1.349578
   60 |     0.2413 |   1.216766
   70 |     0.0928 |   1.134412
   80 |     0.0357 |   1.083346
   90 |     0.0137 |   1.051681
  100 |     0.0053 |   1.032047
  110 |     0.0020 |   1.019871
  120 |     0.0008 |   1.012322
  130 |     0.0003 |   1.007641
  140 |     0.0001 |   1.004738
  150 |     0.0000 |   1.002938
  160 |     0.0000 |   1.001822
  170 |     0.0000 |   1.001130
  180 |     0.0000 |   1.000700
  190 |     0.0000 |   1.000434
  200 |     0.0000 |   1.000269
  210 |     0.0000 |   1.000167
  220 |     0.0000 |   1.000103
  230 |     0.0000 |   1.000064
  240 |     0.0000 |   1.000040
  250 |     0.0000 |   1.000025
  260 |     0.0000 |   1.000015
  270 |     0.0000 |   1.000009
  280 |     0.0000 |   1.000006
  290 |     0.0000 |   1.000004
```

## 2.2. W ë¥¼ tf.Variable() ë¡œ ìƒì„±í•´ì„œ ì—…ë°ì´íŠ¸(2)

```py
cost_list = []
W_list = []

X = np.array([1,2,3])
Y = np.array([1,2,3])
print("{:>5} | {:>10} | {:>10}".format("step", "cost", "W"))

W = tf.Variable(30.0)

for step in range(300):
    hypothesis = W * X
    cost = tf.reduce_mean(tf.square(hypothesis - Y))
    
    alpha = 0.01
    gradient = tf.reduce_mean(tf.multiply(hypothesis - Y, X))
    descent = W - tf.multiply(alpha, gradient)
    W.assign(descent)
    
    W_list.append(W.numpy())
    cost_list.append(cost.numpy())
    if step % 10 == 0:
        print("{:5} | {:10.4f} | {:10.6f}".format(step, cost.numpy(), W.numpy()))
```
```
>>
 step |       cost |          W
    0 |  3924.6667 |  28.646667
   10 |  1509.0312 |  18.143147
   20 |   580.2216 |  11.630123
   30 |   223.0948 |   7.591529
   40 |    85.7798 |   5.087276
   50 |    32.9823 |   3.534438
   60 |    12.6817 |   2.571555
   70 |     4.8761 |   1.974490
   80 |     1.8749 |   1.604262
   90 |     0.7209 |   1.374691
  100 |     0.2772 |   1.232338
  110 |     0.1066 |   1.144068
  120 |     0.0410 |   1.089334
  130 |     0.0158 |   1.055394
  140 |     0.0061 |   1.034349
  150 |     0.0023 |   1.021299
  160 |     0.0009 |   1.013207
  170 |     0.0003 |   1.008190
  180 |     0.0001 |   1.005078
  190 |     0.0001 |   1.003149
  200 |     0.0000 |   1.001953
  210 |     0.0000 |   1.001211
  220 |     0.0000 |   1.000751
  230 |     0.0000 |   1.000466
  240 |     0.0000 |   1.000289
  250 |     0.0000 |   1.000179
  260 |     0.0000 |   1.000111
  270 |     0.0000 |   1.000069
  280 |     0.0000 |   1.000043
  290 |     0.0000 |   1.000026
```
ğŸ”¨ ì´ ì„ í˜•ëª¨ë¸ì„ ì‹œê°í™”í•´ì„œ cost í•¨ìˆ˜ì˜ ê°œí˜•ì„ ì•Œì•„ë³´ì.
```py
plt.figure(figsize = (10,12))
plt.plot(W_list, cost_list)
plt.ylabel('Cost(W)')
plt.xlabel('W')
plt.show()
```

<p align="center"><img src="https://user-images.githubusercontent.com/65170165/149665342-87e55303-1b52-4387-8739-4e06980b1fb1.png" width="500" /></p>

* * *

ğŸ”¨ ì´ë ‡ê²Œ í•´ì„œ ë¹„ìš©ì„ ìµœì†Œí™”í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ê¹Œì§€ êµ¬í˜„í•´ ë³´ì•˜ë‹¤. ìˆ˜ì‹ì„ ì•Œê³  ì½”ë“œë¡œ í‘œí˜„í•˜ëŠ” ë°©ë²•ë§Œ ì•Œë©´ ì´ë¦„ë§Œí¼ ê±°ì°½í•œ ë¶„ì•¼ëŠ” ì•„ë‹ ìˆ˜ë„ ìˆê² ë‹¤ëŠ” ìì‹ ê°ì´ ìƒê¸´ë‹¤ğŸ™ƒ!! ë¬¼ë¡  ê³µë¶€í•˜ë‹¤ ë³´ë©´ ë˜ ì´ëŸ° ìƒê°ì€ ì˜¨ë°ê°„ë° ì—†ê² ì§€ë§Œ ì´ë ‡ê²Œë¼ë„ ìì‹ ê°ì„ ë¶ë‹ì•„ì¤˜ì•¼ê² ë‹¤ã…
