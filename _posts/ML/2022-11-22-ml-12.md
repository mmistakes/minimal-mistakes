---
title:  "[ML] 2. 분류 알고리즘 - 로지스틱 회귀(Logistic Regression)"
layout: single

categories: "ML"
tags: ["분류 알고리즘", "로지스틱 회귀", "Cross-Entropy Loss"]

toc: true
toc_sticky: true
toc_label : "목차"
toc_icon: "bars"

published: false
---

<small>KNN을 활용하여 데이터를 분류할 수 있다.</small>

***

로지스틱 회귀 배경

- 다중선형회귀분석(Linear Regression)
목적 : 수치형 설명변수 X와 종속변수 Y간의 관계를 선형으로 가정하고 이를 가장 잘 표현할 수 있는 회귀 계수를 분석


y가 범주형 변수, classification 태스크에 대해서 해결하는선형 모형을 logistic regression

왜 ? logistic function이라는 변환함수를 사용하기 때문에 그렇게 부름
로지스틱 펑션을 사용하는 리니어 리그레션이라고 생각하면 됨


필요성
- 종속 변수의 속성이 이진 변수일 때(0 또는 1)
질문 : 확률값을 선형 회귀분석의 종속변수로 사용하는 것이 타당한가?
답변 : 선형회귀분석의 우변은 범위에 대한 제한이 없기 때문에 우변과 좌변의 범위가 다른 문제점이 발생함

ex 불량품 0 양품 1 높으면 1 낮으면 0 강아지 1 고양이 0 이런식으로 두개의 변수가 있을 때 하나는 0, 하나는 1로 대응시켜주는 것

https://ifh.cc/g/8ygtp5.png

적합시킨 결과가 y ~ 인데, 이렇게 예측하면 되는거 아닌ㄴ가라고 생각할 수 있지만 가정에는 문제가 좀 있음
일정 수준을 넘어가면 y가 계속 커짐
x가 커짐에 따라서 어떤 특정 클래스로 굉장히 수렴을해서 x가작아지면 어떤 클래스로 분류되는 확률이 줄어들고 그런 패턴을 원하는 것이지 y값이 무한정 커지는 패턴 원하는 건 아님
엑스가 커지면 오힟려 오차 mse 커짐

특정한 x1이 있는데 x1이면 예측 한거고그렇지 않은거에 대해서는 예측할수없어 큰의미없어 x가 특정 기준이상을 넘어ㅏㄱ면 오히려 오차가 커지면서 이거는 예측이 잘 안되는거야 라는 가정인데 이걸 원하는게 아님

특정 클래스로 분류될 확률,ㅡ 정도, 이 개념으로 모델링 해야 하기 떄문에
이방식이 적합하지 않다. (y= ~ )


예제
암진단 이진분류
진단 되었다 안되었다가 있는데 선형회귀 이용하면 의미없는 패턴 학습하게 됨
에이지 그룹을 나눠서 몇명의 사람이 존재하고 퍼센테이지 계산
그걸 그래프로 그리면 나이에 따라서 암진단의 분류 확률이 커지는 패턴, 수렴하는 패턴...

이런 형태를 모사해줄 수 있는 함수가 sigmoid 함수이다. logistic function 이라고 부르기도하고 sigmoid 함수라고 하는데

시그모이드 함수를 사용하면 0~1ㅅ가이의 값을예측하는 함수, 변환해주는 함수로 사용하기 좋음
함수 분류 확률 값을 잘 모델링할 수 있는 상황이 되었다.

분류 문제에서는 cross-entropy loss를 많이 사용함
해당 클래스로 분류되는 확률 값을 이 안에 넣어주게 되고 로그를 취해서 이 두개를 곱한다. ==> 분류가 잘 되었다 안되었다는 측정할 ㅅ ㅜ있음
https://ifh.cc/g/JNHh9m.png
이때 로그는 자연로드이다 (ln)

cross entropy loss minimize 해주면 미ㅏ이너스 때문에 해당 클래스로 류될 그 분류확률 값을 굉장히 높여준다. 높여주면 높여줄수록 큰ㅇ 값 나옴

로스를 작게해주면 실제 클래스로 분류될 확률이 최대화가 되는 그런 베타0 구할 수 있음

결과적으로 minimize 하는 게 결국에는 실제 클래스로 분류될 확률을 키워주는구나. 이거를 이해할 ㅅ ㅜ있음
