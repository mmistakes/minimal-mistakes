---
layout: single
title: "í…ìŠ¤íŠ¸ íƒì§€&ì¸ì‹ 2í¸"
permalink: /projects/pnid/05
tag: [Vision AI, Drawing]
author_profile: false
sidebar:
  nav: "docs1"
date: 2023-10-10
use_math: true
---

ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ ì˜ì—­ íƒì§€ì— ì´ì–´ ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” **íƒì§€ ì˜ì—­ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” ê¸°ìˆ **ì— ëŒ€í•´ ì†Œê°œë“œë¦½ë‹ˆë‹¤.

## ğŸ“‹ Table of Contents

1. [í…ìŠ¤íŠ¸ ì¸ì‹ ë°°ê²½](#1-í…ìŠ¤íŠ¸-ì¸ì‹-ë°°ê²½)
2. [í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì˜ í”„ë ˆì„ì›Œí¬ ë¶„ì„ ë° ì„¤ê³„](#2-í…ìŠ¤íŠ¸-ì¸ì‹-ëª¨ë¸ì˜-í”„ë ˆì„ì›Œí¬-ë¶„ì„-ë°-ì„¤ê³„)
3. [í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ êµ¬ì¶• ê³¼ì •](#3-í…ìŠ¤íŠ¸-ì¸ì‹-ëª¨ë¸-êµ¬ì¶•-ê³¼ì •)
4. [ê²°ë¡ ](#4-ê²°ë¡ )

## 1. í…ìŠ¤íŠ¸ ì¸ì‹ ë°°ê²½
OCR(Optical Character Recognition)ì€ ì¸ì‡„ëœ ê´‘í•™ ë¬¸ì ì´ë¯¸ì§€ë¥¼ ê¸°ê³„ê°€ ì½ì„ ìˆ˜ ìˆëŠ” ë””ì§€í„¸ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€ Real worldì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆì™€ ì™œê³¡ì´ ì„ì—¬ ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” STR(Scene Text Recognition)ë„ ë§ì€ ë°œì „ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ë“¤ì€ ë””ì§€í„¸ ì„œë¥˜ ì „í™˜, ê¸°ë°€ë¬¸ì„œ ë§ˆìŠ¤í‚¹, í‘œì§€íŒ ë° ê°„íŒ ì¸ì‹ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ìœ ìš©í•˜ê²Œ í™œìš©ë˜ëŠ” ê¸°ìˆ ì´ì£ .<br><br>
í˜„ì¬ OCRì€ ì£¼ë¡œ ê³µë¬¸ì„œ, ì‹ ë¶„ì¦, ì˜ìˆ˜ì¦, ì„œì  ë“±ê³¼ ê°™ì´ ì •í˜•í™”ëœ í¬ë§·ì´ë‚˜ ì‚¬ì „ì  ì˜ë¯¸ê°€ ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ë””ì§€í„¸í™”í•˜ëŠ” ë° ë§ì´ ì ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì•„ë˜ ì˜ìˆ˜ì¦ê³¼ ê°™ì´ ì •í˜•í™”ëœ í¬ë§·ì˜ ê²½ìš°, íŠ¹ì • ì˜ì—­ì—ëŠ” ë‚ ì§œ, ì‹œê°„, í’ˆëª©, ê°€ê²© ë“±ê³¼ ê°™ì€ ì •í•´ì§„ íƒ€ì…ì˜ í…ìŠ¤íŠ¸ê°€ ì‘ì„±ë  ê²ƒì´ë¼ ì˜ˆìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‚¬ì „ì  ì˜ë¯¸ê°€ ìˆëŠ” í…ìŠ¤íŠ¸ì˜ ê²½ìš°, ì˜ëª» ì¸ì‹ëœ ê²½ìš°ì—ë„ ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ì˜¤íƒ€ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <br><br>
í•˜ì§€ë§Œ ì„¤ê³„ ë„ë©´ì˜ í…ìŠ¤íŠ¸ëŠ” ì£¼ë¡œ íŠ¹ì • ê±´ì„¤ ì‚¬ì—…ì—ì„œ ì •ì˜ëœ ì½”ë“œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì½”ë“œë“¤ì€ íŠ¹ìˆ˜ ê¸°í˜¸ë“¤ê³¼ ì¡°í•©ë˜ì–´ ìµœëŒ€ 20ì ì´ìƒì˜ ë‹¨ì–´ë¡œ í‘œí˜„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì„¤ê³„ ë„ë©´ì˜ íŠ¹ì„±ì— ë§ëŠ” í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.

<div align="center">
<img src="../../assets/images/2023-09-09-PnID(5)/OCR_example.png" alt="OCR-Example" />
</div>
<center>[ ì˜ìˆ˜ì¦ OCR ì¸ì‹ ì˜ˆì‹œ ]</center>
*ì¶œì²˜: [ì´ë¯¸ì§€ ì¶œì²˜](https://viso.ai/computer-vision/optical-character-recognition-ocr/){:target="_blank"}*

## 2. í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì˜ í”„ë ˆì„ì›Œí¬ ë¶„ì„ ë° ì„¤ê³„
í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ë¹„êµí•˜ëŠ” ì¼ì€ ê·¸ ì–´ë–¤ ë¶„ì•¼ì—ì„œë„ ì‰½ì§€ ì•ŠìŠµë‹ˆë‹¤. 2019ë…„ì— ë°œí‘œëœ ë…¼ë¬¸ ["What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis"](https://arxiv.org/abs/1904.01906){:target="_blank"} ì—ì„œëŠ” ì´ëŸ¬í•œ ì–´ë ¤ì›€ì„ ê·¹ë³µí•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë…¼ë¬¸ì€ í”„ë ˆì„ì›Œí¬ì˜ ë„¤ ê°€ì§€ í•µì‹¬ ìŠ¤í…Œì´ì§€(Transformation, Feature Extraction, Sequence Modeling, Prediction)ë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.<br> ì•„ë˜ ê·¸ë¦¼ì€ ê¸°ì¡´ì— ì œì•ˆëœ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ ë„¤ ê°€ì§€ ìŠ¤í…Œì´ì§€ë¡œ êµ¬ë¶„ì§€ì–´ ì •ì˜í•˜ê³  ì¼ê´€ëœ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•œ ê²°ê³¼ ìë£Œì…ë‹ˆë‹¤.

<div align="center">
<img src="../../assets/images/2023-09-09-PnID(5)/previously_proposed_combinations.png" alt="Previously-Proposed-Combinations" />
</div>
<center>[ ê¸°ì¡´ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì˜ ìŠ¤í…Œì´ì§€ ì¡°í•© ]</center>
*ì¶œì²˜: [ì´ë¯¸ì§€ ì¶œì²˜](https://arxiv.org/abs/1904.01906){:target="_blank"}*

ê° ìŠ¤í…Œì´ì§€ì˜ íŠ¹ì„±ì„ ì´í•´í•˜ê³  ì´ë¥¼ ì¡°í•©í•˜ì—¬ ì í•©í•œ ëª¨ë¸ì„ ê°œë°œí•œë‹¤ë©´, ì„¤ê³„ ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” ë° ë” ë‚˜ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì„¤ê³„ ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹ ë¶„ì•¼ì—ì„œëŠ” ì–´ë–¤ stageì˜ ì¡°í•©ì´ ìµœì ì˜ ì¡°í•©ì¼ì§€ ìŠ¤í…Œì´ì§€ë³„ ë¶„ì„ ë° ì¡°í•©ì„ ì‹œë„í•˜ì˜€ìŠµë‹ˆë‹¤.

### Transformation(Trans.): ë³€í™˜ ìŠ¤í…Œì´ì§€
ì´ ë‹¨ê³„ì—ì„œëŠ” Spatial Transformation Network(STN)ì˜ ë³€í˜• ì¤‘ í•˜ë‚˜ì¸ Thin-Plate Spline(TPS) ë³€í™˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. TPS ë³€í™˜ì€ ë‹¤ì–‘í•œ í˜•íƒœì˜ ê¸°í•˜í•™ì  ì™œê³¡ì„ ì‰½ê²Œ í‘œí˜„í•  ìˆ˜ ìˆì–´, ë³µì¡í•œ í…ìŠ¤íŠ¸ í˜•íƒœë¥¼ ë³´ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. íŠ¹íˆ ê³¡ì„  ë˜ëŠ” ê¸°ìš¸ì–´ì§„ í…ìŠ¤íŠ¸ì™€ ê°™ì€ ì–´ë ¤ìš´ í˜•íƒœì˜ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ì—¬ í›„ì† ë‹¨ê³„ì˜ ì²˜ë¦¬ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
### Feature Extraction(Feat.): íŠ¹ì§• ì¶”ì¶œ ìŠ¤í…Œì´ì§€
ì´ ë‹¨ê³„ì—ì„œëŠ” ì…ë ¥ ë°ì´í„°ë¡œë¶€í„° ì¤‘ìš”í•œ ì‹œê° ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ í•™ìŠµëœ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê±°ë‚˜ ì¸ì‹í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì¼ë°˜ì ì¸ CNN ì•„í‚¤í…ì²˜ëŠ” í•©ì„±ê³± ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ê¸°ë°˜ì´ë©° í…ìŠ¤íŠ¸ì˜ í¬ê¸°, í°íŠ¸, ë°°ê²½ ë“± ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ ì œì™¸í•˜ê³  í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ì •ë³´ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ResNet ì•„í‚¤í…ì²˜ê°€ VGGì™€ RCNNë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ì •ë³´ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ íš¨ê³¼ë¥¼ ë°œíœ˜í•©ë‹ˆë‹¤.
### Sequence Modeling (Seq.): ì‹œí€€ìŠ¤ ëª¨ë¸ë§ ìŠ¤í…Œì´ì§€
ì´ ë‹¨ê³„ì—ì„œëŠ” í…ìŠ¤íŠ¸ë¥¼ ìºë¦­í„° ë‹¨ìœ„ë¡œ ì¸ì‹í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ì˜ ì‹œí€€ìŠ¤ë¥¼ ë¬¸ë§¥ ì •ë³´ë¡œì¨ ì¸ì‹í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ëª¨ë¸ì€ ì¶”ì¶œëœ íŠ¹ì§•ì„ ì‹œí€€ìŠ¤ë¡œ ì¬êµ¬ì„±í•˜ê³ , ë¬¸ë§¥ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ë” ë‚˜ì€ ì‹œí€€ìŠ¤ë¥¼ í˜•ì„±í•˜ëŠ” ë° ëª©í‘œë¥¼ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ BiLSTMì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë” ë„“ì€ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ë¬¸ìë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
### Prediction (Pred.): ì˜ˆì¸¡ ìŠ¤í…Œì´ì§€
ì´ì „ ë‹¨ê³„ë¥¼ í†µí•´ ì–»ì€ íŠ¹ì§•ë“¤ì„ ë‹¨ì–´ë“¤ì˜ ì‹œí€€ìŠ¤ë¡œ ì˜ˆì¸¡í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ë‘ ê°€ì§€ ì„ íƒ ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ë¡œ [Connectionist Temporal Classification(CTC)](https://dl.acm.org/doi/abs/10.1145/1143844.1143891){:target="_blank"}ëŠ” ì¤‘ë³µ ë¬¸ìì™€ ê³µë°±ì„ ì œê±°í•˜ì—¬ ê°€ë³€ ê¸¸ì´ì˜ ì¶œë ¥ ë¬¸ì ì‹œí€€ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ë¡œ [Attention-based Sequence Prediction (Attn)](https://openaccess.thecvf.com/content_iccv_2017/html/Cheng_Focusing_Attention_Towards_ICCV_2017_paper.html){:target="_blank"} ì€ ì£¼ìš” ì •ë³´ íë¦„ì„ íŒŒì•…í•˜ì—¬ ì¶œë ¥ ë¬¸ì ì‹œí€€ìŠ¤ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. íŠ¹íˆ Attnì€ ë¬¸ì ê°„ì˜ ì˜ì¡´ì„±ì„ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ë•ê¸° ë•Œë¬¸ì— ë¬¸ì ì¼ë¶€ê°€ ê°€ë ¤ì ¸ìˆê±°ë‚˜ ëˆ„ë½ëœ ê²½ìš°ì— ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤.

ìœ„ ë„¤ ê°€ì§€ stage ë¶„ì„ì„ í† ëŒ€ë¡œ TPS-ResNet-None-CTC ì¡°í•©ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ ì„¤ê³„í•˜ê³ , ë‹¤ë¥¸ ì¡°í•© í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ê³¼ ë¹„êµ ì‹¤í—˜ì„ í–ˆìŠµë‹ˆë‹¤.

## 3. í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ êµ¬ì¶• ê³¼ì •
### ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
í…ìŠ¤íŠ¸ íƒì§€ ë‹¨ê³„ì—ì„œ ì–¸ê¸‰í•œ ê²ƒì²˜ëŸ¼, ê±´ì„¤ í”„ë¡œì íŠ¸ì™€ ì„¤ê³„ ë²¤ë”ë§ˆë‹¤ í…ìŠ¤íŠ¸ì˜ í°íŠ¸ì™€ í¬ê¸° ë“± ìŠ¤íƒ€ì¼ì´ ë‹¤ì–‘í•©ë‹ˆë‹¤. ì´ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ê°€ëŠ¥í•œ ë§ì€ ë‹¤ì–‘í•œ ê±´ì„¤ í”„ë¡œì íŠ¸ì˜ ë„ë©´ì—ì„œ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤. ì´ **13**ê°œì˜ ê±´ì„¤ í”„ë¡œì íŠ¸ì—ì„œ ì•½ **3,363**ì¥ì˜ ë„ë©´ì„ ìˆ˜ì§‘í•˜ê³ , ìˆ˜ì§‘ëœ ë„ë©´ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ì˜ì—­ ì´ë¯¸ì§€ëŠ” ì´ **376,656**ì¥ì´ì—ˆìŠµë‹ˆë‹¤. 

ë°ì´í„° ë‹¤ì–‘ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ í°íŠ¸ì™€ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±ëœ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê°€ì§œ ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ìˆ˜ì§‘í•œ ë°ì´í„°ì…‹ê³¼ ìœ ì‚¬í•œ ì–‘ì„ ìƒì„±í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ ê°€ì§œ ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ë°ì´í„°ì™€ ë¹„ìŠ·í•œ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆì–´, ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì— í™œìš©ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” ë° ë” ê°•ë ¥í•´ì§‘ë‹ˆë‹¤.g
ìˆ˜ì§‘í•œ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ëŠ” ê¸¸ì´ê°€ í•œ ê¸€ìë¶€í„° 20ì ì´ìƒê¹Œì§€ ë‹¤ì–‘í•©ë‹ˆë‹¤. ì´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ê°€ë¡œì™€ ì„¸ë¡œ ë¹„ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ ì§§ì€ í…ìŠ¤íŠ¸ì™€ ê¸´ í…ìŠ¤íŠ¸ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ê¸¸ì´ì— ë”°ë¼ ë‚˜ëˆˆ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì€ ê¸¸ì´ì— ë”°ë¼ ë‘ ê°œì˜ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ í™œìš©ë©ë‹ˆë‹¤.

### ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ ì œì•ˆí•˜ëŠ” TPS-ResNet-None-CTC ì¡°í•©ì˜ ëª¨ë¸ë¡œ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- Transformation(Trans.): TPS
<details>
<summary>ì½”ë“œ ì ‘ê¸°/í¼ì¹˜ê¸°</summary>
<div markdown="1">
```python
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class TPS_SpatialTransformerNetwork(nn.Module):
    """ RAREì˜ Rectification Network, ì¦‰ TPS ê¸°ë°˜ STN"""

    def __init__(self, F, I_size, I_r_size, I_channel_num=1):
        """ RARE TPSë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•¨
        input:
            batch_I: Batch Input Image [batch_size x I_channel_num x I_height x I_width]
            I_size : ì…ë ¥ ì´ë¯¸ì§€ Iì˜ (ë†’ì´, ë„ˆë¹„)
            I_r_size : ë³€í™˜ëœ ì´ë¯¸ì§€ I_rì˜ (ë†’ì´, ë„ˆë¹„)
            I_channel_num : ì…ë ¥ ì´ë¯¸ì§€ Iì˜ ì±„ë„ ìˆ˜
        output:
            batch_I_r: ë³€í™˜ëœ ì´ë¯¸ì§€ [batch_size x I_channel_num x I_r_height x I_r_width]
        """
        super(TPS_SpatialTransformerNetwork, self).__init__()
        self.F = F
        self.I_size = I_size
        self.I_r_size = I_r_size  # = (I_r_height, I_r_width)
        self.I_channel_num = I_channel_num
        self.LocalizationNetwork = LocalizationNetwork(self.F, self.I_channel_num)
        self.GridGenerator = GridGenerator(self.F, self.I_r_size)

    def forward(self, batch_I):
        batch_C_prime = self.LocalizationNetwork(batch_I)  # batch_size x K x 2
        build_P_prime = self.GridGenerator.build_P_prime(batch_C_prime)  # batch_size x n (= I_r_width x I_r_height) x 2
        build_P_prime_reshape = build_P_prime.reshape([build_P_prime.size(0), self.I_r_size[0], self.I_r_size[1], 2])
        
        # grid_sample í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤.
        if torch.__version__ > "1.2.0":
            batch_I_r = F.grid_sample(batch_I, build_P_prime_reshape, padding_mode='border', align_corners=True)
        else:
            batch_I_r = F.grid_sample(batch_I, build_P_prime_reshape, padding_mode='border')

        return batch_I_r


class LocalizationNetwork(nn.Module):
    """ RAREì˜ Localization Network, ì…ë ¥ ì´ë¯¸ì§€ Iì—ì„œ C' (K x 2)ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. """

    def __init__(self, F, I_channel_num):
        super(LocalizationNetwork, self).__init__()
        self.F = F
        self.I_channel_num = I_channel_num
        # Convolutional layersì™€ Fully connected layersë¡œ êµ¬ì„±ëœ ì‹ ê²½ë§ì…ë‹ˆë‹¤.
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels=self.I_channel_num, out_channels=64, kernel_size=3, stride=1, padding=1,
                      bias=False), nn.BatchNorm2d(64), nn.ReLU(True),
            nn.MaxPool2d(2, 2),  # batch_size x 64 x I_height/2 x I_width/2
            nn.Conv2d(64, 128, 3, 1, 1, bias=False), nn.BatchNorm2d(128), nn.ReLU(True),
            nn.MaxPool2d(2, 2),  # batch_size x 128 x I_height/4 x I_width/4
            nn.Conv2d(128, 256, 3, 1, 1, bias=False), nn.BatchNorm2d(256), nn.ReLU(True),
            nn.MaxPool2d(2, 2),  # batch_size x 256 x I_height/8 x I_width/8
            nn.Conv2d(256, 512, 3, 1, 1, bias=False), nn.BatchNorm2d(512), nn.ReLU(True),
            nn.AdaptiveAvgPool2d(1)  # batch_size x 512
        )
        # ì˜ˆì¸¡ëœ C' ì¢Œí‘œë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ fully connected layersì…ë‹ˆë‹¤.
        self.localization_fc1 = nn.Sequential(nn.Linear(512, 256), nn.ReLU(True))
        self.localization_fc2 = nn.Linear(256, self.F * 2)

        # LocalizationNetworkì˜ fc2 ì´ˆê¸°í™”
        self.localization_fc2.weight.data.fill_(0)
        """ RARE ë…¼ë¬¸ì˜ Fig. 6 (a) ì°¸ì¡° """
        ctrl_pts_x = np.linspace(-1.0, 1.0, int(F / 2))
        ctrl_pts_y_top = np.linspace(0.0, -1.0, num=int(F / 2))
        ctrl_pts_y_bottom = np.linspace(1.0, 0.0, num=int(F / 2))
        ctrl_pts_top = np.stack([ctrl_pts_x, ctrl_pts_y_top], axis=1)
        ctrl_pts_bottom = np.stack([ctrl_pts_x, ctrl_pts_y_bottom], axis=1)
        initial_bias = np.concatenate([ctrl_pts_top, ctrl_pts_bottom], axis=0)
        self.localization_fc2.bias.data = torch.from_numpy(initial_bias).float().view(-1)

    def forward(self, batch_I):
        batch_size = batch_I.size(0)
        features = self.conv(batch_I).view(batch_size, -1)
        batch_C_prime = self.localization_fc2(self.localization_fc1(features)).view(batch_size, self.F, 2)
        return batch_C_prime


class GridGenerator(nn.Module):
    """ RAREì˜ Grid Generator, Tì™€ Pë¥¼ ê³±í•´ì„œ P_primeì„ ìƒì„±í•©ë‹ˆë‹¤. """

    def __init__(self, F, I_r_size):
        """ P_hatê³¼ inv_delta_Cë¥¼ ë¯¸ë¦¬ ìƒì„±í•©ë‹ˆë‹¤. """
        super(GridGenerator, self).__init__()
        self.eps = 1e-6
        self.I_r_height, self.I_r_width = I_r_size
        self.F = F
        self.C = self._build_C(self.F)  # F x 2
        self.P = self._build_P(self.I_r_width, self.I_r_height)
        # multi-gpuë¥¼ ìœ„í•´ bufferë¡œ ë“±ë¡í•©ë‹ˆë‹¤.
        self.register_buffer("inv_delta_C", torch.tensor(self._build_inv_delta_C(self.F, self.C)).float())  # F+3 x F+3
        self.register_buffer("P_hat", torch.tensor(self._build_P_hat(self.F, self.C, self.P)).float())  # n x F+3

    def _build_C(self, F):
        """ I_rì˜ fiducial pointsì˜ ì¢Œí‘œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. """
        ctrl_pts_x = np.linspace(-1.0, 1.0, int(F / 2))
        ctrl_pts_y_top = -1 * np
```
</div>
</details>
<br>
- Feature Extraction(Feat.): ResNet
<details>
<summary>ì½”ë“œ ì ‘ê¸°/í¼ì¹˜ê¸°</summary>
<div markdown="1">
```python
import torch.nn as nn
import torch.nn.functional as F

class ResNet_FeatureExtractor(nn.Module):

    def __init__(self, input_channel, output_channel=512):
        super(ResNet_FeatureExtractor, self).__init__()
        self.ConvNet = ResNet(input_channel, output_channel, BasicBlock, [1, 2, 5, 3])

    def forward(self, input):
        return self.ConvNet(input)

class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = self._conv3x3(inplanes, planes, stride)  # ì²« ë²ˆì§¸ 3x3 í•©ì„±ê³± ë ˆì´ì–´
        self.bn1 = nn.BatchNorm2d(planes)  # ë°°ì¹˜ ì •ê·œí™”
        self.conv2 = self._conv3x3(planes, planes)  # ë‘ ë²ˆì§¸ 3x3 í•©ì„±ê³± ë ˆì´ì–´
        self.bn2 = nn.BatchNorm2d(planes)  # ë°°ì¹˜ ì •ê·œí™”
        self.relu = nn.ReLU(inplace=True)  # ReLU í™œì„±í™” í•¨ìˆ˜
        self.downsample = downsample  # ë‹¤ìš´ ìƒ˜í”Œë§ ë ˆì´ì–´
        self.stride = stride

    def _conv3x3(self, in_planes, out_planes, stride=1):
        "3x3 ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´"
        return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                         padding=1, bias=False)

    def forward(self, x):
        residual = x

        out = self.conv1(x)  # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì ìš©
        out = self.bn1(out)  # ë°°ì¹˜ ì •ê·œí™”
        out = self.relu(out)  # ReLU í™œì„±í™” í•¨ìˆ˜

        out = self.conv2(out)  # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì ìš©
        out = self.bn2(out)  # ë°°ì¹˜ ì •ê·œí™”

        if self.downsample is not None:
            residual = self.downsample(x)  # ë‹¤ìš´ ìƒ˜í”Œë§ ë ˆì´ì–´ ì ìš©
        out += residual  # ì”ì°¨ ì—°ê²°
        out = self.relu(out)  # ReLU í™œì„±í™” í•¨ìˆ˜

        return out

class ResNet(nn.Module):

    def __init__(self, input_channel, output_channel, block, layers):
        super(ResNet, self).__init__()

        # ê° ë ˆì´ì–´ì—ì„œ ì¶œë ¥ ì±„ë„ì˜ ìˆ˜ë¥¼ ì •ì˜
        self.output_channel_block = [int(output_channel / 4), int(output_channel / 2), output_channel, output_channel]

        # ì´ˆê¸° ì…ë ¥ ì±„ë„ ìˆ˜ ì„¤ì •
        self.inplanes = int(output_channel / 8)

        # ì´ˆê¸° ë‘ ê°œì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì •ì˜
        self.conv0_1 = nn.Conv2d(input_channel, int(output_channel / 16),
                                 kernel_size=3, stride=1, padding=1, bias=False)
        self.bn0_1 = nn.BatchNorm2d(int(output_channel / 16))
        self.conv0_2 = nn.Conv2d(int(output_channel / 16), self.inplanes,
                                 kernel_size=3, stride=1, padding=1, bias=False)
        self.bn0_2 = nn.BatchNorm2d(self.inplanes)
        self.relu = nn.ReLU(inplace=True)

        # ê° ë ˆì´ì–´ì— ëŒ€í•œ ë§¥ìŠ¤ í’€ë§ ë ˆì´ì–´ ì •ì˜
        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1))

        # ResNet ë ˆì´ì–´ë“¤ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œ
        self.layer1 = self._make_layer(block, self.output_channel_block[0], layers[0])
        self.layer2 = self._make_layer(block, self.output_channel_block[1], layers[1], stride=1)
        self.layer3 = self._make_layer(block, self.output_channel_block[2], layers[2], stride=1)
        self.layer4 = self._make_layer(block, self.output_channel_block[3], layers[3], stride=1)

        # ê° ë ˆì´ì–´ì— ëŒ€í•œ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì •ì˜
        self.conv1 = nn.Conv2d(self.output_channel_block[0], self.output_channel_block[
                               0], kernel_size=3, stride=1, padding=1, bias=False)
        self.conv2 = nn.Conv2d(self.output_channel_block[1], self.output_channel_block[
                               1], kernel_size=3, stride=1, padding=1, bias=False)
        self.conv3 = nn.Conv2d(self.output_channel_block[2], self.output_channel_block[
                               2], kernel_size=3, stride=1, padding=1, bias=False)
        self.conv4_1 = nn.Conv2d(self.output_channel_block[3], self.output_channel_block[
                                 3], kernel_size=2, stride=(2, 1), padding=(0, 1), bias=False)
        self.conv4_2 = nn.Conv2d(self.output_channel_block[3], self.output_channel_block[
                                 3], kernel_size=1, stride=1, padding=0, bias=False)

        # ê° ë ˆì´ì–´ì— ëŒ€í•œ ë°°ì¹˜ ì •ê·œí™” ë ˆì´ì–´ ì •ì˜
        self.bn1 = nn.BatchNorm2d(self.output_channel_block[0])
        self.bn2 = nn.BatchNorm2d(self.output_channel_block[1])
        self.bn3 = nn.BatchNorm2d(self.output_channel_block[2])
        self.bn4_1 = nn.BatchNorm2d(self.output_channel_block[3])
        self.bn4_2 = nn.BatchNorm2d(self.output_channel_block[3])

    # ê° ResNet ë ˆì´ì–´ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)

    # ìˆœì „íŒŒ í•¨ìˆ˜ ì •ì˜
    def forward(self, x):
        x = self.conv0_1(x)
        x = self.bn0_1(x)
        x = self.relu(x)
        x = self.conv0_2(x)
        x = self.bn0_2(x)
        x = self.relu(x)

        x = self.maxpool1(x)
        x = self.layer1(x)
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)

        x = self.maxpool2(x)
        x = self.layer2(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)

        x = self.maxpool3(x)
        x = self.layer3(x)
        x = self.conv3(x)
        x = self.bn3(x)
        x = self.relu(x)

        x = self.layer4(x)
        x = self.conv4_1(x)
        x = self.bn4_1(x)
        x = self.relu(x)
        x = self.conv4_2(x)
        x = self.bn4_2(x)
        x = self.relu(x)

        return x
```
</div>
</details>
<br>
- Sequence Modeling (Seq.): None<br>
Sequence Modelingì€ ìˆ˜í–‰í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ íŒ¨ìŠ¤

- Prediction (Pred.): ì˜ˆì¸¡ ìŠ¤í…Œì´ì§€
<details>
<summary>ì½”ë“œ ì ‘ê¸°/í¼ì¹˜ê¸°</summary>
<div markdown="1">
```python
```
</div>
</details>
<br>


## 4. ê²°ë¡ 
