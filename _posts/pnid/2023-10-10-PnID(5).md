---
layout: single
title: "í…ìŠ¤íŠ¸ íƒì§€&ì¸ì‹ 2í¸"
permalink: /projects/pnid/05
tag: [Vision AI, Drawing]
author_profile: false
sidebar:
  nav: "docs1"
date: 2023-10-10
use_math: true
---

ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ ì˜ì—­ íƒì§€ì— ì´ì–´ ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” **íƒì§€ ì˜ì—­ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” ê¸°ìˆ **ì— ëŒ€í•´ ì†Œê°œë“œë¦½ë‹ˆë‹¤.

## ğŸ“‹ Table of Contents

1. [í…ìŠ¤íŠ¸ ì¸ì‹ ë°°ê²½](#1-í…ìŠ¤íŠ¸-ì¸ì‹-ë°°ê²½)
2. [í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì˜ í”„ë ˆì„ì›Œí¬ ë¶„ì„ ë° ì„¤ê³„](#2-í…ìŠ¤íŠ¸-ì¸ì‹-ëª¨ë¸ì˜-í”„ë ˆì„ì›Œí¬-ë¶„ì„-ë°-ì„¤ê³„)
3. [í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ êµ¬ì¶• ê³¼ì •](#3-í…ìŠ¤íŠ¸-ì¸ì‹-ëª¨ë¸-êµ¬ì¶•-ê³¼ì •)
4. [ê²°ë¡ ](#4-ê²°ë¡ )

## 1. í…ìŠ¤íŠ¸ ì¸ì‹ ë°°ê²½
OCR(Optical Character Recognition)ì€ ì¸ì‡„ëœ ê´‘í•™ ë¬¸ì ì´ë¯¸ì§€ë¥¼ ê¸°ê³„ê°€ ì½ì„ ìˆ˜ ìˆëŠ” ë””ì§€í„¸ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€ Real worldì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆì™€ ì™œê³¡ì´ ì„ì—¬ ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” STR(Scene Text Recognition)ë„ ë§ì€ ë°œì „ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ë“¤ì€ ë””ì§€í„¸ ì„œë¥˜ ì „í™˜, ê¸°ë°€ë¬¸ì„œ ë§ˆìŠ¤í‚¹, í‘œì§€íŒ ë° ê°„íŒ ì¸ì‹ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ìœ ìš©í•˜ê²Œ í™œìš©ë˜ëŠ” ê¸°ìˆ ì´ì£ .<br><br>
í˜„ì¬ OCRì€ ì£¼ë¡œ ê³µë¬¸ì„œ, ì‹ ë¶„ì¦, ì˜ìˆ˜ì¦, ì„œì  ë“±ê³¼ ê°™ì´ ì •í˜•í™”ëœ í¬ë§·ì´ë‚˜ ì‚¬ì „ì  ì˜ë¯¸ê°€ ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ë””ì§€í„¸í™”í•˜ëŠ” ë° ë§ì´ ì ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì•„ë˜ ì˜ìˆ˜ì¦ê³¼ ê°™ì´ ì •í˜•í™”ëœ í¬ë§·ì˜ ê²½ìš°, íŠ¹ì • ì˜ì—­ì—ëŠ” ë‚ ì§œ, ì‹œê°„, í’ˆëª©, ê°€ê²© ë“±ê³¼ ê°™ì€ ì •í•´ì§„ íƒ€ì…ì˜ í…ìŠ¤íŠ¸ê°€ ì‘ì„±ë  ê²ƒì´ë¼ ì˜ˆìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‚¬ì „ì  ì˜ë¯¸ê°€ ìˆëŠ” í…ìŠ¤íŠ¸ì˜ ê²½ìš°, ì˜ëª» ì¸ì‹ëœ ê²½ìš°ì—ë„ ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ì˜¤íƒ€ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <br><br>
í•˜ì§€ë§Œ ì„¤ê³„ ë„ë©´ì˜ í…ìŠ¤íŠ¸ëŠ” ì£¼ë¡œ íŠ¹ì • ê±´ì„¤ ì‚¬ì—…ì—ì„œ ì •ì˜ëœ ì½”ë“œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì½”ë“œë“¤ì€ íŠ¹ìˆ˜ ê¸°í˜¸ë“¤ê³¼ ì¡°í•©ë˜ì–´ ìµœëŒ€ 20ì ì´ìƒì˜ ë‹¨ì–´ë¡œ í‘œí˜„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì„¤ê³„ ë„ë©´ì˜ íŠ¹ì„±ì— ë§ëŠ” í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.

<div align="center">
<img src="../../assets/images/2023-10-10-PnID(5)/OCR_example.png" alt="OCR-Example" />
</div>
<center>[ ì˜ìˆ˜ì¦ OCR ì¸ì‹ ì˜ˆì‹œ ]</center>
*ì¶œì²˜: [ì´ë¯¸ì§€ ì¶œì²˜](https://viso.ai/computer-vision/optical-character-recognition-ocr/){:target="_blank"}*

## 2. í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì˜ í”„ë ˆì„ì›Œí¬ ë¶„ì„ ë° ì„¤ê³„
í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ë¹„êµí•˜ëŠ” ì¼ì€ ê·¸ ì–´ë–¤ ë¶„ì•¼ì—ì„œë„ ì‰½ì§€ ì•ŠìŠµë‹ˆë‹¤. 2019ë…„ì— ë°œí‘œëœ ë…¼ë¬¸ ["What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis"](https://arxiv.org/abs/1904.01906){:target="_blank"} ì—ì„œëŠ” ì´ëŸ¬í•œ ì–´ë ¤ì›€ì„ ê·¹ë³µí•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë…¼ë¬¸ì€ í”„ë ˆì„ì›Œí¬ì˜ ë„¤ ê°€ì§€ í•µì‹¬ ìŠ¤í…Œì´ì§€(Transformation, Feature Extraction, Sequence Modeling, Prediction)ë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.<br> ì•„ë˜ ê·¸ë¦¼ì€ ê¸°ì¡´ì— ì œì•ˆëœ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ ë„¤ ê°€ì§€ ìŠ¤í…Œì´ì§€ë¡œ êµ¬ë¶„ì§€ì–´ ì •ì˜í•˜ê³  ì¼ê´€ëœ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•œ ê²°ê³¼ ìë£Œì…ë‹ˆë‹¤.

<div align="center">
<img src="../../assets/images/2023-10-10-PnID(5)/previously_proposed_combinations.png" alt="Previously-Proposed-Combinations" />
</div>
<center>[ ê¸°ì¡´ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì˜ ìŠ¤í…Œì´ì§€ ì¡°í•© ]</center>
*ì¶œì²˜: [ì´ë¯¸ì§€ ì¶œì²˜](https://arxiv.org/abs/1904.01906){:target="_blank"}*

ê° ìŠ¤í…Œì´ì§€ì˜ íŠ¹ì„±ì„ ì´í•´í•˜ê³  ì´ë¥¼ ì¡°í•©í•˜ì—¬ ì í•©í•œ ëª¨ë¸ì„ ê°œë°œí•œë‹¤ë©´, ì„¤ê³„ ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” ë° ë” ë‚˜ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì„¤ê³„ ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹ ë¶„ì•¼ì—ì„œëŠ” ì–´ë–¤ stageì˜ ì¡°í•©ì´ ìµœì ì˜ ì¡°í•©ì¼ì§€ ìŠ¤í…Œì´ì§€ë³„ ë¶„ì„ ë° ì¡°í•©ì„ ì‹œë„í•˜ì˜€ìŠµë‹ˆë‹¤.

### Transformation(Trans.): ë³€í™˜ ìŠ¤í…Œì´ì§€
ì´ ë‹¨ê³„ì—ì„œëŠ” Spatial Transformation Network(STN)ì˜ ë³€í˜• ì¤‘ í•˜ë‚˜ì¸ Thin-Plate Spline(TPS) ë³€í™˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. TPS ë³€í™˜ì€ ë‹¤ì–‘í•œ í˜•íƒœì˜ ê¸°í•˜í•™ì  ì™œê³¡ì„ ì‰½ê²Œ í‘œí˜„í•  ìˆ˜ ìˆì–´, ë³µì¡í•œ í…ìŠ¤íŠ¸ í˜•íƒœë¥¼ ë³´ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. íŠ¹íˆ ê³¡ì„  ë˜ëŠ” ê¸°ìš¸ì–´ì§„ í…ìŠ¤íŠ¸ì™€ ê°™ì€ ì–´ë ¤ìš´ í˜•íƒœì˜ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ì—¬ í›„ì† ë‹¨ê³„ì˜ ì²˜ë¦¬ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
### Feature Extraction(Feat.): íŠ¹ì§• ì¶”ì¶œ ìŠ¤í…Œì´ì§€
ì´ ë‹¨ê³„ì—ì„œëŠ” ì…ë ¥ ë°ì´í„°ë¡œë¶€í„° ì¤‘ìš”í•œ ì‹œê° ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ í•™ìŠµëœ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê±°ë‚˜ ì¸ì‹í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì¼ë°˜ì ì¸ CNN ì•„í‚¤í…ì²˜ëŠ” í•©ì„±ê³± ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ê¸°ë°˜ì´ë©° í…ìŠ¤íŠ¸ì˜ í¬ê¸°, í°íŠ¸, ë°°ê²½ ë“± ê´€ë ¨ ì—†ëŠ” ì •ë³´ë¥¼ ì œì™¸í•˜ê³  í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ì •ë³´ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì„ í•©ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼, ResNet ì•„í‚¤í…ì²˜ê°€ VGGì™€ RCNNë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ì •ë³´ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ íš¨ê³¼ë¥¼ ë°œíœ˜í•©ë‹ˆë‹¤.
### Sequence Modeling (Seq.): ì‹œí€€ìŠ¤ ëª¨ë¸ë§ ìŠ¤í…Œì´ì§€
ì´ ë‹¨ê³„ì—ì„œëŠ” í…ìŠ¤íŠ¸ë¥¼ ìºë¦­í„° ë‹¨ìœ„ë¡œ ì¸ì‹í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ì˜ ì‹œí€€ìŠ¤ë¥¼ ë¬¸ë§¥ ì •ë³´ë¡œì¨ ì¸ì‹í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ëª¨ë¸ì€ ì¶”ì¶œëœ íŠ¹ì§•ì„ ì‹œí€€ìŠ¤ë¡œ ì¬êµ¬ì„±í•˜ê³ , ë¬¸ë§¥ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ë” ë‚˜ì€ ì‹œí€€ìŠ¤ë¥¼ í˜•ì„±í•˜ëŠ” ë° ëª©í‘œë¥¼ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ BiLSTMì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë” ë„“ì€ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ë¬¸ìë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
### Prediction (Pred.): ì˜ˆì¸¡ ìŠ¤í…Œì´ì§€
ì´ì „ ë‹¨ê³„ë¥¼ í†µí•´ ì–»ì€ íŠ¹ì§•ë“¤ì„ ë‹¨ì–´ë“¤ì˜ ì‹œí€€ìŠ¤ë¡œ ì˜ˆì¸¡í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ë‘ ê°€ì§€ ì„ íƒ ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ë¡œ [Connectionist Temporal Classification(CTC)](https://dl.acm.org/doi/abs/10.1145/1143844.1143891){:target="_blank"}ëŠ” ì¤‘ë³µ ë¬¸ìì™€ ê³µë°±ì„ ì œê±°í•˜ì—¬ ê°€ë³€ ê¸¸ì´ì˜ ì¶œë ¥ ë¬¸ì ì‹œí€€ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ë¡œ [Attention-based Sequence Prediction (Attn)](https://openaccess.thecvf.com/content_iccv_2017/html/Cheng_Focusing_Attention_Towards_ICCV_2017_paper.html){:target="_blank"} ì€ ì£¼ìš” ì •ë³´ íë¦„ì„ íŒŒì•…í•˜ì—¬ ì¶œë ¥ ë¬¸ì ì‹œí€€ìŠ¤ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. íŠ¹íˆ Attnì€ ë¬¸ì ê°„ì˜ ì˜ì¡´ì„±ì„ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ë•ê¸° ë•Œë¬¸ì— ë¬¸ì ì¼ë¶€ê°€ ê°€ë ¤ì ¸ìˆê±°ë‚˜ ëˆ„ë½ëœ ê²½ìš°ì— ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤.

ìœ„ ë„¤ ê°€ì§€ stage ë¶„ì„ì„ í† ëŒ€ë¡œ TPS-ResNet-None-CTC ì¡°í•©ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ ì„¤ê³„í•˜ê³ , ë‹¤ë¥¸ ì¡°í•© í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ê³¼ ë¹„êµ ì‹¤í—˜ì„ í–ˆìŠµë‹ˆë‹¤.

## 3. í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ êµ¬ì¶• ê³¼ì •
### ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
í…ìŠ¤íŠ¸ íƒì§€ ë‹¨ê³„ì—ì„œ ì–¸ê¸‰í•œ ê²ƒì²˜ëŸ¼, ê±´ì„¤ í”„ë¡œì íŠ¸ì™€ ì„¤ê³„ ë²¤ë”ë§ˆë‹¤ í…ìŠ¤íŠ¸ì˜ í°íŠ¸ì™€ í¬ê¸° ë“± ìŠ¤íƒ€ì¼ì´ ë‹¤ì–‘í•©ë‹ˆë‹¤. ì´ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ê°€ëŠ¥í•œ ë§ì€ ë‹¤ì–‘í•œ ê±´ì„¤ í”„ë¡œì íŠ¸ì˜ ë„ë©´ì—ì„œ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤. ì´ **13**ê°œì˜ ê±´ì„¤ í”„ë¡œì íŠ¸ì—ì„œ ì•½ **3,363**ì¥ì˜ ë„ë©´ì„ ìˆ˜ì§‘í•˜ê³ , ìˆ˜ì§‘ëœ ë„ë©´ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ì˜ì—­ ì´ë¯¸ì§€ëŠ” ì´ **376,656**ì¥ì´ì—ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ì˜ ìºë¦­í„° í´ë˜ìŠ¤ëŠ” ì˜ë¬¸, ìˆ«ì ê·¸ë¦¬ê³  20ê°œì˜ íŠ¹ìˆ˜ ë¬¸ìë¡œ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

ë°ì´í„° ë‹¤ì–‘ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ í°íŠ¸ì™€ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±ëœ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê°€ì§œ ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ìˆ˜ì§‘í•œ ë°ì´í„°ì…‹ê³¼ ìœ ì‚¬í•œ ì–‘ì„ ìƒì„±í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ ê°€ì§œ ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ë°ì´í„°ì™€ ë¹„ìŠ·í•œ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆì–´, ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì— í™œìš©ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” ë° ë” ê°•ë ¥í•´ì§‘ë‹ˆë‹¤.

ìˆ˜ì§‘í•œ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ëŠ” ê¸¸ì´ê°€ í•œ ê¸€ìë¶€í„° 20ì ì´ìƒê¹Œì§€ ë‹¤ì–‘í•©ë‹ˆë‹¤. ì´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ê°€ë¡œì™€ ì„¸ë¡œ ë¹„ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ ì§§ì€ í…ìŠ¤íŠ¸ì™€ ê¸´ í…ìŠ¤íŠ¸ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ê¸¸ì´ì— ë”°ë¼ ë‚˜ëˆˆ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì€ ê¸¸ì´ì— ë”°ë¼ ë‘ ê°œì˜ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ í™œìš©ë©ë‹ˆë‹¤.

### ëª¨ë¸ í•™ìŠµ
ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ ì œì•ˆí•˜ëŠ” ***TPS-ResNet-None-CTC*** ì¡°í•©ì˜ í”„ë ˆì„ì›Œí¬ë¡œ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- Transformation(Trans.): **TPS**
  <details>
  <summary>ì½”ë“œ ì ‘ê¸°/í¼ì¹˜ê¸°</summary>
  <div markdown="1">
  ```python
  import numpy as np
  import torch
  import torch.nn as nn
  import torch.nn.functional as F
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  class TPS_SpatialTransformerNetwork(nn.Module):
      """ RAREì˜ Rectification Network, ì¦‰ TPS ê¸°ë°˜ STN"""

      def __init__(self, F, I_size, I_r_size, I_channel_num=1):
          """ RARE TPSë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•¨
          input:
              batch_I: Batch Input Image [batch_size x I_channel_num x I_height x I_width]
              I_size : ì…ë ¥ ì´ë¯¸ì§€ Iì˜ (ë†’ì´, ë„ˆë¹„)
              I_r_size : ë³€í™˜ëœ ì´ë¯¸ì§€ I_rì˜ (ë†’ì´, ë„ˆë¹„)
              I_channel_num : ì…ë ¥ ì´ë¯¸ì§€ Iì˜ ì±„ë„ ìˆ˜
          output:
              batch_I_r: ë³€í™˜ëœ ì´ë¯¸ì§€ [batch_size x I_channel_num x I_r_height x I_r_width]
          """
          super(TPS_SpatialTransformerNetwork, self).__init__()
          self.F = F
          self.I_size = I_size
          self.I_r_size = I_r_size  # = (I_r_height, I_r_width)
          self.I_channel_num = I_channel_num
          self.LocalizationNetwork = LocalizationNetwork(self.F, self.I_channel_num)
          self.GridGenerator = GridGenerator(self.F, self.I_r_size)

      def forward(self, batch_I):
          batch_C_prime = self.LocalizationNetwork(batch_I)  # batch_size x K x 2
          build_P_prime = self.GridGenerator.build_P_prime(batch_C_prime)  # batch_size x n (= I_r_width x I_r_height) x 2
          build_P_prime_reshape = build_P_prime.reshape([build_P_prime.size(0), self.I_r_size[0], self.I_r_size[1], 2])
          
          # grid_sample í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤.
          if torch.__version__ > "1.2.0":
              batch_I_r = F.grid_sample(batch_I, build_P_prime_reshape, padding_mode='border', align_corners=True)
          else:
              batch_I_r = F.grid_sample(batch_I, build_P_prime_reshape, padding_mode='border')

          return batch_I_r


  class LocalizationNetwork(nn.Module):
      """ RAREì˜ Localization Network, ì…ë ¥ ì´ë¯¸ì§€ Iì—ì„œ C' (K x 2)ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. """

      def __init__(self, F, I_channel_num):
          super(LocalizationNetwork, self).__init__()
          self.F = F
          self.I_channel_num = I_channel_num
          # Convolutional layersì™€ Fully connected layersë¡œ êµ¬ì„±ëœ ì‹ ê²½ë§ì…ë‹ˆë‹¤.
          self.conv = nn.Sequential(
              nn.Conv2d(in_channels=self.I_channel_num, out_channels=64, kernel_size=3, stride=1, padding=1,
                        bias=False), nn.BatchNorm2d(64), nn.ReLU(True),
              nn.MaxPool2d(2, 2),  # batch_size x 64 x I_height/2 x I_width/2
              nn.Conv2d(64, 128, 3, 1, 1, bias=False), nn.BatchNorm2d(128), nn.ReLU(True),
              nn.MaxPool2d(2, 2),  # batch_size x 128 x I_height/4 x I_width/4
              nn.Conv2d(128, 256, 3, 1, 1, bias=False), nn.BatchNorm2d(256), nn.ReLU(True),
              nn.MaxPool2d(2, 2),  # batch_size x 256 x I_height/8 x I_width/8
              nn.Conv2d(256, 512, 3, 1, 1, bias=False), nn.BatchNorm2d(512), nn.ReLU(True),
              nn.AdaptiveAvgPool2d(1)  # batch_size x 512
          )
          # ì˜ˆì¸¡ëœ C' ì¢Œí‘œë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ fully connected layersì…ë‹ˆë‹¤.
          self.localization_fc1 = nn.Sequential(nn.Linear(512, 256), nn.ReLU(True))
          self.localization_fc2 = nn.Linear(256, self.F * 2)

          # LocalizationNetworkì˜ fc2 ì´ˆê¸°í™”
          self.localization_fc2.weight.data.fill_(0)
          """ RARE ë…¼ë¬¸ì˜ Fig. 6 (a) ì°¸ì¡° """
          ctrl_pts_x = np.linspace(-1.0, 1.0, int(F / 2))
          ctrl_pts_y_top = np.linspace(0.0, -1.0, num=int(F / 2))
          ctrl_pts_y_bottom = np.linspace(1.0, 0.0, num=int(F / 2))
          ctrl_pts_top = np.stack([ctrl_pts_x, ctrl_pts_y_top], axis=1)
          ctrl_pts_bottom = np.stack([ctrl_pts_x, ctrl_pts_y_bottom], axis=1)
          initial_bias = np.concatenate([ctrl_pts_top, ctrl_pts_bottom], axis=0)
          self.localization_fc2.bias.data = torch.from_numpy(initial_bias).float().view(-1)

      def forward(self, batch_I):
          batch_size = batch_I.size(0)
          features = self.conv(batch_I).view(batch_size, -1)
          batch_C_prime = self.localization_fc2(self.localization_fc1(features)).view(batch_size, self.F, 2)
          return batch_C_prime


  class GridGenerator(nn.Module):
      """ RAREì˜ Grid Generator, Tì™€ Pë¥¼ ê³±í•´ì„œ P_primeì„ ìƒì„±í•©ë‹ˆë‹¤. """

      def __init__(self, F, I_r_size):
          """ P_hatê³¼ inv_delta_Cë¥¼ ë¯¸ë¦¬ ìƒì„±í•©ë‹ˆë‹¤. """
          super(GridGenerator, self).__init__()
          self.eps = 1e-6
          self.I_r_height, self.I_r_width = I_r_size
          self.F = F
          self.C = self._build_C(self.F)  # F x 2
          self.P = self._build_P(self.I_r_width, self.I_r_height)
          # multi-gpuë¥¼ ìœ„í•´ bufferë¡œ ë“±ë¡í•©ë‹ˆë‹¤.
          self.register_buffer("inv_delta_C", torch.tensor(self._build_inv_delta_C(self.F, self.C)).float())  # F+3 x F+3
          self.register_buffer("P_hat", torch.tensor(self._build_P_hat(self.F, self.C, self.P)).float())  # n x F+3

      def _build_C(self, F):
          """ I_rì˜ fiducial pointsì˜ ì¢Œí‘œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. """
          ctrl_pts_x = np.linspace(-1.0, 1.0, int(F / 2))
          ctrl_pts_y_top = -1 * np
  ```
  </div>
  </details>
<br>

- Feature Extraction(Feat.): **ResNet**
  <details>
  <summary>ì½”ë“œ ì ‘ê¸°/í¼ì¹˜ê¸°</summary>
  <div markdown="1">
  ```python
  import torch.nn as nn
  import torch.nn.functional as F

  class ResNet_FeatureExtractor(nn.Module):

      def __init__(self, input_channel, output_channel=512):
          super(ResNet_FeatureExtractor, self).__init__()
          self.ConvNet = ResNet(input_channel, output_channel, BasicBlock, [1, 2, 5, 3])

      def forward(self, input):
          return self.ConvNet(input)

  class BasicBlock(nn.Module):
      expansion = 1

      def __init__(self, inplanes, planes, stride=1, downsample=None):
          super(BasicBlock, self).__init__()
          self.conv1 = self._conv3x3(inplanes, planes, stride)  # ì²« ë²ˆì§¸ 3x3 í•©ì„±ê³± ë ˆì´ì–´
          self.bn1 = nn.BatchNorm2d(planes)  # ë°°ì¹˜ ì •ê·œí™”
          self.conv2 = self._conv3x3(planes, planes)  # ë‘ ë²ˆì§¸ 3x3 í•©ì„±ê³± ë ˆì´ì–´
          self.bn2 = nn.BatchNorm2d(planes)  # ë°°ì¹˜ ì •ê·œí™”
          self.relu = nn.ReLU(inplace=True)  # ReLU í™œì„±í™” í•¨ìˆ˜
          self.downsample = downsample  # ë‹¤ìš´ ìƒ˜í”Œë§ ë ˆì´ì–´
          self.stride = stride

      def _conv3x3(self, in_planes, out_planes, stride=1):
          "3x3 ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´"
          return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                          padding=1, bias=False)

      def forward(self, x):
          residual = x

          out = self.conv1(x)  # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì ìš©
          out = self.bn1(out)  # ë°°ì¹˜ ì •ê·œí™”
          out = self.relu(out)  # ReLU í™œì„±í™” í•¨ìˆ˜

          out = self.conv2(out)  # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì ìš©
          out = self.bn2(out)  # ë°°ì¹˜ ì •ê·œí™”

          if self.downsample is not None:
              residual = self.downsample(x)  # ë‹¤ìš´ ìƒ˜í”Œë§ ë ˆì´ì–´ ì ìš©
          out += residual  # ì”ì°¨ ì—°ê²°
          out = self.relu(out)  # ReLU í™œì„±í™” í•¨ìˆ˜

          return out

  class ResNet(nn.Module):

      def __init__(self, input_channel, output_channel, block, layers):
          super(ResNet, self).__init__()

          # ê° ë ˆì´ì–´ì—ì„œ ì¶œë ¥ ì±„ë„ì˜ ìˆ˜ë¥¼ ì •ì˜
          self.output_channel_block = [int(output_channel / 4), int(output_channel / 2), output_channel, output_channel]

          # ì´ˆê¸° ì…ë ¥ ì±„ë„ ìˆ˜ ì„¤ì •
          self.inplanes = int(output_channel / 8)

          # ì´ˆê¸° ë‘ ê°œì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì •ì˜
          self.conv0_1 = nn.Conv2d(input_channel, int(output_channel / 16),
                                  kernel_size=3, stride=1, padding=1, bias=False)
          self.bn0_1 = nn.BatchNorm2d(int(output_channel / 16))
          self.conv0_2 = nn.Conv2d(int(output_channel / 16), self.inplanes,
                                  kernel_size=3, stride=1, padding=1, bias=False)
          self.bn0_2 = nn.BatchNorm2d(self.inplanes)
          self.relu = nn.ReLU(inplace=True)

          # ê° ë ˆì´ì–´ì— ëŒ€í•œ ë§¥ìŠ¤ í’€ë§ ë ˆì´ì–´ ì •ì˜
          self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
          self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
          self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1))

          # ResNet ë ˆì´ì–´ë“¤ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œ
          self.layer1 = self._make_layer(block, self.output_channel_block[0], layers[0])
          self.layer2 = self._make_layer(block, self.output_channel_block[1], layers[1], stride=1)
          self.layer3 = self._make_layer(block, self.output_channel_block[2], layers[2], stride=1)
          self.layer4 = self._make_layer(block, self.output_channel_block[3], layers[3], stride=1)

          # ê° ë ˆì´ì–´ì— ëŒ€í•œ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì •ì˜
          self.conv1 = nn.Conv2d(self.output_channel_block[0], self.output_channel_block[
                                0], kernel_size=3, stride=1, padding=1, bias=False)
          self.conv2 = nn.Conv2d(self.output_channel_block[1], self.output_channel_block[
                                1], kernel_size=3, stride=1, padding=1, bias=False)
          self.conv3 = nn.Conv2d(self.output_channel_block[2], self.output_channel_block[
                                2], kernel_size=3, stride=1, padding=1, bias=False)
          self.conv4_1 = nn.Conv2d(self.output_channel_block[3], self.output_channel_block[
                                  3], kernel_size=2, stride=(2, 1), padding=(0, 1), bias=False)
          self.conv4_2 = nn.Conv2d(self.output_channel_block[3], self.output_channel_block[
                                  3], kernel_size=1, stride=1, padding=0, bias=False)

          # ê° ë ˆì´ì–´ì— ëŒ€í•œ ë°°ì¹˜ ì •ê·œí™” ë ˆì´ì–´ ì •ì˜
          self.bn1 = nn.BatchNorm2d(self.output_channel_block[0])
          self.bn2 = nn.BatchNorm2d(self.output_channel_block[1])
          self.bn3 = nn.BatchNorm2d(self.output_channel_block[2])
          self.bn4_1 = nn.BatchNorm2d(self.output_channel_block[3])
          self.bn4_2 = nn.BatchNorm2d(self.output_channel_block[3])

      # ê° ResNet ë ˆì´ì–´ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
      def _make_layer(self, block, planes, blocks, stride=1):
          downsample = None
          if stride != 1 or self.inplanes != planes * block.expansion:
              downsample = nn.Sequential(
                  nn.Conv2d(self.inplanes, planes * block.expansion,
                            kernel_size=1, stride=stride, bias=False),
                  nn.BatchNorm2d(planes * block.expansion),
              )

          layers = []
          layers.append(block(self.inplanes, planes, stride, downsample))
          self.inplanes = planes * block.expansion
          for i in range(1, blocks):
              layers.append(block(self.inplanes, planes))

          return nn.Sequential(*layers)

      # ìˆœì „íŒŒ í•¨ìˆ˜ ì •ì˜
      def forward(self, x):
          x = self.conv0_1(x)
          x = self.bn0_1(x)
          x = self.relu(x)
          x = self.conv0_2(x)
          x = self.bn0_2(x)
          x = self.relu(x)

          x = self.maxpool1(x)
          x = self.layer1(x)
          x = self.conv1(x)
          x = self.bn1(x)
          x = self.relu(x)

          x = self.maxpool2(x)
          x = self.layer2(x)
          x = self.conv2(x)
          x = self.bn2(x)
          x = self.relu(x)

          x = self.maxpool3(x)
          x = self.layer3(x)
          x = self.conv3(x)
          x = self.bn3(x)
          x = self.relu(x)

          x = self.layer4(x)
          x = self.conv4_1(x)
          x = self.bn4_1(x)
          x = self.relu(x)
          x = self.conv4_2(x)
          x = self.bn4_2(x)
          x = self.relu(x)

          return x
  ```
  </div>
  </details>
<br>

- Sequence Modeling (Seq.): **None**<br>
â–¶ Sequence Modelingì€ ìˆ˜í–‰í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ íŒ¨ìŠ¤

- Prediction (Pred.): **CTC**
  <details>
  <summary>ì½”ë“œ ì ‘ê¸°/í¼ì¹˜ê¸°</summary>
  <div markdown="1">
  ```python
  import torch
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  class CTCLabelConverter(object):
      """ í…ìŠ¤íŠ¸ ë¼ë²¨ê³¼ í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ ê°„ì˜ ë³€í™˜ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ """

      def __init__(self, character):
          # character (str): ê°€ëŠ¥í•œ ë¬¸ì ì§‘í•©.
          dict_character = list(character)

          self.dict = {}
          for i, char in enumerate(dict_character):
              # ì°¸ê³ : CTCLossì—ì„œ í•„ìš”í•œ 'CTCblank' í† í°ì„ ìœ„í•´ 0ì„ ì˜ˆì•½í•©ë‹ˆë‹¤.
              self.dict[char] = i + 1

          self.character = ['[CTCblank]'] + dict_character  # CTCLossë¥¼ ìœ„í•œ ë”ë¯¸ '[CTCblank]' í† í° (ì¸ë±ìŠ¤ 0)

      def encode(self, text, batch_max_length=25):
          """ í…ìŠ¤íŠ¸ ë¼ë²¨ì„ í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
          ì…ë ¥:
              text: ê° ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ ë¼ë²¨. [batch_size]
              batch_max_length: ë°°ì¹˜ì—ì„œ í…ìŠ¤íŠ¸ ë¼ë²¨ì˜ ìµœëŒ€ ê¸¸ì´. ê¸°ë³¸ê°’ì€ 25

          ì¶œë ¥:
              text: CTCLossë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤. [batch_size, batch_max_length]
              length: ê° í…ìŠ¤íŠ¸ì˜ ê¸¸ì´. [batch_size]
          """
          length = [len(s) for s in text]

          # 0ìœ¼ë¡œ íŒ¨ë”©ëœ ì¸ë±ìŠ¤ëŠ” CTC ì†ì‹¤ ê³„ì‚°ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
          batch_text = torch.LongTensor(len(text), batch_max_length).fill_(0)
          for i, t in enumerate(text):
              text = list(t)
              text = [self.dict[char] for char in text]
              batch_text[i][:len(text)] = torch.LongTensor(text)
          return (batch_text.to(device), torch.IntTensor(length).to(device))

      def decode(self, text_index, length):
          """ í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ë¥¼ í…ìŠ¤íŠ¸ ë¼ë²¨ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. """
          texts = []
          for index, l in enumerate(length):
              t = text_index[index, :]

              char_list = []
              for i in range(l):
                  if t[i] != 0 and (not (i > 0 and t[i - 1] == t[i])):  # ë°˜ë³µëœ ë¬¸ìì™€ ë¸”ë­í¬ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
                      char_list.append(self.character[t[i]])
              text = ''.join(char_list)

              texts.append(text)
          return texts
  ```
  </div>
  </details>
  <br>

### ëª¨ë¸ í‰ê°€ ê²°ê³¼
ì•„ë˜ ê²°ê³¼ ê·¸ë¦¼ì€ ë‹¤ì„¯ ê°€ì§€ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ë“¤ì˜ ì •ë°€ë„(Precision)ì™€ ì¬í˜„ìœ¨(Recall)ì„ ë¹„êµí•˜ê³  ìˆìŠµë‹ˆë‹¤.<br>

"Tesseract"ëŠ” ë†’ì€ ì¬í˜„ìœ¨ì„ ë³´ì´ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ê³ , "Deep Text Recognition"ì€ ì •í™•ë„ê°€ ì¤‘ê°„ ìˆ˜ì¤€ì´ì§€ë§Œ ë†’ì€ ì¬í˜„ìœ¨ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ë¥¼ í†µí•´ ê° ëª¨ë¸ì˜ ì¥ë‹¨ì ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br>

ê²°ë¡ ì ìœ¼ë¡œ ì œì•ˆí•˜ëŠ” TPS-ResNet-None-CTC ì¡°í•©ì˜ í”„ë ˆì„ì›Œí¬ ëª¨ë¸("Drawing Text Recognition")ì´ ë‹¤ë¥¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ë“¤ ë³´ë‹¤ ë›°ì–´ë‚œ ì„¤ê³„ ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ ì¸ì‹ ì„±ëŠ¥ì„ ë³´ì´ë¯€ë¡œ ì„¤ê³„ ë„ë©´ í…ìŠ¤íŠ¸ ì¸ì‹ì— ìµœì í™”ë˜ì—ˆë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤.

<div align="center">
<img src="../../assets/images/2023-10-10-PnID(5)/result.png" alt="Result" />
</div>
<center>[ ë”¥ëŸ¬ë‹ ëª¨ë¸ë³„ ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ ì¸ì‹ ê²°ê³¼ ]</center>

- Matplotlib ì½”ë“œ
  <details>
  <summary>ì½”ë“œ ì ‘ê¸°/í¼ì¹˜ê¸°</summary>
  <div markdown="1">
  ```python
  import matplotlib.pyplot as plt
  from matplotlib.font_manager import FontProperties

  # ë°ì´í„°
  models = ['Tesseract', 'Rosetta', 'Star-Net', 'Deep Text Recognition', '(Our) Drawing Text Recognition']
  precision = [61.6, 89.76, 87.46, 82.94, 92.41]
  recall = [99.26, 99.31, 99.18, 99.2, 99.32]

  # ë¶„ì‚°í˜• ì°¨íŠ¸ ê·¸ë¦¬ê¸°
  plt.figure(figsize=(10, 6))

  # ê° ëª¨ë¸ì— ëŒ€í•œ íŠ¹ì • ë§ˆì»¤ ë° ìƒ‰ìƒ ì‚¬ìš©í•˜ì—¬ ì  ê·¸ë¦¬ê¸°
  plt.scatter(recall[0], precision[0], color='gray', marker='s', label='Tesseract')  # íšŒìƒ‰ ì •ì‚¬ê°í˜•
  plt.scatter(recall[1], precision[1], color='red', marker='^', label='Rosetta')  # ë¹¨ê°„ìƒ‰ ì‚¼ê°í˜•
  plt.scatter(recall[2], precision[2], color='#f2bb05', marker='*', label='Star-Net')  # ë…¸ë€ìƒ‰ ë³„ëª¨ì–‘
  plt.scatter(recall[3], precision[3], color='green', marker='D', label='Deep Text Recognition')  # ì´ˆë¡ìƒ‰ ë‹¤ì´ì•„ëª¬ë“œ
  plt.scatter(recall[4], precision[4], color='blue', marker='o', label='(Our) Drawing Text Recognition')  # íŒŒë€ìƒ‰ ë™ê·¸ë¼ë¯¸


  # ëŒ€ê°ì„  ê°€ì´ë“œì„  ì¶”ê°€
  plt.plot([99.15, 99.35], [60, 100], color='#707070', linestyle='--', linewidth=0.5)

  plt.xlabel('Recall(%)')
  plt.ylabel('Precision(%)')
  plt.title('Results of Text Recognition in Drawings by Deep Learning Models')

  # X ì¶•ê³¼ Y ì¶•ì˜ ë²”ìœ„ ì„¤ì •
  plt.xlim(99.15, 99.35)
  plt.ylim(60.0, 100.0)

  # ë²”ë¡€ ì¶”ê°€ ë° êµµì€ ê¸€ê¼´ ì„¤ì •
  legend = plt.legend()
  font = FontProperties(weight='bold')  # êµµì€ ê¸€ê¼´ ì„¤ì •
  for text in legend.texts:
      if text.get_text() == '(Our) Drawing Text Recognition':
          text.set_font_properties(font)  # êµµì€ ê¸€ê¼´ ì ìš©

  plt.grid(True)
  plt.show()
  ```
  </div>
  </details>
  <br>

## 4. ê²°ë¡ 

ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì„¤ê³„ ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ ì˜ì—­ì„ íƒì§€í•˜ê³  ì¸ì‹í•˜ëŠ” ê¸°ìˆ ì— ëŒ€í•´ ë‹¤ë¤˜ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ê±´ì„¤ í”„ë¡œì íŠ¸ì˜ ë„ë©´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªì—ˆì§€ë§Œ, ì´ëŸ¬í•œ ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì˜ ì„¤ê³„ì™€ í‰ê°€ë¥¼ í†µí•´ ë›°ì–´ë‚œ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

ìš°ë¦¬ëŠ” "Transformation(Trans.)", "Feature Extraction(Feat.)", "Sequence Modeling(Seq.)", ê·¸ë¦¬ê³  "Prediction(Pred.)" ì´ë ‡ê²Œ ë„¤ ê°€ì§€ í•µì‹¬ ìŠ¤í…Œì´ì§€ë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ì¸ì‹ ëª¨ë¸ì„ ë¶„ì„í•˜ê³  ì„¤ê³„í•˜ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ Transformation ë‹¨ê³„ì—ì„œëŠ” Thin-Plate Spline(TPS) ë³€í™˜ì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ í…ìŠ¤íŠ¸ í˜•íƒœë¥¼ ë³´ì •í•˜ê³ , Feature Extraction ë‹¨ê³„ì—ì„œëŠ” ResNet ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ì˜€ìŠµë‹ˆë‹¤. Sequence Modeling ë‹¨ê³„ì—ì„œëŠ” ë¬¸ë§¥ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ë” ë‚˜ì€ ì‹œí€€ìŠ¤ë¥¼ í˜•ì„±í•˜ê³ , Prediction ë‹¨ê³„ì—ì„œëŠ” Connectionist Temporal Classification(CTC)ì™€ Attention-based Sequence Prediction(Attn)ì„ ë¹„êµí•˜ì—¬ ë›°ì–´ë‚œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

í¬ìŠ¤íŠ¸ì—ì„œ ì œì•ˆí•œ TPS-ResNet-None-CTC ì¡°í•©ì˜ í”„ë ˆì„ì›Œí¬ ëª¨ë¸(Drawing Text Recognition)ì€ ë‹¤ë¥¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ë“¤ë³´ë‹¤ ë›°ì–´ë‚œ ì„¤ê³„ ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ ì¸ì‹ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ ì •ë°€ë„ ì¸¡ë©´ì—ì„œ ìš°ìˆ˜í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆê³ , ì´ëŠ” í˜„ì¥ì—ì„œì˜ ì‹¤ìš©ì„±ê³¼ ì •í™•ì„±ì„ í™•ë³´í•˜ëŠ” ë° í° ê¸°ì—¬ë¥¼ í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

ì´ëŸ¬í•œ ì—°êµ¬ë¥¼ í†µí•´ ì„¤ê³„ ë„ë©´ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” ê¸°ìˆ ì˜ í˜ì‹ ê³¼ ë°œì „ì— ì¼ì¡°í•  ìˆ˜ ìˆì„ ê²ƒì´ë©°, ë¯¸ë˜ì—ëŠ” ë”ìš± ì •í™•í•˜ê³  ë¹ ë¥¸ í…ìŠ¤íŠ¸ ì¸ì‹ ê¸°ìˆ ì´ ì‚°ì—… í˜„ì¥ì—ì„œ í™œìš©ë  ê²ƒì„ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤.