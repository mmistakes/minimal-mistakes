# ìœ„í‚¤ë°±ê³¼ í…ìŠ¤íŠ¸ í¬ë¡¤ë§ (rì½”ë“œ)
```
library(rvest)

# 1. ì¡°ì„  êµ­ì™• ë¦¬ìŠ¤íŠ¸
kings <- c("íƒœì¡°_(ì¡°ì„ )", "ì •ì¢…_(ì¡°ì„ )", "íƒœì¢…_(ì¡°ì„ )", "ì„¸ì¢…", "ë¬¸ì¢…_(ì¡°ì„ )", "ë‹¨ì¢…_(ì¡°ì„ )", "ì„¸ì¡°_(ì¡°ì„ )", "ì˜ˆì¢…_(ì¡°ì„ )", "ì„±ì¢…_(ì¡°ì„ )", "ì—°ì‚°êµ°",
           "ì¤‘ì¢…_(ì¡°ì„ )", "ì¸ì¢…_(ì¡°ì„ )", "ëª…ì¢…_(ì¡°ì„ )", "ì„ ì¡°_(ì¡°ì„ )", "ê´‘í•´êµ°", "ì¸ì¡°_(ì¡°ì„ )", "íš¨ì¢…_(ì¡°ì„ )", "í˜„ì¢…_(ì¡°ì„ )", "ìˆ™ì¢…_(ì¡°ì„ )", "ê²½ì¢…_(ì¡°ì„ )",
           "ì˜ì¡°_(ì¡°ì„ )", "ì •ì¡°_(ì¡°ì„ )", "ìˆœì¡°_(ì¡°ì„ )", "í—Œì¢…_(ì¡°ì„ )", "ì² ì¢…_(ì¡°ì„ )", "ê³ ì¢…_(ì¡°ì„ )", "ìˆœì¢…_(ì¡°ì„ )")

# 2. ìƒˆë¡œìš´ í´ë” ìƒì„± (íŒŒì¼ ì €ì¥í•  ìœ„ì¹˜)
dir.create("kings_full_texts", showWarnings = FALSE)

# 3. ëª¨ë“  êµ­ì™•ì˜ ìœ„í‚¤ë°±ê³¼ ë³¸ë¬¸ í¬ë¡¤ë§ & ì €ì¥
for (king in kings) {
  # ì™•ì˜ ìœ„í‚¤ë°±ê³¼ URL ë§Œë“¤ê¸°
  url <- paste0("https://ko.wikipedia.org/wiki/", king)
  
  # HTML ì½ê¸°
  page <- try(read_html(url), silent = TRUE)
  
  if (inherits(page, "try-error")) {
    print(paste("í˜ì´ì§€ ì˜¤ë¥˜:", king))
    next
  }
  
  # ë³¸ë¬¸ ì „ì²´ ê°€ì ¸ì˜¤ê¸°
  full_text <- page %>%
    html_nodes("#mw-content-text") %>%
    html_text(trim = TRUE)
  
  # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
  file_name <- paste0("kings_full_texts/", king, ".txt")
  writeLines(full_text, file_name, useBytes = TRUE)
  
  print(paste("ì €ì¥ ì™„ë£Œ:", file_name))  # ì§„í–‰ ìƒí™© ì¶œë ¥
}

print("ëª¨ë“  êµ­ì™•ì˜ ìœ„í‚¤ë°±ê³¼ ë³¸ë¬¸ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!")
```

# ê³ ì „ db ì‚¬ì´íŠ¸ ë„ì„œ ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ (python)
## ë§í¬ : https://db.itkc.or.kr/dir/item?itemId=MO#/dir/list?qw=&q=&grpId=&itemId=MO&gubun=book&cate1=&cate2=&upSeoji=&listType=simple&sortField=&sortOrder=&pageIndex={i}&pageUnit=100
```{python}
!pip install playwright
!playwright install

import asyncio
from playwright.async_api import async_playwright
import pandas as pd

async def run():
    data = []

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()

        # ì›í•˜ëŠ” í˜ì´ì§€ ìˆ˜ë§Œí¼ ë°˜ë³µ
        for i in range(1, 14):  # ì˜ˆ: 1~13í˜ì´ì§€ê¹Œì§€
            print(f"í¬ë¡¤ë§ ì¤‘: {i}í˜ì´ì§€")
            url = f"https://db.itkc.or.kr/dir/item?itemId=MO#/dir/list?qw=&q=&grpId=&itemId=MO&gubun=book&cate1=&cate2=&upSeoji=&listType=simple&sortField=&sortOrder=&pageIndex={i}&pageUnit=100"
            await page.goto(url)
            await page.wait_for_timeout(2000)  # JS ë¡œë”© ì‹œê°„ ëŒ€ê¸°

            rows = await page.query_selector_all("tbody > tr")
            for row in rows:
                cols = await row.query_selector_all("td")
                if len(cols) >= 4:
                    title = await cols[0].inner_text()
                    author = await cols[1].inner_text()
                    year = await cols[2].inner_text()
                    collection = await cols[3].inner_text()
                    data.append({
                        "ì„œëª…": title,
                        "ì €ì": author,
                        "ê°„í–‰ë…„": year,
                        "ì§‘ìˆ˜ëª…": collection
                    })

        await browser.close()

    # DataFrame ìƒì„± ë° ì €ì¥
    df = pd.DataFrame(data)
    df.to_csv("itkc_books.csv", index=False)
    print("CSV ì €ì¥ ì™„ë£Œ!")

# ë¹„ë™ê¸° ì‹¤í–‰
await run()
```

# ë‚˜ë¬´ìœ„í‚¤ ë¯¸ëŸ¬ ì‚¬ì´íŠ¸ í¬ë¡¤ë§ (python)
```
import requests
from bs4 import BeautifulSoup

# ë¯¸ëŸ¬ ì‚¬ì´íŠ¸ URL (ì¡°ì„  êµ°ì£¼)
url = "https://namu.moe/w/íƒœì¡°(ì¡°ì„ )"

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
}

response = requests.get(url, headers=headers)
soup = BeautifulSoup(response.text, 'html.parser')

text = soup.get_text()

# ì €ì¥
with open("joseon_kings_from_namu_mirror.txt", "w", encoding="utf-8") as f:
    f.write(text)

print("ë¯¸ëŸ¬ì‚¬ì´íŠ¸ì—ì„œ ì¡°ì„  êµ­ì™• ì •ë³´ ì €ì¥ ì™„ë£Œ!")

import requests
from bs4 import BeautifulSoup
import os

# ì¡°ì„  êµ­ì™• ë¦¬ìŠ¤íŠ¸
kings = [
    "íƒœì¡°(ì¡°ì„ )", "ì •ì¢…(ì¡°ì„ )", "íƒœì¢…(ì¡°ì„ )", "ì„¸ì¢…", "ë¬¸ì¢…(ì¡°ì„ )", "ë‹¨ì¢…(ì¡°ì„ )", "ì„¸ì¡°(ì¡°ì„ )", "ì˜ˆì¢…(ì¡°ì„ )", "ì„±ì¢…(ì¡°ì„ )", "ì—°ì‚°êµ°",
    "ì¤‘ì¢…(ì¡°ì„ )", "ì¸ì¢…(ì¡°ì„ )", "ëª…ì¢…(ì¡°ì„ )", "ì„ ì¡°(ì¡°ì„ )", "ê´‘í•´êµ°", "ì¸ì¡°", "íš¨ì¢…(ì¡°ì„ )", "í˜„ì¢…(ì¡°ì„ )", "ìˆ™ì¢…(ì¡°ì„ )", "ê²½ì¢…(ì¡°ì„ )",
    "ì˜ì¡°(ì¡°ì„ )", "ì •ì¡°(ì¡°ì„ )", "ìˆœì¡°", "í—Œì¢…(ì¡°ì„ )", "ì² ì¢…(ì¡°ì„ )", "ê³ ì¢…(ì¡°ì„ )", "ìˆœì¢…(ì¡°ì„ )"
]

# í—¤ë”
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
}

# ì €ì¥ í´ë” ìƒì„±
output_folder = "joseon_kings_txt"
os.makedirs(output_folder, exist_ok=True)

# ê° ì™•ë³„ íŒŒì¼ ì €ì¥
for king in kings:
    url_name = king.replace(" ", "_")  # ê³µë°± URL ì¸ì½”ë”©
    url = f"https://namu.moe/w/{url_name}"

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        page_text = soup.get_text()

        # íŒŒì¼ ì´ë¦„ ê¹¨ì§ ë°©ì§€ìš© (ê´„í˜¸ í¬í•¨ëœ ì´ë¦„ì€ ìœˆë„ìš°ì—ì„œ ì—ëŸ¬ë‚  ìˆ˜ë„ ìˆì–´ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        safe_filename = king.replace("/", "_")

        with open(f"{output_folder}/{safe_filename}.txt", "w", encoding="utf-8") as f:
            f.write(page_text)

        print(f"âœ… {king} ì €ì¥ ì™„ë£Œ: {safe_filename}.txt")

    except Exception as e:
        print(f"âŒ {king} ì €ì¥ ì‹¤íŒ¨: {e}")

print("\nğŸ‰ ëª¨ë“  ì¡°ì„  êµ­ì™• íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
```

