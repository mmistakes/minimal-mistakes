---
title: '[Kaggle/CV] Protein Atlas - ë°ì´í„° ì‚´í´ë³´ê¸°, baseline model ğŸ§¬'
toc: true
toc_sticky: true
categories:
  - kaggle
---
## 1. Protein Atlas

### 1.0 ë“¤ì–´ê°€ë©°
Protein Atlasì—ëŠ” ë‹¤ì–‘í•œ ë‹¨ë°±ì§ˆ ì†Œê¸°ê´€ë“¤ì˜ ì‚¬ì§„ì´ ìˆëŠ”ë°, ë°ì´í„°ì…‹ì—ëŠ” 28 ì¢…ë¥˜ì˜ ë‹¨ë°±ì§ˆ ì†Œê¸°ê´€ ì´ë¯¸ì§€ë“¤ì´ ë“¤ì–´ìˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ì˜ ëª©í‘œëŠ” ê° ë‹¨ë°±ì§ˆ ì´ë¯¸ì§€ë“¤ì´ 28ê°œì˜ ë‹¨ë°±ì§ˆ ì¢…ë¥˜ ì¤‘ ì–´ë–¤ ì¢…ë¥˜ì˜ ë‹¨ë°±ì§ˆ ì†Œê¸°ê´€ì´ ë“¤ì–´ìˆëŠ”ì§€ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•´ì„œ ë¬¸ì œë¥¼ í‘¸ëŠ” ê²ƒì´ë‹¤. ì´ë²ˆ Protein Atlas ë¬¸ì œì˜ ë°ì´í„°ì…‹ì€ êµ‰ì¥íˆ í¬ê³  ì–´ë ¤ìš´ ë¬¸ì œì´ê¸° ë•Œë¬¸ì— ë°ì´í„°ë¥¼ ì‚´í´ë³´ëŠ” ê³¼ì •ë¶€í„° ì°¨ê·¼ì°¨ê·¼ ë‚˜ì•„ê°„ë‹¤. ì´ë²ˆ ì½”ë“œëŠ” (https://www.kaggle.com/code/allunia/protein-atlas-exploration-and-baselinehttps://www.kaggle.com/code/allunia/protein-atlas-exploration-and-baseline)ì˜ ì½”ë“œë¥¼ ì°¸ê³ í•´ì„œ ì‘ì„±í–ˆë‹¤.

### 1.1 ë°ì´í„° ì‚´í´ë³´ê¸°

#### 1.1.1 ë°ì´í„°, íŒ¨í‚¤ì§€ ë¡œë“œí•˜ê¸°



```python
import numpy as np
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
from PIL import Image
from imageio import imread

import tensorflow as tf
sns.set()

import os
print(os.listdir('../input'))

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
```

    ['human-protein-atlas-image-classification']



```python
train_labels = pd.read_csv('../input/human-protein-atlas-image-classification/train.csv')
train_labels.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>
      <td>16 0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>
      <td>7 1 2 0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>
      <td>18</td>
    </tr>
  </tbody>
</table>
</div>




```python
# í›ˆë ¨ ë°ì´í„° ì´ë¯¸ì§€ ê°œìˆ˜
train_labels.shape[0]
```




    31072




```python
# ìš°ë¦¬ê°€ ì˜ˆì¸¡í•´ì•¼í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì‚´í´ë³´ê¸°
test_path = "../input/human-protein-atlas-image-classification/test/"
submission = pd.read_csv("../input/human-protein-atlas-image-classification/sample_submission.csv")
submission.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>00008af0-bad0-11e8-b2b8-ac1f6b6435d0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0000a892-bacf-11e8-b2b8-ac1f6b6435d0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0006faa6-bac7-11e8-b2b7-ac1f6b6435d0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0008baca-bad7-11e8-b2b9-ac1f6b6435d0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000cce7e-bad4-11e8-b2b8-ac1f6b6435d0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



ìœ„ì˜ ì¶œë ¥ ê°’ì„ ë³´ë©´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ëŠ” ë ˆì´ë¸”ì´ ì •í•´ì ¸ìˆì§€ ì•Šë‹¤. ì´ì œ ìš°ë¦¬ê°€ ëª¨ë¸ì„ ë§Œë“¤ì–´ì„œ Predicted ì¹¸ì„ ì±„ì›Œì•¼ í•˜ëŠ” ê²ƒì´ë‹¤. ë‹¤ìŒ ì½”ë“œì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë“¤ì˜ ì´ë¦„ë“¤ì„ ì¶œë ¥í•´ë³´ê³ , ì˜ˆì¸¡í•´ì•¼í•˜ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°œìˆ˜ë¥¼ ì¶œë ¥í•´ë³´ì.


```python
test_names = submission.Id.values
print(len(test_names))
print(test_names[0])
```

    11702
    00008af0-bad0-11e8-b2b8-ac1f6b6435d0


ì´ì œ í›ˆë ¨ ë°ì´í„°ì˜ ë°ì´í„°í”„ë ˆì„ì„ ë§Œë“¤ê²ƒì¸ë°, ë¬¸ì œë¥¼ í’€ê¸° ì‰½ê²Œ í•˜ê¸° ìœ„í•´ì„œ ê° ë°ì´í„°ê°€ í•´ë‹¹ë˜ëŠ” íƒ€ê¹ƒê°’ì— ëŒ€í•´ì„œë§Œ '1'ì„ ë¶€ì—¬í•˜ê³  í•´ë‹¹ë˜ì§€ ì•ŠëŠ” í´ë˜ìŠ¤ëŠ” '0'ì„ ë¶€ì—¬í•´ì„œ ì´ì§„ë¶„ë¥˜ì˜ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê¸° ì‰¬ì›Œì¡Œë‹¤.


```python
label_names = {
    0:  "Nucleoplasm",  
    1:  "Nuclear membrane",   
    2:  "Nucleoli",   
    3:  "Nucleoli fibrillar center",   
    4:  "Nuclear speckles",
    5:  "Nuclear bodies",   
    6:  "Endoplasmic reticulum",   
    7:  "Golgi apparatus",   
    8:  "Peroxisomes",   
    9:  "Endosomes",   
    10:  "Lysosomes",   
    11:  "Intermediate filaments",   
    12:  "Actin filaments",   
    13:  "Focal adhesion sites",   
    14:  "Microtubules",   
    15:  "Microtubule ends",   
    16:  "Cytokinetic bridge",   
    17:  "Mitotic spindle",   
    18:  "Microtubule organizing center",   
    19:  "Centrosome",   
    20:  "Lipid droplets",   
    21:  "Plasma membrane",   
    22:  "Cell junctions",   
    23:  "Mitochondria",   
    24:  "Aggresome",   
    25:  "Cytosol",   
    26:  "Cytoplasmic bodies",   
    27:  "Rods & rings"
}

reverse_train_labels = dict((v,k) for k,v in label_names.items())

def fill_targets(row):
    row.Target = np.array(row.Target.split(" ")).astype(np.int)
    for num in row.Target:
        name = label_names[int(num)]
        row.loc[name] = 1
    return row

for key in label_names.keys():
    train_labels[label_names[key]] = 0

train_labels = train_labels.apply(fill_targets, axis=1)
train_labels.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Target</th>
      <th>Nucleoplasm</th>
      <th>Nuclear membrane</th>
      <th>Nucleoli</th>
      <th>Nucleoli fibrillar center</th>
      <th>Nuclear speckles</th>
      <th>Nuclear bodies</th>
      <th>Endoplasmic reticulum</th>
      <th>Golgi apparatus</th>
      <th>...</th>
      <th>Microtubule organizing center</th>
      <th>Centrosome</th>
      <th>Lipid droplets</th>
      <th>Plasma membrane</th>
      <th>Cell junctions</th>
      <th>Mitochondria</th>
      <th>Aggresome</th>
      <th>Cytosol</th>
      <th>Cytoplasmic bodies</th>
      <th>Rods &amp; rings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>
      <td>[16, 0]</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>
      <td>[7, 1, 2, 0]</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>
      <td>[5]</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>
      <td>[1]</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>
      <td>[18]</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows Ã— 30 columns</p>
</div>



ë‚˜ì¤‘ì— ì‚¬ìš©í•  ì œì¶œìš© í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ë°ì´í„° í”„ë ˆì„ë„ ì´ì§„ ë¶„ë¥˜ í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì.


```python
test_labels = pd.DataFrame(data=test_names, columns = ['Id'])
for col in train_labels.columns.values:
    if col != 'Id':
        test_labels[col] = 0
test_labels.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Target</th>
      <th>Nucleoplasm</th>
      <th>Nuclear membrane</th>
      <th>Nucleoli</th>
      <th>Nucleoli fibrillar center</th>
      <th>Nuclear speckles</th>
      <th>Nuclear bodies</th>
      <th>Endoplasmic reticulum</th>
      <th>Golgi apparatus</th>
      <th>...</th>
      <th>Microtubule organizing center</th>
      <th>Centrosome</th>
      <th>Lipid droplets</th>
      <th>Plasma membrane</th>
      <th>Cell junctions</th>
      <th>Mitochondria</th>
      <th>Aggresome</th>
      <th>Cytosol</th>
      <th>Cytoplasmic bodies</th>
      <th>Rods &amp; rings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>00008af0-bad0-11e8-b2b8-ac1f6b6435d0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0000a892-bacf-11e8-b2b8-ac1f6b6435d0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0006faa6-bac7-11e8-b2b7-ac1f6b6435d0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>3 rows Ã— 30 columns</p>
</div>



ë‹¹ì—°í•˜ì§€ë§Œ, ì•„ì§ ëª¨ë¸ì„ êµ¬ì¶•í•´ì„œ ì˜ˆì¸¡ì„ ì§„í–‰í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ëª¨ë“  í…ŒìŠ¤íŠ¸ ë°ì´í„° ì´ë¯¸ì§€ëŠ” ì–´ë–¤ íƒ€ê¹ƒê°’ì—ë„ í•´ë‹¹ë˜ì§€ ì•ŠëŠ”ë‹¤.

#### 1.1.2 í›ˆë ¨ ë°ì´í„°ì˜ ë¶„í¬ ì‚´í´ë³´ê¸°
í›ˆë ¨ ë°ì´í„°ì— ê° í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ê°€ ì–¼ë§ˆë‚˜ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ëŠ” ê²ƒ ë˜í•œ ì¢‹ì€ ë°©ë²•ì´ë‹¤. 


```python
target_counts = train_labels.drop(['Id','Target'],axis=1).sum(axis=0).sort_values(ascending=False)
plt.figure(figsize=(15,15))
sns.barplot(y=target_counts.index.values, x=target_counts.values, order=target_counts.index)
```




    <AxesSubplot:>




    
![kaggle_pro1](https://user-images.githubusercontent.com/77332628/202901044-c2241c92-4dfc-4271-b1f2-ab7d942bb618.png)
    


ë°ì´í„°ì˜ ë¶„í¬ë¥¼ í™•ì¸í•´ë³´ë‹ˆ ë¬´ì‹œí•  ìˆ˜ ìˆì„ ì •ë„ë¡œ ì ì€ ìˆ˜ì˜ íƒ€ê¹ƒê°’ë“¤ì´ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ Lipid droplets, Peroxisomes, Endosomes, Lysosomes, Microtubule ends, Rods&ringsëŠ” í›ˆë ¨ ë°ì´í„°ì— êµ‰ì¥íˆ ì ì€ ìˆ˜ê°€ ìˆê¸° ë•Œë¬¸ì— ëª¨ë¸ì´ ì •í™•í•œ ì˜ˆì¸¡ì„ í•˜ê¸° ì–´ë ¤ìš¸ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.

ì´ë²ˆì—” ê° ì´ë¯¸ì§€ë§ˆë‹¤ ëª‡ê°œì˜ í´ë˜ìŠ¤ë“¤ì´ í•´ë‹¹ë˜ëŠ”ì§€ ì‚´í´ë³´ì.


```python
train_labels['number_of_targets'] = train_labels.drop(['Id','Target'], axis=1).sum(axis=1)
count_perc = np.round(100*train_labels['number_of_targets'].value_counts() / train_labels.shape[0],2)
plt.figure(figsize=(20,5))
sns.barplot(x=count_perc.index.values, y=count_perc.values, palette='Reds')
plt.xlabel('Number of targets per image')
plt.ylabel('percentage of train data')
```




    Text(0, 0.5, 'percentage of train data')




    
![kaggle_pro2](https://user-images.githubusercontent.com/77332628/202901045-9c72a405-de96-41f2-84ab-aefdd567658b.png)
    


ë¶„ì„í•´ë³´ë‹ˆ 4ê°œ ì´ìƒì˜ íƒ€ê¹ƒê°’ì„ ê°€ì§€ëŠ” ë°ì´í„°ëŠ” ë¬´ì‹œí•  ìˆ˜ ìˆì„ ì •ë„ë¡œ ì ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— 3ê°œ ì´í•˜ì˜ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ì´ë¯¸ì§€ë§Œì„ ëª¨ë¸ì´ ì •í™•íˆ ë¶„ë¥˜í•  ê²ƒì´ë¼ê³  ì˜ˆìƒí•  ìˆ˜ ìˆë‹¤.

#### 1.1.3 ë°ì´í„°ê°„ ì—°ê´€ì„± í™•ì¸í•˜ê¸°
ë‹¤ìŒìœ¼ë¡œ ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ê°ê°ì˜ í´ë˜ìŠ¤ë“¤ì´ ì–¼ë§ˆë‚˜ ì—°ê´€ë˜ì–´ ìˆëŠ”ì§€ ì‚´í´ë³´ì.


```python
plt.figure(figsize=(15,15))
sns.heatmap(train_labels[train_labels.number_of_targets>1].drop(['Id','Target','number_of_targets'],axis=1).corr(), cmap='RdYlBu',vmin=-1,vmax=1)
```




    <AxesSubplot:>




    
![kaggle_pro3](https://user-images.githubusercontent.com/77332628/202901046-34f0105b-623d-4fff-8953-512a4c84c858.png)
    


ì¶œë ¥ëœ íˆíŠ¸ë§µì„ ë³´ë©´ ëŒ€ë¶€ë¶„ì˜ í´ë˜ìŠ¤ë“¤ì€ ì„œë¡œ ì‘ì€ ì—°ê´€ì„±ì„ ê°€ì§€ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ lysosomesì™€ endosomesëŠ” ê°•í•œ ì—°ê´€ì„±ì„ ê°€ì§€ê³  ìˆë‹¤. ê·¸ë¦¬ê³  ì´ ë‘˜ì´ endoplasmatic reticulumê³¼ ì–´ëŠ ì •ë„ì˜ ì—°ê´€ì„±ì„ ë„ëŠ” ê²ƒìœ¼ë¡œ ë³´ì•„ lysosomesì™€ endosomesëŠ” endoplasmatic reticulumì— ìœ„ì¹˜í•´ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  mitotic spindleê³¼ cytokinetic bridgeë„ ì„œë¡œ ì–´ëŠì •ë„ì˜ ì—°ê´€ì„±ì„ ë³´ì´ê³ , ì´ ë‘˜ì€ ë˜ microtubulesì™€ ì—°ê´€ì„±ì´ ìˆë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ ìœ„ ë°” ê·¸ë˜í”„ í˜•íƒœë¥¼ í†µí•´ì„œ ì•Œì•„ë³¸ í¬ì†Œí•œ ìˆ˜ì˜ ë°ì´í„°ì— í•´ë‹¹ë˜ëŠ” í´ë˜ìŠ¤ë“¤ì´ ì–´ë–¤ ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ê³¼ ì–´ë–»ê²Œ ì—°ê´€ë˜ì–´ ìˆëŠ”ì§€ ì‚´í´ë³´ì. 


```python
def find_counts(special_target, labels):
    counts = labels[labels[special_target] == 1].drop(['Id','Target','number_of_targets'],axis=1).sum(axis=0)
    counts = counts[counts>0]
    counts = counts.sort_values()
    return counts
```


```python
lyso_endo_counts = find_counts('Lysosomes',train_labels)
plt.figure(figsize=(10,3))
sns.barplot(x=lyso_endo_counts.index.values, y=lyso_endo_counts.values, palette='Blues')
plt.ylabel('Counts in train data')
plt.title('Lysosomes and Endosomes')
```




    Text(0.5, 1.0, 'Lysosomes and Endosomes')




    
![kaggle_pro4](https://user-images.githubusercontent.com/77332628/202901048-7978d994-f61a-4bdc-a3a7-844319d259aa.png)
    


ìœ„ì˜ íˆíŠ¸ë§µì—ì„œ ë¶„ì„í•œëŒ€ë¡œ lysosomesê³¼ endosomesëŠ” ê±°ì˜ í•­ìƒ ê°™ì€ ìœ„ì¹˜ì—ì„œ ë°œê²¬ë˜ê³ , ì´ ë‘˜ì´ endoplamic reticulumì— ìœ„ì¹˜í•´ ìˆëŠ” ì´ë¯¸ì§€ ë°ì´í„°ë„ 11ê°œì •ë„ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.


```python
rod_rings_counts = find_counts('Rods & rings',train_labels)
plt.figure(figsize=(10,3))
sns.barplot(x=rod_rings_counts.index.values, y=rod_rings_counts.values, palette='Greens')
plt.ylabel('Counts in train data')
plt.title('Rod & rings')
```




    Text(0.5, 1.0, 'Rod & rings')




    
![kaggle_pro5](https://user-images.githubusercontent.com/77332628/202901049-1265b39c-803b-4185-b3f3-db881d23d595.png)
    



```python
peroxi_counts = find_counts('Peroxisomes',train_labels)
plt.figure(figsize=(10,3))
sns.barplot(x=peroxi_counts.index.values, y=peroxi_counts.values, palette='Reds')
plt.ylabel('Counts in train data')
plt.xticks(rotation='30')
plt.title('Peroxisomes')
```




    Text(0.5, 1.0, 'Peroxisomes')




    
![kaggle_pro6](https://user-images.githubusercontent.com/77332628/202901050-56f8252c-7e7a-456a-9c1d-128c2f51d4c8.png)
    



```python
tubeends_counts = find_counts('Microtubule ends',train_labels)
plt.figure(figsize=(10,3))
sns.barplot(x=tubeends_counts.index.values, y=tubeends_counts.values, palette='Oranges')
plt.ylabel('Counts in train data')
plt.title('Microtubule ends')
```




    Text(0.5, 1.0, 'Microtubule ends')




    
![kaggle_pro7](https://user-images.githubusercontent.com/77332628/202901053-eda5e4b6-f776-4177-9f88-d74ec23a7f90.png)



```python
nuclear_speckles_counts = find_counts('Nuclear speckles',train_labels)
plt.figure(figsize=(10,3))
sns.barplot(x=nuclear_speckles_counts.index.values, y=nuclear_speckles_counts.values, palette='Purples')
plt.ylabel('Counts in train data')
plt.xticks(rotation='70')
plt.title('Nuclear speckles')
```




    Text(0.5, 1.0, 'Nuclear speckles')




    
![kaggle_pro8](https://user-images.githubusercontent.com/77332628/202901054-900013f6-f898-442e-9445-9863cb4c1073.png)
    


ìœ„ì˜ ë¶„ì„ì„ í†µí•´ì„œ ìš°ë¦¬ëŠ” ì•„ì£¼ ë“œë¬¼ê²Œ ë‚˜íƒ€ë‚˜ëŠ” í´ë˜ìŠ¤ì¼ì§€ë¼ë„ ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ê³¼ ì—°ê´€ì„±ì´ ìˆê³  ì´ ì—°ê´€ì„±ì„ í†µí•´ ìš°ë¦¬ëŠ” ë‹¨ë°±ì§ˆ ì†Œê¸°ê´€ì´ ì–´ë””ì— ìœ„ì¹˜í•´ ìˆëŠ”ì§€ ì•Œ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, rod&ringsëŠ” nucleusì™€ ì—°ê´€ë˜ì–´ìˆê³ , peroxisomesëŠ” nucleusì™€ cytosolì— ìœ„ì¹˜í•´ ìˆë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

#### 1.1.4 ì´ë¯¸ì§€ ì‹œê°í™”í•˜ê¸°
ë¨¼ì € train í´ë”ì— ìˆëŠ” ì´ë¯¸ì§€ íŒŒì¼ë“¤ì˜ íŒŒì¼ëª…ì„ ì¶œë ¥í•´ë³´ì


```python
from os import listdir

files = listdir('../input/human-protein-atlas-image-classification/train')
for n in range(10) : # ì²« ì—´ê°œë§Œ ìƒ˜í”Œë¡œ ì¶œë ¥
    print(files[n])
```

    5e3a2e6a-bb9c-11e8-b2b9-ac1f6b6435d0_red.png
    9891a4fa-bba4-11e8-b2b9-ac1f6b6435d0_red.png
    315a9edc-bbc6-11e8-b2bc-ac1f6b6435d0_yellow.png
    437fa1ce-bb9f-11e8-b2b9-ac1f6b6435d0_yellow.png
    8a51782e-bb9b-11e8-b2b9-ac1f6b6435d0_green.png
    0df0c3aa-bbca-11e8-b2bc-ac1f6b6435d0_blue.png
    bf0b3946-bbba-11e8-b2ba-ac1f6b6435d0_red.png
    641a0682-bbb7-11e8-b2ba-ac1f6b6435d0_green.png
    05d32f36-bba3-11e8-b2b9-ac1f6b6435d0_red.png
    168cbdc8-bb9f-11e8-b2b9-ac1f6b6435d0_red.png



```python
len(files) / 4 == train_labels.shape[0]
```




    True



ì¶œë ¥ëœ íŒŒì¼ëª…ë“¤ì„ ë³´ë©´ í™•ì¥ì ì•ì— red,yellow,greend,blueì˜ ìƒ‰ ì´ë¦„ì´ ë¶™ì–´ìˆë‹¤. ê° ì´ë¯¸ì§€ id í•˜ë‚˜ë‹¹ ë‹¤ìŒì˜ 4ê°€ì§€ í•„í„°ê°€ ì”Œì›Œì ¸ìˆë‹¤.
* target protein structure -> ì´ˆë¡
* nuclues -> íŒŒë‘
* microtubules -> ë¹¨ê°•
* endoplasmatic reticulum -> ë…¸ë‘
(ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ 512x512)

ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ í•„í„°ê°€ ì”Œì›Œì§„ ì´ë¯¸ì§€ë“¤ì„ ì‹œê°í™”í•´ë³´ì.


```python
train_path = '../input/human-protein-atlas-image-classification/train/'

def load_image(basepath, image_id):
    images = np.zeros(shape=(4,512,512))
    images[0,:,:] = imread(basepath + image_id + "_green" + ".png")
    images[1,:,:] = imread(basepath + image_id + "_red" + ".png")
    images[2,:,:] = imread(basepath + image_id + "_blue" + ".png")
    images[3,:,:] = imread(basepath + image_id + "_yellow" + ".png")
    return images

def make_image_row(image,subax,title):
    subax[0].imshow(image[0], cmap='Greens')
    subax[0].set_title(title)
    subax[1].imshow(image[1], cmap='Reds')
    subax[1].set_title('stained microtubules')
    subax[2].imshow(image[2], cmap='Blues')
    subax[2].set_title('stained nucleus')
    subax[3].imshow(image[3], cmap='Oranges')
    subax[1].set_title('stained endoplasmatic reticulum')
    return subax

def make_title(file_id):
    file_targets = train_labels.loc[train_labels.Id==file_id, 'Target'].values[0]
    title=' - '
    for n in file_targets:
        title += label_names[n] + ' - '
    return title
```


```python
class TargetGroupIterator:
    def __init__(self, target_names,batch_size, basepath):
        self.target_names = target_names
        self.target_list = [reverse_train_labels[key] for key in target_names]
        self.batch_shape = (batch_size, 4, 512, 512)
        self.basepath = basepath
    
    def find_matching_data_entries(self):
        train_labels['check_col'] = train_labels.Target.apply(
            lambda l : self.check_subset(l))
        self.images_identifier = train_labels[train_labels.check_col==1].Id.values
        train_labels.drop('check_col',axis=1,inplace=True)
        
    def check_subset(self,targets):
        return np.where(set(self.target_list).issubset(set(targets)),1,0)
    
    def get_loader(self):
        filenames = []
        idx = 0
        images = np.zeros(self.batch_shape)
        for image_id in self.images_identifier:
            images[idx,:,:,:] = load_image(self.basepath, image_id)
            filenames.append(image_id)
            idx += 1
            if idx == self.batch_shape[0]:
                yield filenames, images
                filenames = []
                images = np.zeros(self.batch_shape)
                idx = 0
        if idx > 0:
            yield filenames, images
            
```

ìœ„ì—ì„œ ì´ë¯¸ì§€ ì¶œë ¥ì„ ìœ„í•œ í´ë˜ìŠ¤ì™€ í•¨ìˆ˜ë¥¼ ì •ì˜í–ˆìœ¼ë‹ˆ, íŠ¹ì • í´ë˜ìŠ¤ë¥¼ ì •í•´ì„œ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•˜ë©´ ëœë‹¤. ë‚˜ëŠ” lysosomesì™€ endosomesë¥¼ ì„ íƒí–ˆëŠ”ë°, ë³¸ì¸ì´ ì›í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ì„ íƒí•´ì„œ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•˜ë©´ ëœë‹¤.


```python
my_choice = ['Lysosomes','Endosomes']
my_batch_size = 20

imageloader = TargetGroupIterator(my_choice, my_batch_size, train_path)
imageloader.find_matching_data_entries()
iterator = imageloader.get_loader()
```


```python
file_ids, images = next(iterator)
fig,ax = plt.subplots(len(file_ids),4,figsize=(20,5*len(file_ids)))
if ax.shape==(4,):
    ax = ax.reshape(1,-1)
for n in range(len(file_ids)):
    make_image_row(images[n],ax[n],make_title(file_ids[n]))
```


    
![kaggle_pro9](https://user-images.githubusercontent.com/77332628/202901056-77a15b1a-3825-4ef1-90a2-19a3eaaf1ab6.png)
    


### 1.2 ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ êµ¬ì¶•í•˜ê¸°

#### 1.2.0 Kernel Setting
ê³„ì‚°ì‹œê°„ì„ ì¤„ì´ê¸° ìœ„í•´ ì´ë¯¸ í›ˆë ¨ëœ ê²°ê³¼ê°’ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì»¤ë„ ì„¤ì •ì„ í•´ì¤€ë‹¤.




```python
class KernelSettings:
    
    def __init__(self, fit_baseline=False,
                 fit_improved_baseline=True,
                 fit_improved_higher_batchsize=False,
                 fit_improved_without_dropout=False):
        self.fit_baseline = fit_baseline
        self.fit_improved_baseline = fit_improved_baseline
        self.fit_improved_higher_batchsize = fit_improved_higher_batchsize
        self.fit_improved_without_dropout = fit_improved_without_dropout
kernelsettings = KernelSettings(fit_baseline=False,
                                fit_improved_baseline=False,
                                fit_improved_higher_batchsize=False,
                                fit_improved_without_dropout=False)
use_dropout = True
```

#### 1.2.1 K-Fold Cross Validation ì‚¬ìš©í•˜ê¸°
ë¨¼ì € í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ë¹„ìœ¨ì„ ì•Œì•„ë³´ì.


```python
train_files = os.listdir("../input/human-protein-atlas-image-classification/train")
test_files = os.listdir("../input/human-protein-atlas-image-classification/test")
percentage = np.round(len(test_files) / len(train_files) * 100)
print('test set size turns out to be {} % compared to the train set.'.format(percentage))
```

    test set size turns out to be 38.0 % compared to the train set.


ì´ë²ˆ ê¸€ì—ì„œëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ì„œ **k-fold ê²€ì¦**ì„ ì‚¬ìš©í•  ê²ƒì´ë‹¤. kfold ê²€ì¦ ë°©ë²•ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´ í›ˆë ¨ ë°ì´í„°ë¥¼ kê°œë¡œ ë‚˜ëˆ ì„œ ê·¸ ì¤‘ í•˜ë‚˜ë¥¼ ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. kfold ê²€ì¦ì— ëŒ€í•œ ìì„¸í•œ ê¸€ì€ [**ì´ ê¸€**](https://hamin-chang.github.io/basics/kfold/)ì„ ì°¸ê³ í•˜ë©´ ëœë‹¤. í•˜ì§€ë§Œ ë‹¨ë°±ì§ˆ ì†Œê¸°ê´€ ë°ì´í„°ì˜ íŠ¹ì„±ìƒ kê°œì˜ í´ë“œ ì¤‘ ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©í–ˆì„ ë•Œ ìœ ë… ì¢‹ì€ ê²€ì¦ ì„±ëŠ¥ì´ ë‚˜ì˜¬ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë§Œì•½ ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©í•œ í´ë“œì— í¬ì†Œí•œ í´ë˜ìŠ¤ê°€ ë“¤ì–´ ìˆìœ¼ë©´ ë‚˜ìœ ê²€ì¦ ì„±ëŠ¥ì´ ë‚˜ì˜¬ ê²ƒì´ë‹¤. ì´ëŸ¬í•œ í˜„ìƒì˜ ì˜í–¥ì„ ì¤„ì´ê¸° ìœ„í•´ kfold ê²€ì¦ ë°©ë²•ì„ ì—¬ëŸ¬ë²ˆ ë°˜ë³µí•œë‹¤.

ìœ„ì˜ ì½”ë“œì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ í›ˆë ¨ ë°ì´í„°ì˜ 38% ì •ë„ì´ê¸° ë•Œë¬¸ì— kfoldë¥¼ 3ê°œë¡œ ë‚˜ëˆ ì„œ ì§„í–‰í•˜ë©´ í›ˆë ¨ ë°ì´í„°ì˜ 33%ë¥¼ ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— ì ì ˆí•  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. 3ê°œì˜ í´ë“œë¡œ ë‚˜ëˆ„ëŠ” kfold êµì°¨ ê²€ì¦ì„ 2ë²ˆ ë°˜ë³µí•˜ê² ë‹¤.


```python
from sklearn.model_selection import RepeatedKFold
splitter = RepeatedKFold(n_splits=3, n_repeats=1, random_state=0)
```

ìœ„ì—ì„œ ì •ì˜í•œ splitterë¥¼ ì´ë¯¸ì§€ idì—ë‹¤ê°€ ì ìš©í•  ê²ƒì´ë‹¤. kfoldê°€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê¸° ë•Œë¬¸ì— n_repeatsë¥¼ 1ë¡œ ì§€ì •í•´ì„œ í›ˆë ¨ ë°ì´í„°ë¥¼ 3ê°œë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ í•œë²ˆë§Œ ë°˜ë³µí•˜ë„ë¡ í•œë‹¤.


```python
partitions = []
for train_idx, valid_idx in splitter.split(train_labels.index.values):
    partition = {}
    partition['train'] = train_labels.Id.values[train_idx]
    partition['validation'] = train_labels.Id.values[valid_idx]
    partitions.append(partition)
    print('TRAIN:',train_idx,'VALIDATION:',valid_idx)
    print('TRAIN:',len(train_idx),'TEST:',len(valid_idx))
    
    
```

    TRAIN: [    1     2     3 ... 31063 31064 31065] VALIDATION: [    0     4     6 ... 31069 31070 31071]
    TRAIN: 20714 TEST: 10358
    TRAIN: [    0     4     6 ... 31069 31070 31071] VALIDATION: [    1     2     3 ... 31060 31061 31065]
    TRAIN: 20715 TEST: 10357
    TRAIN: [    0     1     2 ... 31069 31070 31071] VALIDATION: [   10    11    13 ... 31062 31063 31064]
    TRAIN: 20715 TEST: 10357



```python
partitions[0]['train'][0:5]
```




    array(['000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0',
           '000a9596-bbc4-11e8-b2bc-ac1f6b6435d0',
           '000c99ba-bba4-11e8-b2b9-ac1f6b6435d0',
           '001bcdd2-bbb2-11e8-b2ba-ac1f6b6435d0',
           '002daad6-bbc9-11e8-b2bc-ac1f6b6435d0'], dtype=object)



#### 1.2.2 Basline ëª¨ë¸ êµ¬ì¶•í•˜ê¸°
ì´ì œ ë³¸ê²©ì ì¸ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³¼ê±´ë°, ì´ë²ˆ ê¸€ì—ì„œëŠ” ë‹¨ìˆœí•œ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì„ ë§Œë“¤ê²ƒì´ë‹¤. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì€ ì¼€ë¼ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ë§Œë“¤ê²ƒì´ë‹¤. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì€ ë‹¤ìŒ ëª‡ê°€ì§€ ì•„ì´ë””ì–´ë“¤ì„ í¬í•¨í•´ì„œ êµ¬ì¶•í•œë‹¤.
* ë‹¨ìˆœí•œ ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ ë„¤ê°€ì§€ í•„í„° ì‚¬ì§„ë“¤ì¤‘ íƒ€ê¹ƒê°’ì— ëŒ€í•œ ê°€ì¥ ë§ì€ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” ì´ˆë¡ìƒ‰ í•„í„° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œë‹¤.
* ê°„ë‹¨í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•´ì„œ ì‚¬ìš©í•œë‹¤. 
* ë°ì´í„° ë¡œë”ì™€ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ì™€ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  íŒŒë¼ë¯¸í„°ë“¤ì„ ë‹´ê³  ìˆëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜í•´ì„œ ì‚¬ìš©í•œë‹¤.

ì‚¬ìš©í•  íŒŒë¼ë¯¸í„°ë“¤ì„ ë‹´ê³  ìˆëŠ” í´ë˜ìŠ¤ë¥¼ ë¨¼ì € ì •ì˜í•´ë³´ì.


```python
class ModelParameter:
    def __init__(self, basepath,
                num_classes=28,
                image_rows=512,
                image_cols=512,
                batch_size=200,
                n_channels=1,
                row_scale_factor=4,
                col_scale_factor=4,
                shuffle=False,
                n_epochs=1):
        self.basepath = basepath
        self.num_classes = num_classes
        self.image_rows = image_rows
        self.image_cols = image_cols
        self.batch_size = batch_size
        self.n_channels = n_channels
        self.shuffle = shuffle
        self.row_scale_factor = row_scale_factor
        self.col_scale_factor = col_scale_factor
        self.scaled_row_dim = np.int(self.image_rows / self.row_scale_factor)
        self.scaled_col_dim = np.int(self.image_cols / self.col_scale_factor)
        self.n_epochs = n_epochs
```

ì´ì œ ì´ í´ë˜ìŠ¤ë¥¼ datagenerator, ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸, ì´ë¯¸ì§€ ì „ì²˜ë¦¬ì— ì „ë‹¬í•˜ê¸° ìœ„í•´ ì •ì˜í•œë‹¤.


```python
parameter = ModelParameter(train_path)
```

ê·¸ ë‹¤ìŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•œë‹¤. 


```python
from skimage.transform import resize

class ImagePreprocessor :
    def __init__(self, modelparameter):
        self.parameter = modelparameter
        self.basepath = self.parameter.basepath
        self.scaled_row_dim = self.parameter.scaled_row_dim
        self.scaled_col_dim = self.parameter.scaled_col_dim
        self.n_channels = self.parameter.n_channels
    
    def preprocess(self,image):
        image = self.resize(image)
        image = self.reshape(image)
        image = self.normalize(image)
        return image
    
    def resize(self,image):
        image = resize(image, (self.scaled_row_dim, self.scaled_col_dim))
        return image
    
    def reshape(self,image):
        image = np.reshape(image, (image.shape[0],image.shape[1], self.n_channels))
        return image
    
    def normalize(self,image):
        image /= 255
        return image
    
    def load_image(self,image_id):
        image = np.zeros(shape=(512,512,4))
        image[:,:,0] = imread(self.basepath + image_id + '_green' + '.png')
        image[:,:,1] = imread(self.basepath + image_id + '_blue' + '.png')
        image[:,:,2] = imread(self.basepath + image_id + '_red' + '.png')
        image[:,:,3] = imread(self.basepath + image_id + '_yellow' + '.png')
        return image[:,:,0:self.parameter.n_channels]
```

ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ë¥¼ datageneratorì— ì „ë‹¬í•˜ê¸° ìœ„í•´ ì •ì˜í•œë‹¤.


```python
preprocessor = ImagePreprocessor(parameter)
```

ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ìƒ˜í”Œì„ ì¶œë ¥í•´ë³´ì.


```python
example = images[0,0]
preprocessed = preprocessor.preprocess(example)
print(example.shape) # ì „ì²˜ë¦¬ ì „ ì´ë¯¸ì§€ í¬ê¸°
print(preprocessed.shape) # ì „ì²˜ë¦¬ í›„ ì´ë¯¸ì§€ í¬ê¸°

fig, ax = plt.subplots(1,2,figsize=(20,10))
ax[0].imshow(example, cmap='Greens')
ax[1].imshow(preprocessed.reshape(parameter.scaled_row_dim, parameter.scaled_col_dim), cmap='Greens')
ax[0].set_title('before preprocess')
ax[1].set_title('after preprocess')
```

    (512, 512)
    (128, 128, 1)





    Text(0.5, 1.0, 'after preprocess')




    
![kaggle_pro10](https://user-images.githubusercontent.com/77332628/202901058-8bd32df8-f5a5-42aa-9b22-4d7f11f58be0.png)
    


ì¶œë ¥ëœ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ë¥¼ ë³´ë‹ˆ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì´ë‹ˆ ë” ìì„¸í•œ ì •ë³´ê°€ ë³´ì¸ë‹¤!

ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì„ ë§Œë“¤ê¸° ì „ì— ë§ˆì§€ë§‰ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜í•œë‹¤.


```python
import keras
import tensorflow

class DataGenerator(tensorflow.keras.utils.Sequence):
    def __init__(self,list_IDs,labels,modelparameter, imagepreprocessor):
        self.current_epoch = 0
        self.params = modelparameter
        self.labels = labels
        self.list_IDs = list_IDs
        self.dim = (self.params.scaled_row_dim, self.params.scaled_col_dim)
        self.batch_size = self.params.batch_size
        self.n_channels = self.params.n_channels
        self.num_classes = self.params.num_classes
        self.shuffle = self.params.shuffle
        self.preprocessor = imagepreprocessor
        self.on_epoch_end()
        
    def on_epoch_end(self):
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes, random_state=self.current_epoch)
            self.current_epoch += 1
    
    def get_targets_per_image(self,identifier):
        return self.labels.loc[self.Id == identifier].drop(
        ['Id','Target','number_of_targets'],axis=1).values
    
    def __data_generation(self,list_IDs_temp) :
        # Generates data containing batch_size samples
        X = np.empty((self.batch_size, *self.dim, self.n_channels))
        y = np.empty((self.batch_size, self.num_classes), dtype=int)
        # Generate data
        for i, identifier in enumerate(list_IDs_temp):
            image = self.preprocessor.load_image(identifier)
            image = self.preprocessor.preprocess(image)
            X[i] = image
            y[i] = self.get_targets_per_image(identifier)
        return X,y

    def __len__(self):
        return int(np.floor(len(self.list_IDs) / self.batch_size))
    
    def __get_item__(self,index):
        indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]
        list_IDs_temp = [self.list_IDs[k] for k in indexes]
        X,y = self.__data_generation(list_IDs_temp)
        return X,y
```


```python
class PredictGenerator : 
    def __init__(self, predict_Ids, imagepreprocessor, predict_path):
        self.preprocessor = imagepreprocessor
        self.preprocessor.basepath = predict_path
        self.identifiers = predict_Ids
        
    def predict(self, model):
        y = np.empty(shape=(len(self.identifiers), self.preprocessor.parameter.num_classes))
        for n in range(len(self.identifiers)):
            image = self.preprocessor.load_image(self.identifiers[n])
            image = self.preprocessorpre.preprocess(image)
            image = image.reshape((1,*image.shape))
            y[n] = model.predict(image)
        return y
```
ì´ì œ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì€ kerasì˜ Sequentialì„ ì‚¬ìš©í•´ì„œ layerë“¤ì„ ìŒ“ì•„ê°„ë‹¤.

```python
from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.losses import binary_crossentropy
from tensorflow.keras.optimizers import Adadelta
from keras.initializers import VarianceScaling # ì´ˆê¸° ê°€ì¤‘ì¹˜ ì„¤ì •

class BaseLineModel:
    def __init__(self,modelparameter):
        self.params = modelparameter
        self.num_classes = self.params.num_classes
        self.img_rows = self.params.scaled_row_dim
        self.img_cols = self.params.scaled_col_dim
        self.n_channels = self.params.n_channels
        self.input_shape = (self.img_rows, self.img_cols, self.n_channels)
        self.my_metrics = ['accuracy']
        
    def build_model(self):
        self.model = Sequential()
        self.model.add(Conv2D(16,kernel_size=(3,3), activation = 'relu',input_shape=self.input_shapein,
                             kernel_initializer=VarianceScaling(seed=0)))
        self.model.add(Conv2D(32,(3,3),activation='relu',kernel_initializer=VarianceScaling(seed=0)))
        self.model.add(MaxPooling2D(pool_size=(2,2)))
        self.model.add(Dropout(0.25))
        self.model.add(Flatten())
        self.model.add(Dense(64,activation='relu',
                            kernel_initializer=VarianceScaling(seed=0)))
        self.model.add(Dropout(0.5))
        # ì´ì§„ ë¶„ë¥˜ì´ê¸° ë•Œë¬¸ì— ë§ˆì§€ë§‰ í•„í„°ëŠ” sigmoid í™œì„±í™” ì‚¬ìš©
        self.model.add(Dense(self.num_classes, activation = 'sigmoid'))
        
    def compile_model(self):
        self.model.compile(loss=keras.binary_crossentropy,
                          optimizer = keras.optimizers.Adadelta(),
                          metrics = self.my_metrics)
    
    def set_generators(self,train_generator,validation_generator):
        self.training_generator = train_generator
        self.validation_generator = validation_generator
        
    def learn(self):
        return self.model.fit_generator(generator=self.training_generator,
                                       validation_data =self.validation_generator,
                                       epochs = self.params.n_epochs,
                                       use_multiprocessing = True,
                                       workers=8)
    
    def score(self):
        return self.model.evaluate_generator(generator=self.validation_generator,
                                            use_multiprocessing=True, workers=8)
    
    def predict(self,predict_generator):
        y = predict_generator.predict(self.model)
        return y
    
    def save(self, model_output_path):
        self.model.save(model_output_path)
        
    def load(self, model_input_path):
        self.model = load_model(model_input_path)
```

ì´ì œ ì²«ë²ˆì§¸ cross validation í´ë“œì—ì„œ í›ˆë ¨ì„ ì‹œì‘í• ê±´ë°, í›ˆë ¨ì„ ì‹œì‘í•˜ê¸°ì— ì•ì„œ í›ˆë ¨ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•œë‹¤.


```python
# ì²«ë²ˆì§¸ cross validation ë°ì´í„° ì¤€ë¹„
partition = partitions[0]
labels = train_labels

print('Number of data in train : ',len(partition['train']))
print('Number of data in validation : ',len(partition['validation']))
```

    Number of data in train :  20714
    Number of data in validation :  10358



```python
training_generator = DataGenerator(partition['train'],labels,parameter,preprocessor)
validation_generator = DataGenerator(partition['validation'],labels,parameter,preprocessor)
```

ê·¸ë¦¬ê³  ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•œ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ generatorì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬ë¥¼ ì •ì˜í•´ì£¼ê³ , ì œì¶œì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ generatorë¥¼ ì •ì˜í•œë‹¤.


```python
predict_generator = PredictGenerator(partition['validation'], preprocessor,train_path)
test_preprocessor = ImagePreprocessor(parameter)
submission_predict_generator = PredictGenerator(test_names, test_preprocessor, test_path)
```


```python
target_names = train_labels.drop(['Target','number_of_targets','Id'],axis=1).columns
if kernelsettings.fit_baseline == True:
    model = BaseLineModel(parameter)
    model.build_model()
    model.compile_model()
    model.set_generators(training_generator, validation_generator)
    history = model.learn()
    
    proba_predictions = model.predict(predict_generator)
    baseline_proba_predictions = pd.DataFrame(index=partition['validation'],
                                              data = proba_predictions,
                                              columns=target_names)
    baseline_proba_predictions.to_csv('baseline_predictions.csv')
    baseline_losses = pd.DataFrame(history.history['loss'], 
                                  columns = ['train_loss'])
    baseline_losses['val_loss'] = history.history['val_loss']
    baseline_losses.to_csv('baseline_losses.csv')
    submission_proba_predictions = model.predict(submission_predict_generator)
    baseline_labels = test_labels.copy()
    baseline_labels.loc[:, test_labels.drop(["Id", "Target"], axis=1).columns.values] = submission_proba_predictions
    baseline_labels.to_csv("baseline_submission_proba.csv")
    # ë§Œì•½ í›ˆë ¨(fit)ì„ í•œë²ˆ í–ˆë‹¤ë©´ ê²°ê³¼ë¥¼ ë‹¤ìš´ë°›ëŠ”ë‹¤. 
    # you can load predictions as csv and further fitting is not neccessary:
else:
    baseline_proba_predictions = pd.read_csv("../input/proteinatlaseabpredictions/baseline_predictions.csv", index_col=0)
    baseline_losses = pd.read_csv("../input/proteinatlaseabpredictions/baseline_losses.csv", index_col=0)
    baseline_labels = pd.read_csv("../input/proteinatlaseabpredictions/baseline_submission_proba.csv", index_col=0)

```

#### 1.2.3 í›ˆë ¨ ê²°ê³¼ ë¶„ì„í•˜ê¸°


```python
validation_labels = train_labels.loc[train_labels.Id.isin(partition["validation"])].copy()
validation_labels.shape
```




    (10358, 31)




```python
baseline_proba_predictions.shape
```




    (10358, 28)




```python
from sklearn.metrics import accuracy_score as accuracy

y_true = validation_labels.drop(['Id','Target','number_of_targets'],axis=1).values
y_pred = np.where(baseline_proba_predictions.values > 0.5,1,0)
accuracy(y_true.flatten(), y_pred.flatten())
```




    0.9413152015005655



WOW ì²« ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì— ê²€ì¦ ì •í™•ë„ê°€ 94.1%ë‚˜ ëœë‹¤! í•˜ì§€ë§Œ ì´ ì •í™•ë„ëŠ” ë¯¿ì„ ìˆ˜ ì—†ëŠ” ì •í™•ë„ë‹¤. ì™œê·¸ëŸ°ì§€ ì•Œì•„ë³´ì.


```python
y_pred[0]
```




    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0])




```python
y_true[0]
```




    array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0])




```python
proba_predictions = baseline_proba_predictions.values
hot_values = validation_labels.drop(['Id','Target','number_of_targets'], axis=1).values.flatten()
one_hot = (hot_values.sum()) / hot_values.shape[0] * 100
zero_hot = (hot_values.shape[0] - hot_values.sum()) / hot_values.shape[0] * 100

fig,ax = plt.subplots(1,2,figsize=(20,5))
sns.distplot(proba_predictions.flatten() * 100, color='DodgerBlue',ax=ax[0])
ax[0].set_xlabel("Probability in %")
ax[0].set_ylabel("Density")
ax[0].set_title("Predicted probabilities")
sns.barplot(x=["label = 0", "label = 1"], y=[zero_hot, one_hot], ax=ax[1])
ax[1].set_ylim([0,100])
ax[1].set_title("True target label count")
ax[1].set_ylabel("Percentage");
```


    
![kaggle_pro11](https://user-images.githubusercontent.com/77332628/202901059-85f35fa5-b552-4ed6-987f-e34077b6e806.png)


ìœ„ì˜ ì™¼ìª½ ê·¸ë˜í”„ë¥¼ ë³´ë©´ ëª¨ë¸ì´ ë‹¨ë°±ì§ˆ êµ¬ì¡°ë¥¼ 10% ì´ìƒ ë§íŒ ë°ì´í„°ëŠ” êµ‰ì¥íˆ ì ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  ì˜¤ë¥¸ìª½ ê·¸ë˜í”„ë¥¼ ë³´ë©´ labelì´ 0ì¸ í´ë˜ìŠ¤ê°€ 1ì¸ í´ë˜ìŠ¤ë³´ë‹¤ ì›”ë“±íˆ ë§ì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ëŠ” ë‹¹ì—°í•œê²ƒì´, ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ëŠ” 1ê°œ ë˜ëŠ” 2ê°œì˜ íƒ€ê¹ƒë§Œ í¬í•¨í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ 0ìœ¼ë¡œ label ë˜ì—ˆê¸° ë•Œë¬¸ì´ë‹¤. ë”°ë¼ì„œ ìœ„ì˜ 94.3%ì˜ ì •í™•ë„ëŠ” ëª¨ë¸ì´ labelì´ 0ì¸, ì¦‰ ë°ì´í„°ì— 'ì¡´ì¬í•˜ì§€ ì•ŠëŠ”' íƒ€ê¹ƒê°’ì„ ì˜ˆì¸¡í•œ ì •í™•ë„ë¥¼ í¬í•¨í•œ ê²ƒì´ë‹¤.

ê·¸ëŸ¼ ì–´ë–¤ ëª¨ë¸ì´ ì–´ë–¤ ë°ì´í„°ë¥¼ ë†’ì€ ì •í™•ë„ë¡œ ì˜ˆì¸¡í–ˆê³ , ì–´ë–¤ ë°ì´í„°ë¥¼ ë‚®ì€ ì •í™•ë„ë¡œ ì˜ˆì¸¡í–ˆëŠ”ì§€ í™•ì¸í•´ë³´ì.


```python
mean_predictions = np.mean(proba_predictions, axis=0)
std_predictions = np.std(proba_predictions, axis=0)
mean_targets = validation_labels.drop(['Id','Target','number_of_targets'],axis=1).mean()

labels =  validation_labels.drop(["Id", "Target", "number_of_targets"], axis=1).columns.values
fig,ax = plt.subplots(1,2,figsize=(20,5))
sns.barplot(x=labels,y=mean_predictions,ax=ax[0])
ax[0].set_xticklabels(labels=labels, rotation=90)
ax[0].set_ylabel('Mean predicted probability')
ax[0].set_title('Mean predicted probility per class over all datas')\

sns.barplot(x=labels,y=std_predictions,ax=ax[1])
ax[1].set_xticklabels(labels=labels,rotation=90)
ax[1].set_ylabel('Standard deviation')
ax[1].set_title('Standard deviation of predicted probabilty per class over all datas')
```




    Text(0.5, 1.0, 'Standard deviation of predicted probabilty per class over all datas')




    
![kaggle_pro12](https://user-images.githubusercontent.com/77332628/202901060-41c8ba24-8d81-436f-978b-18c99ddb9829.png)



```python
fig,ax = plt.subplots(1,1,figsize=(20,5))
sns.barplot(x=labels,y=mean_targets.values,ax=ax)
ax.set_xticklabels(labels=labels,rotation=90)
ax.set_ylabel('Percentage of hot (1)')
ax.set_title('Percentage of hot counts (ones) per target class')
```




    Text(0.5, 1.0, 'Percentage of hot counts (ones) per target class')




    
![kaggle_pro13](https://user-images.githubusercontent.com/77332628/202901061-f9a4d0af-9280-46a5-ae90-0a6b0dcc5e3e.png)

    


ì¶œë ¥í•œ ë°” ê·¸ë˜í”„ë“¤ì„ ë³´ë©´ ëŒ€ë¶€ë¶„ì˜ ì˜ˆì¸¡í•œ ë°ì´í„°ë“¤ì´ ë‚®ì€ ì •í™•ë„ë¥¼ ë³´ì¸ ê²ƒì„ ë³´ì¸ë‹¤. ë”°ë¼ì„œ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì€ ê·¸ë ‡ê²Œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì§€ëŠ” ëª»í•œë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. 

ë‹¤ìŒ ê¸€ì—ì„  ë² ì´ìŠ¤ë¼ì¸ì—ì„œ í•œ ë‹¨ê³„ ë” ë°œì „í•œ ëª¨ë¸ì— ëŒ€í•´ ë‹¤ë¤„ë³´ë„ë¡ í•˜ê² ë‹¤.
