---
title: "GenAI Souveraine : RAG Local avec Llama 3 & Qdrant"
date: 2026-03-01
categories:
  - Generative AI
  - Open Source
tags:
  - Llama 3
  - Qdrant
  - LlamaIndex
  - Docker
header:
  teaser: https://miro.medium.com/v2/resize:fit:1400/1*c_fiB-YgbNMkTwnHSjvDNg.png
excerpt: "Construction d'une architecture RAG 100% On-Premise pour donn√©es confidentielles. Stack Open Source : Llama 3, Qdrant et Embeddings BGE-M3."
---

## üéØ Le D√©fi : Confidentialit√© & Souverainet√©
Dans les secteurs r√©gul√©s (Banque, D√©fense, Sant√©), l'envoi de documents sensibles vers des APIs publiques (comme OpenAI) est impossible. L'objectif √©tait de concevoir un syst√®me de **Knowledge Management intelligent** fonctionnant enti√®rement en local ("Air-gapped"), sans qu'aucune donn√©e ne quitte l'infrastructure de l'entreprise.

## üí° La Solution : La "Sovereign Stack"

J'ai d√©ploy√© une architecture RAG haute performance utilisant uniquement des mod√®les et outils Open Source, conteneuris√©e via Docker.

### 1. Ingestion & Recherche Hybride
Pour d√©passer les limites de la recherche vectorielle simple :
* **Embeddings SOTA :** Utilisation du mod√®le **BGE-M3** (BAAI) pour une repr√©sentation s√©mantique multilingue sup√©rieure aux mod√®les propri√©taires.
* **Vector Store :** D√©ploiement de **Qdrant** (Rust) pour le stockage vectoriel.
* **Recherche Hybride :** Impl√©mentation d'une strat√©gie de retrieval combinant *Dense Vector Search* (S√©mantique) et *Sparse Keyword Search* (BM25) pour une pr√©cision maximale.

### 2. Inf√©rence Locale (LLM)
* **Mod√®le :** **Meta Llama 3 (8B Instruct)** quantiz√© en 4-bit pour tourner sur des GPU grand public (T4/L4) avec une latence < 100ms.
* **Moteur d'inf√©rence :** Utilisation d'**Ollama** pour servir le mod√®le via une API locale compatible REST.

## üõ†Ô∏è Stack Technique
* **LLM :** Llama 3 (via Ollama/vLLM)
* **Orchestration :** LlamaIndex (Python)
* **Vector DB :** Qdrant (Docker)
* **Embedding :** HuggingFace (BAAI/bge-m3)
* **Infra :** Docker Compose, NVIDIA Container Toolkit

## üöÄ R√©sultats & Performance

> "La puissance de GPT-4, avec la confidentialit√© d'un coffre-fort."

* **S√©curit√© :** 0% de fuite de donn√©es (Architecture 100% Offline).
* **Co√ªts :** Suppression des co√ªts variables au token (CAPEX vs OPEX).
* **Qualit√© :** Le Reranking (ColBERT) a permis d'atteindre un score de pertinence comparable aux solutions propri√©taires sur le corpus technique.

---
[Retour √† l'accueil](https://www.thiernobarry-ai.com)
