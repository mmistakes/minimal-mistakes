---
layout: single
title: PyTorch Intro
categories:
  - pytorch
tags:
  - 부스트캠프
  - AITech
  - AIBasic
  - PyTorch
author_profile: false
use_math: true
---
## 1. PyTorch Introduction

### 1.1 PyTorch Intro

- PyTorch? → 간편한 딥러닝 API를 제공하는 <mark style="background: #FFF3A3A6;">멀티플랫폼 프로그래밍 인터페이스</mark>
    (멀티플랫폼? - 다양한 OS에서 모두 구현 가능 의미)
    - ML 알고리즘 구현 우수, 실행 확장성이 뛰어남 <mark style="background: #FFF3A3A6;">(=작업량 처리 능력이 좋음)</mark>
    - Produced by. FAIR(Facebook AI Research) Since. 2016.09<br><br>

- PyTorch 활용기업
    - Tesla: Autopilot → 자율주행 기능
    - Uber: Pyro → 확률적 프로그래밍 언어 제작
    - <mark style="background: #FFF3A3A6;">Hugging Face(최신 DL 모델 무료 제공 기업) → BERT, GPT-Series, Vision Transformer 등</mark><br><br>

- PyTorch vs Tensorflow
    - On HuggingFace : PyTorch(92%) - Tensorflow(8%)
    - Fraction of Papers : 꾸준한 증가추세
        ![image1.png](../../images/2024-08-05-aitech-week1_1/image1.png)
        
        ![image2.png](../../images/2024-08-05-aitech-week1_1/image2.png)
        

- PyTorch 아키텍처
    ⇒ (Top -level) API + (Mid-level) Engine + (Low-level) Library
    
    1. API: 개발단계서 이용 (<mark style="background: #FFF3A3A6;">torch.autograd(자동미분)</mark>, <mark style="background: #FFF3A3A6;">torch.nn(신경망)</mark>, torch.multiprocessing, torch.utils)
    2. Engine: Tensor 연산처리, 자동미분 담당
    3. Library: C - Tensor 연산 담당 / CUDA - GPU 담당

- 기타 PyTorch 장점
    1. 간편한 사용성: “Pythonic”
    2. 강력한 커뮤니티, 생태계: GitHub, Twitter, Tutorials etc.
        - 풍부한 모델 구현체: HuggingFace, PyTorch Hub 등 <mark style="background: #FFF3A3A6;">강력한 커뮤니티 형성</mark>
    3. 동적 계산 그래프: 명령형 프로그래밍 환경 제공(2022, 연산 평가와 계산 실행, 구체적인 값 즉시반환 등)
    4. 고성능, 효율성: GPU 지원(CUDA → 대규모 병렬연산 효율적으로)

## 2. What is Tensor?
### 2.1 Tensor의 의미
Tensor - PyTorch의 <mark style="background: #FFF3A3A6;">핵심 데이터 구조</mark> ⇒ 데이터 표현

### 2.2 Tensor의 여러가지 표현
1. 0-D Tensor(=Scalar)
    - 하나의 숫자로 표현되는 양
    - 대수적 표현
	    $a = a_1, a \in R$<br><br>
    - 공간적 표현 - "하나의 왕점"으로 표현 가능
    - 코드 표현
        ```
         a = torch.tensor(36.5)
		```
	    

2. 1-D Tensor(=Vector)
    - 순서가 지정된 여러 개의 숫자가 <mark style="background: #FFF3A3A6;">일렬로 나열</mark>된 구조 (ex. 사람들의 키, 체중, 허리둘레 등)
    - 대수적 표현
        $b = [b_1, b_2, b_3, b_4, b_5], b \in R^n$<br><br>
    - 공간적 표현 - 일렬로 나열, dim-0 (차원이 늘어날 때마다 축의 위치 변경)
    - 코드 표현
	    ~~~
	    b = torch.tensor([175, 60, 81, 0.8, 0.9])
	    ~~~
		

3. 2-D Tensor(=Matrix)
    - <u>동일한 크기를 가진 1-D Tensor</u>들이 형성한, <mark style="background: #FFF3A3A6;">행과 열로 구성된 사각형 구조</mark>(ex. Grayscale Image)
    - 대수적 표현
        ![image6](../../images/2024-08-05-aitech-week1_1/image6.png)<br><br>
    - 공간적 표현
	    - dim-0: 행 차원의 축
	    - dim-1: 열 차원의 축(기존 dim-0이 이동)
	- 코드 표현
		~~~
		c = torch.tensor([[77, 114, 140, 191],
						  [39, 56, 45, 119],
						  [61, 29, 20, 33]])
		~~~
		

4. 3-D Tensor
	- <u>동일한 크기의 2-D Tensor</u>가 여러 겹 쌓여 형성, <mark style="background: #FFF3A3A6;">입체적 배열 구조</mark>
		(여기에 배치축을 추가할 경우, 4-D Tensor로 표현 가능)
	- 대수적 표현
		![image7](../../images/2024-08-05-aitech-week1_1/image7.png)<br><br>
	- 공간적 표현
		- dim-0: 깊이(depth) 차원의 축
		- dim-1: 행 차원의 축
		- dim-2: 열 차원의 축(기존 dim-1이 이동) 
		![3-D Tensor](../../images/2024-08-05-aitech-week1_1/image3.png)
	- 코드 표현
	~~~
	d = torch.tensor([[[255, 0, 0],
						[0, 255, 0],
						[0, 0, 255],
						[255, 255, 0]]])
	~~~
	

5. N-D Tensor
	- <u>동일한 크기의 N-D Tensor</u>가 여러 겹 쌓여 형성된 <mark style="background: #FFF3A3A6;">입체적 배열 구조</mark>
	- 투명도 고려한 이미지, Time-Dimesion 추가한 영상 등
	- 공간적 표현
	![4-D Tensor](../../images/2024-08-05-aitech-week1_1/image4.png)![5-D Tensor](../../images/2024-08-05-aitech-week1_1/image5.png)<br><br>

### 결론
Tensor는 언어/대수로, 공간에서, <mark style="background: #FFF3A3A6;">코드로 표현 가능</mark>



