---
layout: single
title:  "데이터분석 개발일지1.2"
---

# 2022.08.09

웹 스크래핑과 관련하여 배운 내용을 정리하고자 한다.

**BeautifulSoup**
html에서 태그를 가지고 오고자 한다면, BeautifulSoup을 이용하자.  
BeautifulSoup은 크롤링에 꼭 필요하다!  
BeautifulSoup 인스턴스를 생성하기 위해서 밑과 같이 적어준다.  

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'html.parser')
```

두 번째 매개변수는 분석할 분석기(parser)의 종류이다.  
 태그를 가져오기 위해서는 soup.select()을 이용하면 된다. 이때, id는 앞에 # 붙이고 calss는 앞에 . 을 붙여준다.

**Newspaper3k**  
기사를 가져올 때 사용한다. 패키지이다.

```python
!pip install newspaper3k
from newspaper import Article
```
HTML 소스 코드를 가져오기 위해서는 requests 패키지의 get 모듈을 이용해야 한다.

```python
news = requests.get(url, headers=headers)
news.content
```
이때, 유저의 에이전트가 필요하다.  
이를 이용하여 원하는 페이지수와 카테고리, 날짜를 뽑아낼 수 있다는 것이 신기했다. 또, 함수를 만들어 리스트에 담아주며 최종적으로 url로부터 데이터 프레임을 생성해볼 수 있어서 좋았다.


**과제**

과제로 스크래핑을 했다.  
웹 스크래핑을 할 때, 해당 부분을 copy selector을 해주면 넣어줘야 할 해당 요소를 가져올 수 있는 사실을 알았다.  
힘들게 하나하나 찾아볼 필요가 없어서 시간 효율이 높아졌다.  
가져온 요소에 text를 붙여주면 문자에 해당하는 부분만 가져온다.  
또, 띄어쓰기가 되어있어 한눈에 알아보기 힘들다면,  띄어쓰기 함수인 strip을 사용해준다.  

```python
tr.select('해당 요소')[0].text.strip()
```
만약 전체 중에서 하나만 선택하고 싶은데, [0]을 쓰지 않고 표현하고 싶다면
```python
tr.select_one('해당 요소').text.strip()
```
을 써준다.

재밌는 1 주차 수업이었다.
