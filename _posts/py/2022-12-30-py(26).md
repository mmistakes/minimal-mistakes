---
title: "python-26: Web Scrapping"
layout: single
categories : python
tag: [coding, github, jekyll, blog, python]
toc: true
toc_sticky: true
author_profile: false
---

### Pypi
- https://pypi.org/search/
- ë‹¤ë¥¸ì‚¬ëŒì´ ë§Œë“  í”„ë¡œì íŠ¸ë‚˜ ëª¨ë“ˆì„ ëª¨ì•„ë‘” ê³³


### Requests
- HTTP for Humans
- https://requests.readthedocs.io/en/latest/

```
Response = get(website)
Print(response.status_code)
```

- ì›¹ ìŠ¤í¬ë˜í•‘: ë‚´ê°€ ì“´ ì½”ë“œê°€ ì›¹ì‚¬ì´íŠ¸ì— ë“¤ì–´ê°€ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ëƒ„


### ê°œë°œì ì¼ìë¦¬ ì°¾ê¸°  
- https://kr.indeed.com/?r=us
- https://weworkremotely.com/

### Beautifusoup
- ì›¹ì‚¬ì´íŠ¸(HTML)ì˜ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¬ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

- Beautifulsoup ë“¤ì–´ê°€ëŠ” ë²•: <br>
  ë¦¬í”Œì—ì„œ íë¸Œëª¨ì–‘ í´ë¦­ , beautifulsoup ê²€ìƒ‰, beautifulsoup4 ì„¤ì¹˜, requestsë„ ì„¤ì¹˜í™•ì¸

- `get(f{ë°”ë€ŒëŠ” ë³€ìˆ˜})` ì—¬ê¸°ì„œ `f` ëŠ” ë¬¸ìì—´ì•ˆì— ë³€ìˆ˜ë¥¼ ë„£ì„ ìˆ˜ ìˆê²Œ í•´ì¤Œ
 
```py
from request import get
 
base_url = "https://weworkremotely.com/remote-jobs/search?term="
 
search_term = "python"
 
response = get(f"{base_url}{search_term}")
 
print(response.text)
```

```py
def say_hello(name, age):
  print(f"Hello {name} you are {age} years old")
 
 
say_hello("nico", 12)
say_hello(age=12, name="nico")
```

![image](https://user-images.githubusercontent.com/111720411/209949024-32e34359-65f6-435b-bf94-c77a37f30a65.png)

- ì²«ë²ˆì§¸ê°€ positional(ë§¤ê°œë³€ìˆ˜ì™€ ì¸ìˆ˜ì™€ì˜ ê´€ê³„ê°„ì— ìˆœì„œê°€ ë°˜ë“œì‹œ ë§ì•„ì•¼í•¨)
- ë‘ë²ˆì§¸ë¡œ(argumentì˜ ì´ë¦„ì„ ì ì–´ì£¼ë©´) í•˜ë©´ ìˆœì„œê°€ ë§ì§€ ì•Šì•„ë„ ë¨
- ì›¹ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ requestsì˜ getì„ ì„í¬íŠ¸

```py
from requests import get
#beautifulsoup ì‚¬ìš©ì„ ìœ„í•´ ì„í¬íŠ¸
from bs4 import BeautifulSoup
base_url = "https://weworkremotely.com/remote-jobs/search?utf8=%E2%9C%93&term="
search_term = "python"
```

- ë‚˜ì¤‘ì— urlê³¼ ê²€ìƒ‰ì–´ë¥¼ ë³€ê²½í•˜ì—¬ ì¬ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ fë¬¸ìì—´ í¬ë§¤íŒ… <br>
  `response = get(f"{base_url}+{search_term}")`
- ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì •ìƒì ì¸ ì‘ë‹µ(200)ì„ ì£¼ì§€ ì•Šì„ë•Œë¥¼ ëŒ€ë¹„
```py
if not response.status_code == 200:
print("Can't request website")
```

- ì •ìƒì´ë¼ë©´ í˜ì´ì§€ì˜ html ì½”ë“œë¥¼ ì«™ ê¸ì–´ ì˜´

```py
else:
print(response.text)
soup = BeautifulSoup(response.text, 'html.parser')
```

- sectionì˜ jobsí´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì

```py
jobs = soup.find_all('section', class_="jobs")
for job_section in jobs:
job_posts = job_section.find_all('li')
```

- viewlallì œê±°

```py
job_posts.pop(-1)
for post in job_posts:
anchors = post.find_all('a')
anchor = anchors[1]
```

- listì˜ ê¸¸ì´(len)ì„ ì•Œê³  ìˆë‹¤ë©´ itemë“¤ì˜ ìˆœì„œì— ë§ì¶° ë³€ìˆ˜ëª…ì„ ë„£ì–´ì¤„ ìˆ˜ ìˆìŒ <br>

```py
company_name, shift, region = anchor.find_all('span', class_="company")
link = anchor['href']
```

- find_allì€ í•­ìƒ listë¥¼ ì£¼ê¸° ë•Œë¬¸ì— titleí•˜ë‚˜ë§Œ ì›í•´ì„œ .find

```py
title = anchor.find('span', class_="title")
print(company_name, shift, region, title)
print("ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸ğŸ”¸")
```

- .string = htmlíƒœê·¸ëŠ” ì—†ì• ì¤Œ



