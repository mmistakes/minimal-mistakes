---
title: '[Kaggle/CV] Intel image classification - Inception Model ğŸï¸'
toc: true
toc_sticky: true
categories:
  - kaggle-imageclassification
---


## 2. Intel Image Classification

### 2.0 ë“¤ì–´ê°€ë©°
[**ì €ë²ˆ ê¸€**](https://hamin-chang.github.io/kaggle/kaggle1/)ì—ì„œ ë‹¤ë¤˜ë˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì¸ Intel Image Classification ë°ì´í„°ë¥¼ ì´ë²ˆ ê¸€ì—ì„œëŠ” ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ í’€ì–´ë³¼ ê²ƒì´ë‹¤. ì´ë²ˆ ê¸€ì—ì„œ ì‚¬ìš©í•  ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì€ [**ì´ì „ ê¸€**](https://hamin-chang.github.io/visions/inception/)ì—ì„œ ì•Œì•„ë³¸ InceptionNetV3 ëª¨ë¸ì´ë‹¤. ì €ë²ˆ ê¸€ì—ì„œ ê¸°ë³¸ CNN ëª¨ë¸ë¡œ ë¬¸ì œë¥¼ í’€ê¸° ì „ì— ë°ì´í„°ë¥¼ ì¤€ë¹„í•œ ê²ƒì²˜ëŸ¼ ë°ì´í„°ë¥¼ ë¡œë“œí•´ì¤€ë‹¤.

(*ì´ë²ˆ ì½”ë“œëŠ” [ì´ ìºê¸€ëŸ¬](https://www.kaggle.com/code/vishnuvardhan97/intel-image-classification-inceptionnetv3)ì˜ ì½”ë“œë¥¼ ì°¸ê³ í–ˆë‹¤.)

ì´ë²ˆì—ëŠ” ê¸°ë³¸ ëª¨ë¸ë¡œ ë¬¸ì œë¥¼ í’€ì—ˆë˜ ê¸€ì—ì„œì™€ëŠ” ë‹¤ë¥´ê²Œ ë°ì´í„°ë¥¼ Dataframeìœ¼ë¡œ ì¤€ë¹„í•œë‹¤.


```python
import numpy as np
import pandas as pd
import os

labels = ['buildings','forest','glacier','mountain','sea','street']
def dataframer(base_dir):
    path = []
    label = []
    for img_class in os.listdir(base_dir):
        label_path = os.path.join(base_dir, img_class)
        if img_class in labels :
            for img in os.listdir(label_path):
                path.append(os.path.join(label_path, img))
                label.append(img_class)
    img_data = pd.DataFrame({'Path':path, 'Label':label})
    return img_data

train_base_dir = "/kaggle/input/intel-image-classification/seg_train/seg_train"
validation_base_dir = "/kaggle/input/intel-image-classification/seg_test/seg_test"

train_img_data = dataframer(train_base_dir)
validation_img_data = dataframer(validation_base_dir)

```

ë¡œë“œí•œ í›ˆë ¨ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„° ì¤‘ ìƒ˜í”Œ 5ê°œì”©ë§Œ ì¶œë ¥í•´ë³´ì.


```python
train_img_data.sample(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Path</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12074</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>glacier</td>
    </tr>
    <tr>
      <th>2175</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>mountain</td>
    </tr>
    <tr>
      <th>5702</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>buildings</td>
    </tr>
    <tr>
      <th>12960</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>glacier</td>
    </tr>
    <tr>
      <th>7935</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>sea</td>
    </tr>
  </tbody>
</table>
</div>




```python
validation_img_data.sample(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Path</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>697</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>street</td>
    </tr>
    <tr>
      <th>2732</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>glacier</td>
    </tr>
    <tr>
      <th>680</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>street</td>
    </tr>
    <tr>
      <th>2892</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>glacier</td>
    </tr>
    <tr>
      <th>818</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>street</td>
    </tr>
  </tbody>
</table>
</div>



ì´ë²ˆ ê¸€ì—ì„œë„ ë³¸ê²©ì ì¸ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê¸° ì „ì— ë°ì´í„° ì¦ì‹ ê¸°ë²•ì„ ì´ìš©í•´ì„œ ê³¼ëŒ€ì í•©ì„ ìµœì†Œí™” ì‹œì¼œì¤„ ê²ƒì´ë‹¤.
ë°ì´í„° ì¦ì‹ì— ëŒ€í•œ ì„¤ëª…ì€ [ì´ì „ ê¸€](https://hamin-chang.github.io/visions/small/)ì—ì„œ ë‹¤ë¤˜ë‹¤.


```python
from keras_preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale = 1.0/255,
                                  zoom_range = 0.1,
                                  horizontal_flip = True)
validation_datagen = ImageDataGenerator(rescale = 1.0/255)

# ì €ë²ˆê³¼ ë‹¤ë¥´ê²Œ ì´ë²ˆ ê¸€ì—ì„œëŠ” dataframeì„ ì´ìš©í•˜ê¸° ë•Œë¬¸ì— flow_from_dataframe ì‚¬ìš©
train_generator = train_datagen.flow_from_dataframe(dataframe = train_img_data,
                                                   x_col = 'Path',
                                                   y_col = 'Label',
                                                   target_size = (150,150),
                                                   batch_size = 1024,
                                                   class_mode = 'categorical',
                                                   subset = 'training',
                                                   shuffle = True,
                                                   seed = 10)

validation_generator = validation_datagen.flow_from_dataframe(dataframe = validation_img_data,
                                                               x_col = 'Path',
                                                               y_col = 'Label',
                                                               target_size = (150,150),
                                                               batch_size = 256,
                                                               class_mode = 'categorical',
                                                               shuffle = False)
```

    Found 14034 validated image filenames belonging to 6 classes.
    Found 3000 validated image filenames belonging to 6 classes.


### 2.1 ì‚¬ì „ í›ˆë ¨ëœ InceptionNetV3 model ì‚¬ìš©í•˜ê¸°
ì´ì œ ëª¨ë¸ì— ì£¼ì…í•  ë°ì´í„°ì˜ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆë‹¤. ì´ì œ ì´ë²ˆ ê¸€ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í• ê±´ë°, ë‹¤ì–‘í•œ CNN ì‚¬ì „í›ˆë ¨ ëª¨ë¸ë“¤ ì¤‘ Inception Modelì„ ì‚¬ìš©í•œë‹¤. Inception Modelì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•˜ìë©´ ë‹¤ìŒ ì´ë¯¸ì§€ì²˜ëŸ¼ ë‹¤ì–‘í•œ í¬ê¸°ì˜ convolution ì¸µìœ¼ë¡œ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ì¶”ì¶œí•œ ë‹¤ìŒ ë‹¤ì‹œ í•©ì¹˜ëŠ” ì•„ì´ë””ì–´ë¥¼ í†µí•´ CNN ëª¨ë¸ì˜ ì¸µì´ ê¹Šì–´ì§€ë”ë¼ë„ ì—°ì‚° ë¹„ìš©ì„ ìµœëŒ€í•œ ì¤„ì´ê³ , vanishing gradient í˜„ìƒì„ ìµœì†Œí™”í•˜ëŠ” ëª¨ë¸ì´ë‹¤. Inception Modelì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ [ì´ì „ ê¸€](https://hamin-chang.github.io/visions/inception/)ì—ì„œ ë‹¤ë¤˜ìœ¼ë‹ˆ ê¶ê¸ˆí•˜ë‹¤ë©´ ë³´ë©´ ë„ì›€ì´ ë  ê²ƒì´ë‹¤.

![kaggle2_1](https://user-images.githubusercontent.com/77332628/202590852-b11a723a-7531-49c5-8638-7a5295b1bdd6.png)

ì´ì œ InceptionNetV3 ëª¨ë¸ì„ ì •ì˜í•˜ì.


```python
import tensorflow as tf
from keras.applications.inception_v3 import InceptionV3
from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D
from keras.models import Sequential

# ëŒ€ê·œëª¨ ë°ì´í„°ì¸ ImageNetì—ì„œ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë“¤ì„ ì‚¬ìš©
inception = InceptionV3(weights='imagenet',
                        include_top=False, # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì˜ ë¶„ë¥˜ê¸° ì¸µì€ ì‚¬ìš©X
                       input_shape=(150,150,3))

# Inception-v3 ëª¨ë¸ì˜ ë§ˆì§€ë§‰ 5ê°œ ì¸µì˜ ê°€ì¤‘ì¹˜ ë™ê²°
for layer in inception.layers[:-5]:
    layer.trainable = False
    
# Sequential modelì„ ì‚¬ìš©í•´ì„œ inception-v3ìœ„ì— ì¸µì„ ìŒ“ëŠ”ë‹¤.
# inceptionì¸µ ìœ„ì— poolingì¸µ, flattenì¸µ ë‹¤ìŒ 4ê°œì˜ Denseì¸µ
inception_model = Sequential([
    inception,
    GlobalAveragePooling2D(),
    Flatten(),
    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(6, activation='softmax')
])

```

    2022-11-17 23:49:31.586160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.587252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.951723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.952768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.953647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.954578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.956519: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
    2022-11-17 23:49:32.218030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.218846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.219575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.220557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.221366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.222109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.096838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.097737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.098462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.099189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.099881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.100530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5
    2022-11-17 23:49:37.105907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.106780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5


    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5
    87916544/87910968 [==============================] - 1s 0us/step
    87924736/87910968 [==============================] - 1s 0us/step


êµ¬ì¶•í•œ inception_modelì˜ êµ¬ì¡°ë¥¼ ì‚´í´ë³´ì.


```python
inception_model.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    inception_v3 (Functional)    (None, 3, 3, 2048)        21802784  
    _________________________________________________________________
    global_average_pooling2d (Gl (None, 2048)              0         
    _________________________________________________________________
    flatten (Flatten)            (None, 2048)              0         
    _________________________________________________________________
    dense (Dense)                (None, 256)               524544    
    _________________________________________________________________
    dense_1 (Dense)              (None, 128)               32896     
    _________________________________________________________________
    dense_2 (Dense)              (None, 64)                8256      
    _________________________________________________________________
    dense_3 (Dense)              (None, 6)                 390       
    =================================================================
    Total params: 22,368,870
    Trainable params: 566,086
    Non-trainable params: 21,802,784
    _________________________________________________________________


ëª¨ë¸ì„ êµ¬ì¶•í–ˆìœ¼ë‹ˆ optimizer,lossì™€ metricsë¥¼ ì •ì˜í•˜ê³  ëª¨ë¸ì„ compile í•œë‹¤.


```python
inception_model.compile(optimizer = 'adam',loss='categorical_crossentropy',
                       metrics=['accuracy'])
```

### 2.2 ëª¨ë¸ í›ˆë ¨í•˜ê¸°
ì´ì œ í›ˆë ¨í•  ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒê¹Œì§€ ì™„ë£Œí–ˆë‹¤. ì´ì œ ëª¨ë¸ì„ í›ˆë ¨í• ê±´ë°, ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ì „ì— ModelCheckpointë¼ëŠ” ì½œë°±í•¨ìˆ˜ë¥¼ ì •ì˜í•´ì„œ ìµœìƒì˜ ëª¨ë¸ì„ ì €ì¥í•˜ê³ , ì‹œë“œë¥¼ ì •í•´ì„œ í›ˆë ¨í•  ë•Œë§ˆë‹¤ ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜¤ë„ë¡ ì„¤ì •í•œë‹¤.


```python
from tensorflow.keras.callbacks import ModelCheckpoint
checkpoint = ModelCheckpoint('kaggle/working/inception.hdf5',
                            monitor = 'val_accuracy',
                            save_best_only = True)

import random as rd
rd.seed(150)
np.random.seed(150)
tf.random.set_seed(150)
```

ì´ì œ ë³¸ê²©ì ì¸ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•œë‹¤.


```python
inception_history = inception_model.fit(train_generator,
                                       steps_per_epoch=10,
                                       validation_data=validation_generator,
                                       validation_steps=5,
                                       epochs=20,
                                       callbacks=[checkpoint])
```

    2022-11-18 00:01:46.373693: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)


    Epoch 1/20


    2022-11-18 00:02:06.281662: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005


    10/10 [==============================] - 162s 14s/step - loss: 0.9810 - accuracy: 0.6574 - val_loss: 0.5298 - val_accuracy: 0.8102
    Epoch 2/20
    10/10 [==============================] - 92s 9s/step - loss: 0.4272 - accuracy: 0.8570 - val_loss: 0.4673 - val_accuracy: 0.8305
    Epoch 3/20
    10/10 [==============================] - 81s 8s/step - loss: 0.3574 - accuracy: 0.8795 - val_loss: 0.3822 - val_accuracy: 0.8578
    Epoch 4/20
    10/10 [==============================] - 84s 8s/step - loss: 0.3211 - accuracy: 0.8880 - val_loss: 0.2826 - val_accuracy: 0.9000
    Epoch 5/20
    10/10 [==============================] - 80s 8s/step - loss: 0.3062 - accuracy: 0.8898 - val_loss: 0.5119 - val_accuracy: 0.7977
    Epoch 6/20
    10/10 [==============================] - 79s 8s/step - loss: 0.3086 - accuracy: 0.8887 - val_loss: 0.3500 - val_accuracy: 0.8672
    Epoch 7/20
    10/10 [==============================] - 79s 8s/step - loss: 0.2761 - accuracy: 0.9023 - val_loss: 0.2799 - val_accuracy: 0.8961
    Epoch 8/20
    10/10 [==============================] - 80s 8s/step - loss: 0.2486 - accuracy: 0.9089 - val_loss: 0.2819 - val_accuracy: 0.8914
    Epoch 9/20
    10/10 [==============================] - 80s 8s/step - loss: 0.2463 - accuracy: 0.9101 - val_loss: 0.2947 - val_accuracy: 0.8859
    Epoch 10/20
    10/10 [==============================] - 82s 8s/step - loss: 0.2345 - accuracy: 0.9153 - val_loss: 0.2819 - val_accuracy: 0.8945
    Epoch 11/20
    10/10 [==============================] - 80s 8s/step - loss: 0.2402 - accuracy: 0.9112 - val_loss: 0.3832 - val_accuracy: 0.8562
    Epoch 12/20
    10/10 [==============================] - 81s 8s/step - loss: 0.2236 - accuracy: 0.9190 - val_loss: 0.2964 - val_accuracy: 0.8883
    Epoch 13/20
    10/10 [==============================] - 79s 8s/step - loss: 0.2090 - accuracy: 0.9239 - val_loss: 0.3315 - val_accuracy: 0.8703
    Epoch 14/20
    10/10 [==============================] - 82s 8s/step - loss: 0.2010 - accuracy: 0.9254 - val_loss: 0.3252 - val_accuracy: 0.8750
    Epoch 15/20
    10/10 [==============================] - 83s 8s/step - loss: 0.2078 - accuracy: 0.9195 - val_loss: 0.2610 - val_accuracy: 0.9000
    Epoch 16/20
    10/10 [==============================] - 83s 8s/step - loss: 0.2024 - accuracy: 0.9242 - val_loss: 0.2614 - val_accuracy: 0.9047
    Epoch 17/20
    10/10 [==============================] - 79s 8s/step - loss: 0.2142 - accuracy: 0.9193 - val_loss: 0.3364 - val_accuracy: 0.8773
    Epoch 18/20
    10/10 [==============================] - 79s 8s/step - loss: 0.2108 - accuracy: 0.9213 - val_loss: 0.3651 - val_accuracy: 0.8594
    Epoch 19/20
    10/10 [==============================] - 81s 8s/step - loss: 0.1955 - accuracy: 0.9241 - val_loss: 0.3130 - val_accuracy: 0.8813
    Epoch 20/20
    10/10 [==============================] - 80s 8s/step - loss: 0.1924 - accuracy: 0.9287 - val_loss: 0.4367 - val_accuracy: 0.8375


### 2.3 ëª¨ë¸ í‰ê°€í•˜ê¸°
ë¨¼ì € í›ˆë ¨ accuracy ì™€ ê²€ì¦ accuracyë¥¼ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë³´ì.


```python
import matplotlib.pyplot as plt

inception_acc = inception_history.history['accuracy']
inception_val_acc = inception_history.history['val_accuracy']

epochs = range(len(inception_acc))

plt.figure(figsize=(12,8))
plt.plot(epochs, inception_acc,'r',label = 'Training Accuracy')
plt.plot(epochs, inception_val_acc,'b',label='Validation Accuracy')
plt.title('InceptionV3 Training and Validation Accuracy',fontsize=15)
plt.legend(loc=0)
plt.show()
```


    
![kaggle2_2](https://user-images.githubusercontent.com/77332628/202590854-c1f13792-6ff9-40f4-8214-258a12fd4125.png)
    


ê·¸ ë‹¤ìŒ í›ˆë ¨ lossì™€ ê²€ì¦ lossë¥¼ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë³´ì.


```python
inception_loss = inception_history.history['loss']
inception_val_loss = inception_history.history['val_loss']

epochs = range(len(inception_loss))

plt.figure(figsize=(12,8))
plt.plot(epochs, inception_loss,'r',label = 'Training Loss')
plt.plot(epochs, inception_val_loss, 'b',label='Validation Loss')
plt.title('InceptionV3 Training and Validation Loss',fontsize=15)
plt.legend(loc=0)
plt.show()
```


    
![kaggle2_3](https://user-images.githubusercontent.com/77332628/202590859-a09bc367-428c-42bf-8d6c-a873538dd965.png)
    


í›ˆë ¨ ì†ì‹¤ì€ ê³„ì†í•´ì„œ ê°ì†Œí–ˆì§€ë§Œ ê²€ì¦ ì†ì‹¤ì€ ë“¤ì­‰ë‚ ì­‰í•˜ë‹¤. í•˜ì§€ë§Œ ê³¼ëŒ€ì í•©ì´ ì‹¬í•˜ê²Œ ë˜ì§€ ì•Šì€ ê²ƒìœ¼ë¡œ ë³´ì•„ ìœ ìš©í•œ ëª¨ë¸ì„ ì˜ êµ¬ì¶•í•œ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.

ModelCheckpoint ì½œë°±ì„ ì´ìš©í•´ì„œ ì €ì¥í–ˆë˜ ìµœìƒì˜ ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , ìµœìƒì˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ confusion matrixë¥¼ í†µí•´ì„œ ì‹œê°í™”í•œë‹¤.

(confusion matrixì— ëŒ€í•œ ì„¤ëª…ì€ [ì´ì „ ê¸€](https://hamin-chang.github.io/basics/confusionmatrix/)ì„ ì°¸ê³ í•˜ë©´ ëœë‹¤.)


```python
# ìµœìƒì˜ ëª¨ë¸ ë¡œë“œ
from keras.models import load_model
inception_model = load_model('kaggle/working/inception.hdf5')

# confusion matrix ê·¸ë¦¬ê¸°
import seaborn as sns
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

y_pred_inception = inception_model.predict(validation_generator)
y_pred_inception_cf = np.argmax(y_pred_inception,axis=1)

inception_confusion_matrix = confusion_matrix(validation_generator.classes,
                                              y_pred_inception_cf)
conf_matrix = pd.DataFrame(data=inception_confusion_matrix,
                          columns = labels,
                          index = labels)

plt.figure(figsize=(12,8))
sns.heatmap(conf_matrix, annot=True, cbar = False, fmt='d',linewidth = 0.5)
plt.xlabel('Predicted Classes',fontsize=12)
plt.ylabel('True Classes', fontsize=12)
plt.title('InceptionV3 Confusion Matrix',fontsize=15)
plt.show()
```


    
![kaggle2_4](https://user-images.githubusercontent.com/77332628/202590863-86334387-8728-447e-8597-2e250966710f.png)
    


ìµœìƒì˜ ëª¨ë¸ì´ ëŒ€ë¶€ë¶„ì˜ í´ë˜ìŠ¤ì—ì„œ ìœ ì˜ë¯¸í•œ ìˆ˜ì¤€ì˜ ì •í™•ë„ë¥¼ ë³´ì—¬ì¤¬ì§€ë§Œ mountainê³¼ glacierë¥¼ ê°€ì¥ ë§ì´ í—·ê°ˆë¦¬ê³ , streetì™€ building í´ë˜ìŠ¤ë„ ì•½ê°„ì˜ ì˜¤ì°¨ë¥¼ ë³´ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

ë‹¤ìŒì€ confusion matrixë¥¼ í†µí•´ ê³„ì‚°í•œ ê° í´ë˜ìŠ¤ì˜ precision, recall, f1_scoreì´ë‹¤.


```python
print('InceptionV3 Classification Report')
print(classification_report(validation_generator.classes,
                           y_pred_inception_cf,
                           target_names = labels))
```

    InceptionV3 Classification Report
                  precision    recall  f1-score   support
    
       buildings       0.89      0.92      0.90       437
          forest       0.97      0.99      0.98       474
         glacier       0.92      0.61      0.73       553
        mountain       0.72      0.91      0.81       525
             sea       0.89      0.96      0.92       510
          street       0.93      0.89      0.91       501
    
        accuracy                           0.88      3000
       macro avg       0.89      0.88      0.88      3000
    weighted avg       0.89      0.88      0.87      3000
    


ì´ë²ˆ ê¸€ì—ëŠ” test ë°ì´í„°ë¥¼ ì§€ì •í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ë§ˆì§€ë§‰ìœ¼ë¡œ ìµœìƒì˜ ëª¨ë¸ì˜ ê²€ì¦ ì†ì‹¤ê³¼ ê²€ì¦ ì •í™•ë„ë¥¼ ì¶œë ¥í•˜ê³  ê¸€ì„ ë§ˆë¬´ë¦¬ í•˜ê² ë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì¸ InceptionV3 ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ë¬¸ì œë¥¼ í’€ì–´ë´¤ë‹¤. ì´ë²ˆì— êµ¬ì¶•í•œ ëª¨ë¸ì€ ì €ë²ˆì— êµ¬ì¶•í•œ ë³¸ì ì¸ CNN ëª¨ë¸ì— ë¹„í•˜ë©´ êµ‰ì¥íˆ ê¹Šì§€ë§Œ inception ë•ë¶„ì— ê³„ì‚°ëŸ‰ì´ ë§ì§€ ì•Šì•˜ë‹¤. 
