---
title: '[Kaggle/CV] Intel image classification - Inception Model ✏️'
toc: true
toc_sticky: true
categories:
  - kaggle
---


## 2. Intel Image Classification

### 2.0 들어가며
[**저번 글**](https://hamin-chang.github.io/kaggle/kaggle1/)에서 다뤘던 이미지 분류 문제인 Intel Image Classification 데이터를 이번 글에서는 사전 훈련된 모델을 사용해서 풀어볼 것이다. 이번 글에서 사용할 사전 훈련된 모델은 [**이전 글**](https://hamin-chang.github.io/visions/inception/)에서 알아본 InceptionNetV3 모델이다. 저번 글에서 기본 CNN 모델로 문제를 풀기 전에 데이터를 준비한 것처럼 데이터를 로드해준다.

(*이번 코드는 [이 캐글러](https://www.kaggle.com/code/vishnuvardhan97/intel-image-classification-inceptionnetv3)의 코드를 참고했다.)

이번에는 기본 모델로 문제를 풀었던 글에서와는 다르게 데이터를 Dataframe으로 준비한다.


```python
import numpy as np
import pandas as pd
import os

labels = ['buildings','forest','glacier','mountain','sea','street']
def dataframer(base_dir):
    path = []
    label = []
    for img_class in os.listdir(base_dir):
        label_path = os.path.join(base_dir, img_class)
        if img_class in labels :
            for img in os.listdir(label_path):
                path.append(os.path.join(label_path, img))
                label.append(img_class)
    img_data = pd.DataFrame({'Path':path, 'Label':label})
    return img_data

train_base_dir = "/kaggle/input/intel-image-classification/seg_train/seg_train"
validation_base_dir = "/kaggle/input/intel-image-classification/seg_test/seg_test"

train_img_data = dataframer(train_base_dir)
validation_img_data = dataframer(validation_base_dir)

```

로드한 훈련 데이터와 검증 데이터 중 샘플 5개씩만 출력해보자.


```python
train_img_data.sample(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Path</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12074</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>glacier</td>
    </tr>
    <tr>
      <th>2175</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>mountain</td>
    </tr>
    <tr>
      <th>5702</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>buildings</td>
    </tr>
    <tr>
      <th>12960</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>glacier</td>
    </tr>
    <tr>
      <th>7935</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>sea</td>
    </tr>
  </tbody>
</table>
</div>




```python
validation_img_data.sample(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Path</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>697</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>street</td>
    </tr>
    <tr>
      <th>2732</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>glacier</td>
    </tr>
    <tr>
      <th>680</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>street</td>
    </tr>
    <tr>
      <th>2892</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>glacier</td>
    </tr>
    <tr>
      <th>818</th>
      <td>/kaggle/input/intel-image-classification/seg_t...</td>
      <td>street</td>
    </tr>
  </tbody>
</table>
</div>



이번 글에서도 본격적인 모델을 구축하기 전에 데이터 증식 기법을 이용해서 과대적합을 최소화 시켜줄 것이다.
데이터 증식에 대한 설명은 [이전 글](https://hamin-chang.github.io/visions/small/)에서 다뤘다.


```python
from keras_preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale = 1.0/255,
                                  zoom_range = 0.1,
                                  horizontal_flip = True)
validation_datagen = ImageDataGenerator(rescale = 1.0/255)

# 저번과 다르게 이번 글에서는 dataframe을 이용하기 때문에 flow_from_dataframe 사용
train_generator = train_datagen.flow_from_dataframe(dataframe = train_img_data,
                                                   x_col = 'Path',
                                                   y_col = 'Label',
                                                   target_size = (150,150),
                                                   batch_size = 1024,
                                                   class_mode = 'categorical',
                                                   subset = 'training',
                                                   shuffle = True,
                                                   seed = 10)

validation_generator = validation_datagen.flow_from_dataframe(dataframe = validation_img_data,
                                                               x_col = 'Path',
                                                               y_col = 'Label',
                                                               target_size = (150,150),
                                                               batch_size = 256,
                                                               class_mode = 'categorical',
                                                               shuffle = False)
```

    Found 14034 validated image filenames belonging to 6 classes.
    Found 3000 validated image filenames belonging to 6 classes.


### 2.1 사전 훈련된 InceptionNetV3 model 사용하기
이제 모델에 주입할 데이터의 준비가 완료되었다. 이제 이번 글에서 가장 중요한 사전 훈련된 모델을 사용할건데, 다양한 CNN 사전훈련 모델들 중 Inception Model을 사용한다. Inception Model에 대해 간단히 설명하자면 다음 이미지처럼 다양한 크기의 convolution 층으로 데이터의 특성을 추출한 다음 다시 합치는 아이디어를 통해 CNN 모델의 층이 깊어지더라도 연산 비용을 최대한 줄이고, vanishing gradient 현상을 최소화하는 모델이다. Inception Model에 대한 자세한 설명은 [이전 글](https://hamin-chang.github.io/visions/inception/)에서 다뤘으니 궁금하다면 보면 도움이 될 것이다.

![kaggle2_1](https://user-images.githubusercontent.com/77332628/202590852-b11a723a-7531-49c5-8638-7a5295b1bdd6.png)

이제 InceptionNetV3 모델을 정의하자.


```python
import tensorflow as tf
from keras.applications.inception_v3 import InceptionV3
from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D
from keras.models import Sequential

# 대규모 데이터인 ImageNet에서 훈련된 가중치들을 사용
inception = InceptionV3(weights='imagenet',
                        include_top=False, # 사전 훈련된 모델의 분류기 층은 사용X
                       input_shape=(150,150,3))

# Inception-v3 모델의 마지막 5개 층의 가중치 동결
for layer in inception.layers[:-5]:
    layer.trainable = False
    
# Sequential model을 사용해서 inception-v3위에 층을 쌓는다.
# inception층 위에 pooling층, flatten층 다음 4개의 Dense층
inception_model = Sequential([
    inception,
    GlobalAveragePooling2D(),
    Flatten(),
    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(6, activation='softmax')
])

```

    2022-11-17 23:49:31.586160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.587252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.951723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.952768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.953647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.954578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:31.956519: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
    To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
    2022-11-17 23:49:32.218030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.218846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.219575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.220557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.221366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:32.222109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.096838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.097737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.098462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.099189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.099881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.100530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5
    2022-11-17 23:49:37.105907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
    2022-11-17 23:49:37.106780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5


    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5
    87916544/87910968 [==============================] - 1s 0us/step
    87924736/87910968 [==============================] - 1s 0us/step


구축한 inception_model의 구조를 살펴보자.


```python
inception_model.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    inception_v3 (Functional)    (None, 3, 3, 2048)        21802784  
    _________________________________________________________________
    global_average_pooling2d (Gl (None, 2048)              0         
    _________________________________________________________________
    flatten (Flatten)            (None, 2048)              0         
    _________________________________________________________________
    dense (Dense)                (None, 256)               524544    
    _________________________________________________________________
    dense_1 (Dense)              (None, 128)               32896     
    _________________________________________________________________
    dense_2 (Dense)              (None, 64)                8256      
    _________________________________________________________________
    dense_3 (Dense)              (None, 6)                 390       
    =================================================================
    Total params: 22,368,870
    Trainable params: 566,086
    Non-trainable params: 21,802,784
    _________________________________________________________________


모델을 구축했으니 optimizer,loss와 metrics를 정의하고 모델을 compile 한다.


```python
inception_model.compile(optimizer = 'adam',loss='categorical_crossentropy',
                       metrics=['accuracy'])
```

### 2.2 모델 훈련하기
이제 훈련할 모델을 구축하는 것까지 완료했다. 이제 모델을 훈련할건데, 모델을 훈련하기 전에 ModelCheckpoint라는 콜백함수를 정의해서 최상의 모델을 저장하고, 시드를 정해서 훈련할 때마다 같은 결과가 나오도록 설정한다.


```python
from tensorflow.keras.callbacks import ModelCheckpoint
checkpoint = ModelCheckpoint('kaggle/working/inception.hdf5',
                            monitor = 'val_accuracy',
                            save_best_only = True)

import random as rd
rd.seed(150)
np.random.seed(150)
tf.random.set_seed(150)
```

이제 본격적인 모델 훈련을 시작한다.


```python
inception_history = inception_model.fit(train_generator,
                                       steps_per_epoch=10,
                                       validation_data=validation_generator,
                                       validation_steps=5,
                                       epochs=20,
                                       callbacks=[checkpoint])
```

    2022-11-18 00:01:46.373693: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)


    Epoch 1/20


    2022-11-18 00:02:06.281662: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005


    10/10 [==============================] - 162s 14s/step - loss: 0.9810 - accuracy: 0.6574 - val_loss: 0.5298 - val_accuracy: 0.8102
    Epoch 2/20
    10/10 [==============================] - 92s 9s/step - loss: 0.4272 - accuracy: 0.8570 - val_loss: 0.4673 - val_accuracy: 0.8305
    Epoch 3/20
    10/10 [==============================] - 81s 8s/step - loss: 0.3574 - accuracy: 0.8795 - val_loss: 0.3822 - val_accuracy: 0.8578
    Epoch 4/20
    10/10 [==============================] - 84s 8s/step - loss: 0.3211 - accuracy: 0.8880 - val_loss: 0.2826 - val_accuracy: 0.9000
    Epoch 5/20
    10/10 [==============================] - 80s 8s/step - loss: 0.3062 - accuracy: 0.8898 - val_loss: 0.5119 - val_accuracy: 0.7977
    Epoch 6/20
    10/10 [==============================] - 79s 8s/step - loss: 0.3086 - accuracy: 0.8887 - val_loss: 0.3500 - val_accuracy: 0.8672
    Epoch 7/20
    10/10 [==============================] - 79s 8s/step - loss: 0.2761 - accuracy: 0.9023 - val_loss: 0.2799 - val_accuracy: 0.8961
    Epoch 8/20
    10/10 [==============================] - 80s 8s/step - loss: 0.2486 - accuracy: 0.9089 - val_loss: 0.2819 - val_accuracy: 0.8914
    Epoch 9/20
    10/10 [==============================] - 80s 8s/step - loss: 0.2463 - accuracy: 0.9101 - val_loss: 0.2947 - val_accuracy: 0.8859
    Epoch 10/20
    10/10 [==============================] - 82s 8s/step - loss: 0.2345 - accuracy: 0.9153 - val_loss: 0.2819 - val_accuracy: 0.8945
    Epoch 11/20
    10/10 [==============================] - 80s 8s/step - loss: 0.2402 - accuracy: 0.9112 - val_loss: 0.3832 - val_accuracy: 0.8562
    Epoch 12/20
    10/10 [==============================] - 81s 8s/step - loss: 0.2236 - accuracy: 0.9190 - val_loss: 0.2964 - val_accuracy: 0.8883
    Epoch 13/20
    10/10 [==============================] - 79s 8s/step - loss: 0.2090 - accuracy: 0.9239 - val_loss: 0.3315 - val_accuracy: 0.8703
    Epoch 14/20
    10/10 [==============================] - 82s 8s/step - loss: 0.2010 - accuracy: 0.9254 - val_loss: 0.3252 - val_accuracy: 0.8750
    Epoch 15/20
    10/10 [==============================] - 83s 8s/step - loss: 0.2078 - accuracy: 0.9195 - val_loss: 0.2610 - val_accuracy: 0.9000
    Epoch 16/20
    10/10 [==============================] - 83s 8s/step - loss: 0.2024 - accuracy: 0.9242 - val_loss: 0.2614 - val_accuracy: 0.9047
    Epoch 17/20
    10/10 [==============================] - 79s 8s/step - loss: 0.2142 - accuracy: 0.9193 - val_loss: 0.3364 - val_accuracy: 0.8773
    Epoch 18/20
    10/10 [==============================] - 79s 8s/step - loss: 0.2108 - accuracy: 0.9213 - val_loss: 0.3651 - val_accuracy: 0.8594
    Epoch 19/20
    10/10 [==============================] - 81s 8s/step - loss: 0.1955 - accuracy: 0.9241 - val_loss: 0.3130 - val_accuracy: 0.8813
    Epoch 20/20
    10/10 [==============================] - 80s 8s/step - loss: 0.1924 - accuracy: 0.9287 - val_loss: 0.4367 - val_accuracy: 0.8375


### 2.3 모델 평가하기
먼저 훈련 accuracy 와 검증 accuracy를 그래프로 그려보자.


```python
import matplotlib.pyplot as plt

inception_acc = inception_history.history['accuracy']
inception_val_acc = inception_history.history['val_accuracy']

epochs = range(len(inception_acc))

plt.figure(figsize=(12,8))
plt.plot(epochs, inception_acc,'r',label = 'Training Accuracy')
plt.plot(epochs, inception_val_acc,'b',label='Validation Accuracy')
plt.title('InceptionV3 Training and Validation Accuracy',fontsize=15)
plt.legend(loc=0)
plt.show()
```


    
![kaggle2_2](https://user-images.githubusercontent.com/77332628/202590854-c1f13792-6ff9-40f4-8214-258a12fd4125.png)
    


그 다음 훈련 loss와 검증 loss를 그래프로 그려보자.


```python
inception_loss = inception_history.history['loss']
inception_val_loss = inception_history.history['val_loss']

epochs = range(len(inception_loss))

plt.figure(figsize=(12,8))
plt.plot(epochs, inception_loss,'r',label = 'Training Loss')
plt.plot(epochs, inception_val_loss, 'b',label='Validation Loss')
plt.title('InceptionV3 Training and Validation Loss',fontsize=15)
plt.legend(loc=0)
plt.show()
```


    
![kaggle2_3](https://user-images.githubusercontent.com/77332628/202590859-a09bc367-428c-42bf-8d6c-a873538dd965.png)
    


훈련 손실은 계속해서 감소했지만 검증 손실은 들쭉날쭉하다. 하지만 과대적합이 심하게 되지 않은 것으로 보아 유용한 모델을 잘 구축한 것으로 보인다.

ModelCheckpoint 콜백을 이용해서 저장했던 최상의 모델을 로드하고, 최상의 모델의 성능을 confusion matrix를 통해서 시각화한다.

(confusion matrix에 대한 설명은 [이전 글](https://hamin-chang.github.io/basics/confusionmatrix/)을 참고하면 된다.)


```python
# 최상의 모델 로드
from keras.models import load_model
inception_model = load_model('kaggle/working/inception.hdf5')

# confusion matrix 그리기
import seaborn as sns
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

y_pred_inception = inception_model.predict(validation_generator)
y_pred_inception_cf = np.argmax(y_pred_inception,axis=1)

inception_confusion_matrix = confusion_matrix(validation_generator.classes,
                                              y_pred_inception_cf)
conf_matrix = pd.DataFrame(data=inception_confusion_matrix,
                          columns = labels,
                          index = labels)

plt.figure(figsize=(12,8))
sns.heatmap(conf_matrix, annot=True, cbar = False, fmt='d',linewidth = 0.5)
plt.xlabel('Predicted Classes',fontsize=12)
plt.ylabel('True Classes', fontsize=12)
plt.title('InceptionV3 Confusion Matrix',fontsize=15)
plt.show()
```


    
![kaggle2_4](https://user-images.githubusercontent.com/77332628/202590863-86334387-8728-447e-8597-2e250966710f.png)
    


최상의 모델이 대부분의 클래스에서 유의미한 수준의 정확도를 보여줬지만 mountain과 glacier를 가장 많이 헷갈리고, street와 building 클래스도 약간의 오차를 보인 것을 알 수 있다.

다음은 confusion matrix를 통해 계산한 각 클래스의 precision, recall, f1_score이다.


```python
print('InceptionV3 Classification Report')
print(classification_report(validation_generator.classes,
                           y_pred_inception_cf,
                           target_names = labels))
```

    InceptionV3 Classification Report
                  precision    recall  f1-score   support
    
       buildings       0.89      0.92      0.90       437
          forest       0.97      0.99      0.98       474
         glacier       0.92      0.61      0.73       553
        mountain       0.72      0.91      0.81       525
             sea       0.89      0.96      0.92       510
          street       0.93      0.89      0.91       501
    
        accuracy                           0.88      3000
       macro avg       0.89      0.88      0.88      3000
    weighted avg       0.89      0.88      0.87      3000
    


이번 글에는 test 데이터를 지정하지 않았기 때문에 마지막으로 최상의 모델의 검증 손실과 검증 정확도를 출력하고 글을 마무리 하겠다. 이번 글에서는 사전 훈련된 모델인 InceptionV3 모델을 사용해서 문제를 풀어봤다. 이번에 구축한 모델은 저번에 구축한 본적인 CNN 모델에 비하면 굉장히 깊지만 inception 덕분에 계산량이 많지 않았다. 
